{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nC9ikeKcH9S"
      },
      "source": [
        "In this notebook, we provide the code for re-training the exact models present in the Sentinel-2 benchmark of the pre-print paper. Alternatively, one can also choose to directly load the available weights of the pre-trained models from the 'Sentinel_model_weigths' folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuV-T9cAJH7T"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlnVAopP3at0",
        "outputId": "18ad8874-901f-4d23-f8e5-2f1d4720051c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "import copy as cp\n",
        "from time import time\n",
        "import math\n",
        "\n",
        "# import torch\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingLR, ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch import autograd\n",
        "import torch.cuda\n",
        "from torch.func import stack_module_state, vmap, functional_call\n",
        "import gc\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n",
        "\n",
        "try :\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "except :\n",
        "  print(\"No GPU is available.\")\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def mse_loss(x, x_hat):\n",
        "    \"\"\"\n",
        "    Calculate the Mean Squared Error (MSE) loss between input and reconstructed data.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): Input data.\n",
        "        x_hat (torch.Tensor): Reconstructed data.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Mean squared error loss.\n",
        "    \"\"\"\n",
        "    total_prediction_loss = torch.sum((x-x_hat)**2)/(x.size()[0])\n",
        "    return total_prediction_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B3jdrxYfNMd",
        "outputId": "4c6ac21f-b376-4b18-fed6-f128fc5566bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AIKAE'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 95 (delta 25), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (95/95), 12.73 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/anthony-frion/AIKAE\n",
        "\n",
        "from AIKAE.models import KoopmanAE, IKAE, IKAE_zp, AIKAE, NICE, RealNVP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIQoOK5DAchz"
      },
      "outputs": [],
      "source": [
        "def rescale(im, minim=None, maxim=None):\n",
        "    if maxim is None :\n",
        "      maxim = np.amax(im)\n",
        "    if minim is None :\n",
        "      minim = np.amin(im)\n",
        "    return (im-minim)/(maxim-minim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA64Z5vg41ey"
      },
      "outputs": [],
      "source": [
        "def truncate(im):\n",
        "  im[im < 0] = 0\n",
        "  im[im > 1] = 1\n",
        "  return im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAM1YmqB0LbR"
      },
      "outputs": [],
      "source": [
        "def mse_loss(x, x_hat):\n",
        "  total_prediction_loss = torch.sum((x-x_hat)**2)/(x.size()[0])\n",
        "  return total_prediction_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztmhyu9VLEVM"
      },
      "source": [
        "# Import data with gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQjBUqHNLG6V",
        "outputId": "a64705f8-7450-4550-a744-024aa2c4a880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZWH06EQYTiBUHRABVH2o_s2I_9Zm6dpo\n",
            "From (redirected): https://drive.google.com/uc?id=1ZWH06EQYTiBUHRABVH2o_s2I_9Zm6dpo&confirm=t&uuid=c2cc4e0b-4bec-43ea-bb55-2b36b0736d2a\n",
            "To: /content/Fontainebleau_interpolated.npy\n",
            "100% 3.43G/3.43G [00:55<00:00, 61.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1K2QtxcJjnzCpPgBQnXrTyAM_yoyi2710\n",
            "From (redirected): https://drive.google.com/uc?id=1K2QtxcJjnzCpPgBQnXrTyAM_yoyi2710&confirm=t&uuid=ae05dfe8-61fe-4917-8d9c-56dcc496cc5f\n",
            "To: /content/Orléans_irregular.npy\n",
            "100% 3.43G/3.43G [00:52<00:00, 66.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17IjvRhWT4dzyr9vlKQOjoolYAzTvLfvF\n",
            "To: /content/Orléans_mask.npy\n",
            "100% 2.87k/2.87k [00:00<00:00, 16.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Fontainebleau interpolated time series\n",
        "!gdown 1ZWH06EQYTiBUHRABVH2o_s2I_9Zm6dpo -O Fontainebleau_interpolated.npy\n",
        "\n",
        "# Orléans irregular time series and its mask\n",
        "!gdown 1K2QtxcJjnzCpPgBQnXrTyAM_yoyi2710 -O Orléans_irregular.npy\n",
        "!gdown 17IjvRhWT4dzyr9vlKQOjoolYAzTvLfvF -O Orléans_mask.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uewGvH3RdN_p"
      },
      "source": [
        "Running the cell below enables you to download the Sentinel-2 data directly from Google Drive. Another option is to download the files from https://drive.google.com/drive/u/1/folders/1doHnjryCMptkzxYFfw-ILwAD0tOK3LGH and then use it as will, either locally or on a Google Colab session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4QI34sNLKqj"
      },
      "outputs": [],
      "source": [
        "data = np.load('drive/MyDrive/Thèse_Anthony/Sentinel-2/Fontainebleau_interpolated.npy')\n",
        "max_Fontainebleau = np.max(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EKmCs36LMeS"
      },
      "outputs": [],
      "source": [
        "# We rescale the data to values between 0 and 1\n",
        "if np.max(data) > 1:\n",
        "  data /= max_Fontainebleau\n",
        "  data *= 3 # Arbitrary rescaling and thresholding since the max is highly saturated\n",
        "  data[data > 1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no0BVecULOcR",
        "outputId": "8d387f00-728b-4630-a254-91d21a4939a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(343, 10, 500, 500)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)\n",
        "#343 -> temporal index ; 10 -> spectral band index ; 500, 500 -> spatial indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxY6jTrzLSkS"
      },
      "outputs": [],
      "source": [
        "data_test = np.load('Orléans_irregular.npy')\n",
        "mask_test = np.load('Orléans_mask.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a92rEvUcLXex"
      },
      "outputs": [],
      "source": [
        "# We rescale the data to values between 0 and 1\n",
        "if np.max(data_test) > 3:\n",
        "  data_test /= max_Fontainebleau\n",
        "  data_test *= 3 # Arbitrary rescaling since the max is highly saturated\n",
        "  # This time we do not impose a threshold of 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFXls3LhLeqL",
        "outputId": "8814a614-8fb3-4f7e-c333-d3ac981496e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(343, 150, 150, 10)\n"
          ]
        }
      ],
      "source": [
        "# We extract 150x150 squares out of the 500x500 pixel time series\n",
        "\n",
        "data_small = data[:,:,250:400,250:400].transpose(0,2,3,1) #150x150\n",
        "reflectances = data_small.transpose(3,1,2,0)\n",
        "\n",
        "data_test_small = data_test[:,:,150:300,150:300].transpose(0,2,3,1) #150x150\n",
        "print(data_test_small.shape)\n",
        "reflectances_test = data_test_small.transpose(3,1,2,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6B4duNNN-NE"
      },
      "source": [
        "# Set path for saving models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w54v5BlKOA4L"
      },
      "outputs": [],
      "source": [
        "# Path for saving the trained models. You can set this path to whatever suitable value.\n",
        "path = ''\n",
        "if os.path.exists(path):\n",
        "  models_path = path\n",
        "else:\n",
        "  models_path = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeOHCR1FE9QZ"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJzCN-CeNE0"
      },
      "source": [
        "Here, we pre-process the data to a format that is suitable for training the models. We randomly extract slices of length 100 (i.e. one year and a half since one time step is 5 days) corresponding to random pixels and initial times. The RNG seed is manually set so that you can get the same results as in the paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9EdQ2Y1HoHS",
        "outputId": "fd1a80fd-4911-4949-e753-09a6af6a426c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-c374176a773b>:23: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
            "  - reflectances[:,initial_x,initial_y,initial_times-1]))).T\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of initial_state : torch.Size([512, 512, 20])\n",
            "Shape of states : torch.Size([101, 512, 512, 20])\n"
          ]
        }
      ],
      "source": [
        "time_span = 100\n",
        "data_small_train = data[:,:,250:400,250:400].transpose(0,2,3,1) #150x150 -> TSP benchmark\n",
        "#data_small_train = data.transpose(0,2,3,1) # 500x500\n",
        "reflectances = data_small_train.transpose(3,1,2,0)\n",
        "L = 10\n",
        "forward = True\n",
        "batch_size = 512 # TSP benchmark\n",
        "nb_batches = 512\n",
        "#batch_size = 2048 # 16x more data\n",
        "#nb_batches = 2048\n",
        "\n",
        "# We set a manual seed for the RNG so that the results\n",
        "rng = torch.Generator().manual_seed(42)\n",
        "\n",
        "initial_times = torch.randint(1, 341 - 2*time_span, (batch_size, nb_batches), generator=rng)\n",
        "\n",
        "initial_x = torch.randint(0, reflectances.shape[1], (batch_size, nb_batches), generator=rng)\n",
        "initial_y = torch.randint(0, reflectances.shape[1], (batch_size, nb_batches), generator=rng)\n",
        "\n",
        "initial_state = torch.Tensor(reflectances[:,initial_x,initial_y,initial_times])\n",
        "initial_state = torch.cat((initial_state,\n",
        "                            torch.Tensor(reflectances[:,initial_x,initial_y,initial_times]\n",
        "                                        - reflectances[:,initial_x,initial_y,initial_times-1]))).T\n",
        "print(f\"Shape of initial_state : {initial_state.shape}\")\n",
        "\n",
        "state_batches = torch.zeros((time_span+1, nb_batches, batch_size, 20))\n",
        "for t in range(time_span+1) :\n",
        "  state_batches[t] = torch.cat((torch.Tensor(reflectances[:,initial_x,initial_y,initial_times+t]),\n",
        "                    torch.Tensor(reflectances[:,initial_x,initial_y,initial_times+t]\n",
        "                                  - reflectances[:,initial_x,initial_y,initial_times+t-1]))).permute((2,1,0))\n",
        "\n",
        "print(f\"Shape of states : {state_batches.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHK-0puojTdZ",
        "outputId": "7a5219ea-5ea7-4778-cde5-50d5f0408876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of initial_state : torch.Size([512, 20])\n",
            "Shape of states : torch.Size([101, 512, 20])\n"
          ]
        }
      ],
      "source": [
        "initial_x = torch.randint(0, reflectances.shape[1], (batch_size,), generator=rng)\n",
        "initial_y = torch.randint(0, reflectances.shape[1], (batch_size,), generator=rng)\n",
        "initial_time = 341 - time_span\n",
        "initial_state_val = torch.Tensor(reflectances[:,initial_x,initial_y, initial_time]).to(device)\n",
        "initial_state_val = torch.cat((initial_state_val,\n",
        "                            torch.Tensor(reflectances[:,initial_x,initial_y,initial_time]\n",
        "                                        - reflectances[:,initial_x,initial_y,initial_time-1]).cuda())).T\n",
        "print(f\"Shape of initial_state : {initial_state_val.shape}\")\n",
        "\n",
        "states_val = torch.zeros((time_span+1, batch_size, 20)).to(device)\n",
        "for t in range(time_span+1) :\n",
        "  states_val[t] = torch.cat((torch.Tensor(reflectances[:,initial_x,initial_y,initial_time+t]).cuda(),\n",
        "                    torch.Tensor(reflectances[:,initial_x,initial_y,initial_time+t]\n",
        "                                  - reflectances[:,initial_x,initial_y,initial_time+t-1]).cuda())).T\n",
        "print(f\"Shape of states : {states_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSrWC6_uIr5r",
        "outputId": "9fc7a856-c90a-45e6-cf5a-61f30e9379a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([101, 512, 512, 20])\n"
          ]
        }
      ],
      "source": [
        "print(state_batches.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "NQLponpFIwU5",
        "outputId": "c7df997d-09c4-4d59-a787-082d68fd5d17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Spectral band')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "#plt.figure()\n",
        "gs = gridspec.GridSpec(2,1,height_ratios=[2,1])\n",
        "plt.subplot(gs[0])\n",
        "plt.plot([5*k for k in range(state_batches.shape[0])], state_batches[:,42,42,:10].cpu().detach().numpy())\n",
        "plt.xlim(-2.5, 5*state_batches.shape[0]-2.5)\n",
        "plt.xlabel('Time (days)')\n",
        "plt.ylabel('Reflectance')\n",
        "plt.subplot(gs[1])\n",
        "plt.imshow(state_batches[:,42,42,:10].T.cpu().detach().numpy())\n",
        "x = [0, 100, 200, 300, 400, 500]\n",
        "xi = [k // 5 for k in x]\n",
        "plt.xticks(xi, x)\n",
        "plt.xlabel('Time (days)')\n",
        "plt.ylabel('Spectral band')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_BalDRr8J6Z"
      },
      "source": [
        "# KAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2DEiBSpOHg",
        "outputId": "b4f3bda9-e078-482d-a429-d8a14e3468fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 300596\n",
            "KoopmanAE(\n",
            "  (encoder): ModuleList(\n",
            "    (0): Linear(in_features=20, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=32, bias=True)\n",
            "  )\n",
            "  (decoder): ModuleList(\n",
            "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (2): Linear(in_features=512, out_features=20, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "model = KoopmanAE.KoopmanAE(20, [512,256,32], device=device).to(device)\n",
        "\n",
        "print(f\"Number of parameters: {count_parameters(model)}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UZ26Gxk2pME9",
        "outputId": "1354687e-8bc9-4f48-f276-c686e5d342f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with seed 0\n",
            "Epoch 1 : Train loss 42.29852713085711, validation loss 16.657142639160156\n",
            "Complete prediction MSE : 0.0033415014728621177\n",
            "Saving model\n",
            "Epoch 2 : Train loss 13.218219744041562, validation loss 10.151602745056152\n",
            "Complete prediction MSE : 0.0030637703789057305\n",
            "Saving model\n",
            "Epoch 3 : Train loss 11.161183092743158, validation loss 9.764592170715332\n",
            "Complete prediction MSE : 0.003106205448436413\n",
            "Epoch 4 : Train loss 10.001219255849719, validation loss 8.573482513427734\n",
            "Complete prediction MSE : 0.0030965341656651454\n",
            "Epoch 5 : Train loss 9.306296849623322, validation loss 8.282848358154297\n",
            "Complete prediction MSE : 0.002745189062960039\n",
            "Saving model\n",
            "Epoch 6 : Train loss 8.854835169389844, validation loss 8.796456336975098\n",
            "Complete prediction MSE : 0.002670479171592385\n",
            "Saving model\n",
            "Epoch 7 : Train loss 8.477220820263028, validation loss 9.631791114807129\n",
            "Complete prediction MSE : 0.0026483069546195622\n",
            "Saving model\n",
            "Epoch 8 : Train loss 8.128242121078074, validation loss 9.412687301635742\n",
            "Complete prediction MSE : 0.0025441673694789955\n",
            "Saving model\n",
            "Epoch 9 : Train loss 7.84035334829241, validation loss 9.700664520263672\n",
            "Complete prediction MSE : 0.0024548655777144116\n",
            "Saving model\n",
            "Epoch 10 : Train loss 7.595213044434786, validation loss 10.138341903686523\n",
            "Complete prediction MSE : 0.0023305219096454366\n",
            "Saving model\n",
            "Epoch 11 : Train loss 7.379354012198746, validation loss 9.646736145019531\n",
            "Complete prediction MSE : 0.0023475542101135827\n",
            "Epoch 12 : Train loss 7.195002959109843, validation loss 9.20988941192627\n",
            "Complete prediction MSE : 0.002372259690955311\n",
            "Epoch 13 : Train loss 7.038181149400771, validation loss 9.439454078674316\n",
            "Complete prediction MSE : 0.0022951193586493775\n",
            "Saving model\n",
            "Epoch 14 : Train loss 6.885943764820695, validation loss 9.451305389404297\n",
            "Complete prediction MSE : 0.0022610240030974046\n",
            "Saving model\n",
            "Epoch 15 : Train loss 6.7516832603141665, validation loss 9.271971702575684\n",
            "Complete prediction MSE : 0.0022225144130135284\n",
            "Saving model\n",
            "Epoch 16 : Train loss 6.622173981741071, validation loss 9.472182273864746\n",
            "Complete prediction MSE : 0.002290218737150742\n",
            "Epoch 17 : Train loss 6.5040882946923375, validation loss 9.126778602600098\n",
            "Complete prediction MSE : 0.002261629365844942\n",
            "Epoch 18 : Train loss 6.403565865010023, validation loss 9.024706840515137\n",
            "Complete prediction MSE : 0.002300508302490632\n",
            "Epoch 19 : Train loss 6.307281878776848, validation loss 8.937321662902832\n",
            "Complete prediction MSE : 0.002281769398717576\n",
            "Epoch 20 : Train loss 6.2202025055885315, validation loss 8.689878463745117\n",
            "Complete prediction MSE : 0.0022654639670300434\n",
            "Epoch 21 : Train loss 6.1374651016667485, validation loss 8.567378997802734\n",
            "Complete prediction MSE : 0.0022450763141655217\n",
            "Epoch 22 : Train loss 6.058570330031216, validation loss 8.278139114379883\n",
            "Complete prediction MSE : 0.002190709589504417\n",
            "Saving model\n",
            "Epoch 23 : Train loss 5.965909089893103, validation loss 8.227051734924316\n",
            "Complete prediction MSE : 0.002118912873491877\n",
            "Saving model\n",
            "Epoch 24 : Train loss 5.91161107365042, validation loss 8.06051254272461\n",
            "Complete prediction MSE : 0.002104196698684951\n",
            "Saving model\n",
            "Epoch 25 : Train loss 5.841988580301404, validation loss 7.918150424957275\n",
            "Complete prediction MSE : 0.0020829306123112614\n",
            "Saving model\n",
            "Epoch 26 : Train loss 5.78058812674135, validation loss 7.958410263061523\n",
            "Complete prediction MSE : 0.002003759623388853\n",
            "Saving model\n",
            "Epoch 27 : Train loss 5.714264842681587, validation loss 8.025882720947266\n",
            "Complete prediction MSE : 0.0019714228895488153\n",
            "Saving model\n",
            "Epoch 28 : Train loss 5.659788548946381, validation loss 8.206086158752441\n",
            "Complete prediction MSE : 0.0019026275127812333\n",
            "Saving model\n",
            "Epoch 29 : Train loss 5.6049918392673135, validation loss 8.328469276428223\n",
            "Complete prediction MSE : 0.0019127605705400721\n",
            "Epoch 30 : Train loss 5.554579869844019, validation loss 8.203767776489258\n",
            "Complete prediction MSE : 0.0019077878071842532\n",
            "Epoch 31 : Train loss 5.504990151152015, validation loss 8.090624809265137\n",
            "Complete prediction MSE : 0.0019242963725623714\n",
            "Epoch 32 : Train loss 5.459301274269819, validation loss 8.17475414276123\n",
            "Complete prediction MSE : 0.0019891277391314503\n",
            "Epoch 33 : Train loss 5.410058293491602, validation loss 8.203673362731934\n",
            "Complete prediction MSE : 0.0019417256699810366\n",
            "Epoch 34 : Train loss 5.365213365294039, validation loss 8.48167896270752\n",
            "Complete prediction MSE : 0.0018946543023228351\n",
            "Saving model\n",
            "Epoch 35 : Train loss 5.327558710239828, validation loss 8.441120147705078\n",
            "Complete prediction MSE : 0.0019114638043118892\n",
            "Epoch 36 : Train loss 5.284305430948734, validation loss 8.184528350830078\n",
            "Complete prediction MSE : 0.00194088242563201\n",
            "Epoch 37 : Train loss 5.246376302093267, validation loss 8.439436912536621\n",
            "Complete prediction MSE : 0.0018301300018052598\n",
            "Saving model\n",
            "Epoch 38 : Train loss 5.2018836019560695, validation loss 8.538642883300781\n",
            "Complete prediction MSE : 0.001801294580933287\n",
            "Saving model\n",
            "Epoch 39 : Train loss 5.1703556925058365, validation loss 8.50060749053955\n",
            "Complete prediction MSE : 0.0017389815489167655\n",
            "Saving model\n",
            "Epoch 40 : Train loss 5.132727453485131, validation loss 8.558367729187012\n",
            "Complete prediction MSE : 0.00173748470180635\n",
            "Saving model\n",
            "Epoch 41 : Train loss 5.1069523906335235, validation loss 8.660972595214844\n",
            "Complete prediction MSE : 0.0016993948648041117\n",
            "Saving model\n",
            "Epoch 42 : Train loss 5.067788331769407, validation loss 8.679747581481934\n",
            "Complete prediction MSE : 0.0017069395553063792\n",
            "Epoch 43 : Train loss 5.038304113782942, validation loss 9.075552940368652\n",
            "Complete prediction MSE : 0.0017169015372861824\n",
            "Epoch 44 : Train loss 5.002655515447259, validation loss 8.930957794189453\n",
            "Complete prediction MSE : 0.0016977512628888643\n",
            "Saving model\n",
            "Epoch 45 : Train loss 4.982908988371491, validation loss 9.27674674987793\n",
            "Complete prediction MSE : 0.0016767838458583014\n",
            "Saving model\n",
            "Epoch 46 : Train loss 4.950375963002443, validation loss 9.241130828857422\n",
            "Complete prediction MSE : 0.0016574296063714292\n",
            "Saving model\n",
            "Epoch 47 : Train loss 4.925220035947859, validation loss 9.2252836227417\n",
            "Complete prediction MSE : 0.001672941027787208\n",
            "Epoch 48 : Train loss 4.896585639566183, validation loss 9.378500938415527\n",
            "Complete prediction MSE : 0.0016452386275091126\n",
            "Saving model\n",
            "Epoch 49 : Train loss 4.867636604234576, validation loss 9.628454208374023\n",
            "Complete prediction MSE : 0.0015537312338919768\n",
            "Saving model\n",
            "Epoch 50 : Train loss 4.849088378250599, validation loss 9.485726356506348\n",
            "Complete prediction MSE : 0.001580844606491463\n",
            "Epoch 51 : Train loss 4.815949901938438, validation loss 9.465689659118652\n",
            "Complete prediction MSE : 0.001520928670239327\n",
            "Saving model\n",
            "Epoch 52 : Train loss 4.787859434261918, validation loss 9.618932723999023\n",
            "Complete prediction MSE : 0.001511902037589478\n",
            "Saving model\n",
            "Epoch 53 : Train loss 4.760833917185664, validation loss 9.555543899536133\n",
            "Complete prediction MSE : 0.0015503031518794457\n",
            "Epoch 54 : Train loss 4.745550721883774, validation loss 9.652970314025879\n",
            "Complete prediction MSE : 0.0015410863247652161\n",
            "Epoch 55 : Train loss 4.719889149069786, validation loss 9.470414161682129\n",
            "Complete prediction MSE : 0.001532428589201428\n",
            "Epoch 56 : Train loss 4.695361005142331, validation loss 9.561850547790527\n",
            "Complete prediction MSE : 0.0014710012779790994\n",
            "Saving model\n",
            "Epoch 57 : Train loss 4.671186996623874, validation loss 9.964095115661621\n",
            "Complete prediction MSE : 0.0015226595866837946\n",
            "Epoch 58 : Train loss 4.655968338251114, validation loss 9.763978004455566\n",
            "Complete prediction MSE : 0.0014678471347617744\n",
            "Saving model\n",
            "Epoch 59 : Train loss 4.632381718605757, validation loss 9.633587837219238\n",
            "Complete prediction MSE : 0.0014176783937898283\n",
            "Saving model\n",
            "Epoch 60 : Train loss 4.608941353391856, validation loss 9.714552879333496\n",
            "Complete prediction MSE : 0.0014186513248652737\n",
            "Epoch 61 : Train loss 4.596807452850044, validation loss 9.695234298706055\n",
            "Complete prediction MSE : 0.0014037606804449038\n",
            "Saving model\n",
            "Epoch 62 : Train loss 4.570417030714452, validation loss 9.656386375427246\n",
            "Complete prediction MSE : 0.0013777376447621627\n",
            "Saving model\n",
            "Epoch 63 : Train loss 4.558247720822692, validation loss 9.820415496826172\n",
            "Complete prediction MSE : 0.0014049400276850462\n",
            "Epoch 64 : Train loss 4.543213156983256, validation loss 9.632267951965332\n",
            "Complete prediction MSE : 0.0014126661598829083\n",
            "Epoch 65 : Train loss 4.52238598652184, validation loss 9.665084838867188\n",
            "Complete prediction MSE : 0.0013974877860373728\n",
            "Epoch 66 : Train loss 4.497818265110254, validation loss 9.601719856262207\n",
            "Complete prediction MSE : 0.0014467132338076539\n",
            "Epoch 67 : Train loss 4.487043344881386, validation loss 9.824273109436035\n",
            "Complete prediction MSE : 0.001424212592867487\n",
            "Epoch 68 : Train loss 4.4635653449222445, validation loss 9.504755020141602\n",
            "Complete prediction MSE : 0.001446568710827946\n",
            "Epoch 69 : Train loss 4.448289817664772, validation loss 9.4541654586792\n",
            "Complete prediction MSE : 0.0014448962078982225\n",
            "Epoch 70 : Train loss 4.432601256296039, validation loss 9.658768653869629\n",
            "Complete prediction MSE : 0.001434434098850802\n",
            "Epoch 71 : Train loss 4.422264881432056, validation loss 9.506306648254395\n",
            "Complete prediction MSE : 0.0014562907775244732\n",
            "Epoch 72 : Train loss 4.400272715836763, validation loss 9.629814147949219\n",
            "Complete prediction MSE : 0.0014796123546687238\n",
            "Epoch 73 : Train loss 4.391881998162717, validation loss 9.471280097961426\n",
            "Complete prediction MSE : 0.0014450093014271295\n",
            "Epoch 74 : Train loss 4.373577158432454, validation loss 9.699678421020508\n",
            "Complete prediction MSE : 0.001434835691859003\n",
            "Epoch 75 : Train loss 4.361675085965544, validation loss 9.673340797424316\n",
            "Complete prediction MSE : 0.0015022653366269455\n",
            "Epoch 76 : Train loss 4.344362498726696, validation loss 9.443031311035156\n",
            "Complete prediction MSE : 0.0014105664403594427\n",
            "Epoch 77 : Train loss 4.3347520381212234, validation loss 9.708723068237305\n",
            "Complete prediction MSE : 0.001407744799697435\n",
            "Epoch 78 : Train loss 4.321555750910193, validation loss 9.431772232055664\n",
            "Complete prediction MSE : 0.0014661166415012577\n",
            "Epoch 79 : Train loss 4.310007385443896, validation loss 9.4536714553833\n",
            "Complete prediction MSE : 0.0014486013445621556\n",
            "Epoch 80 : Train loss 4.298026828560978, validation loss 9.397431373596191\n",
            "Complete prediction MSE : 0.0014745342237702103\n",
            "Epoch 81 : Train loss 4.290794626809657, validation loss 9.158781051635742\n",
            "Complete prediction MSE : 0.0014397321845066927\n",
            "Epoch 82 : Train loss 4.272749410942197, validation loss 9.100090980529785\n",
            "Complete prediction MSE : 0.0014152341100128318\n",
            "Epoch 83 : Train loss 4.26270057586953, validation loss 9.206916809082031\n",
            "Complete prediction MSE : 0.0015162930986813961\n",
            "Epoch 84 : Train loss 4.254452082328498, validation loss 9.06119441986084\n",
            "Complete prediction MSE : 0.0014117282946603717\n",
            "Epoch 85 : Train loss 4.245487239677459, validation loss 8.84063720703125\n",
            "Complete prediction MSE : 0.001393305561394352\n",
            "Epoch 86 : Train loss 4.239847466815263, validation loss 8.646632194519043\n",
            "Complete prediction MSE : 0.0014543950769142628\n",
            "Epoch 87 : Train loss 4.223286926280707, validation loss 8.830462455749512\n",
            "Complete prediction MSE : 0.001484202766163388\n",
            "Epoch 88 : Train loss 4.217020361684263, validation loss 8.80666732788086\n",
            "Complete prediction MSE : 0.0015673299486671087\n",
            "Epoch 89 : Train loss 4.207515469752252, validation loss 8.82059097290039\n",
            "Complete prediction MSE : 0.0014454934397240345\n",
            "Epoch 90 : Train loss 4.202146750874817, validation loss 8.802018165588379\n",
            "Complete prediction MSE : 0.0013501638879949256\n",
            "Saving model\n",
            "Epoch 91 : Train loss 4.186789722181857, validation loss 8.516014099121094\n",
            "Complete prediction MSE : 0.0014672760439592295\n",
            "Epoch 92 : Train loss 4.178207288030535, validation loss 8.61034870147705\n",
            "Complete prediction MSE : 0.0015338138503561177\n",
            "Epoch 93 : Train loss 4.167595074977726, validation loss 8.530338287353516\n",
            "Complete prediction MSE : 0.0015021671527583847\n",
            "Epoch 94 : Train loss 4.162844032980502, validation loss 8.60474681854248\n",
            "Complete prediction MSE : 0.0014978693643054454\n",
            "Epoch 95 : Train loss 4.158196239266545, validation loss 8.612955093383789\n",
            "Complete prediction MSE : 0.0014348255175562197\n",
            "Epoch 96 : Train loss 4.144064047839493, validation loss 8.341654777526855\n",
            "Complete prediction MSE : 0.0014177447352462871\n",
            "Epoch 97 : Train loss 4.136184848845005, validation loss 8.391408920288086\n",
            "Complete prediction MSE : 0.0015498547876062695\n",
            "Epoch 98 : Train loss 4.128457861486822, validation loss 8.47143840789795\n",
            "Complete prediction MSE : 0.0014698186255588661\n",
            "Epoch 99 : Train loss 4.119008426554501, validation loss 8.526185035705566\n",
            "Complete prediction MSE : 0.001519448954765874\n",
            "Epoch 100 : Train loss 4.1173227108083665, validation loss 8.34266471862793\n",
            "Complete prediction MSE : 0.0014405726086011864\n",
            "Epoch 101 : Train loss 4.106874166987836, validation loss 8.11946964263916\n",
            "Complete prediction MSE : 0.0015234985198742449\n",
            "Epoch 102 : Train loss 4.098136635031551, validation loss 8.224488258361816\n",
            "Complete prediction MSE : 0.0015627504147934996\n",
            "Epoch 103 : Train loss 4.097204183693975, validation loss 7.846723556518555\n",
            "Complete prediction MSE : 0.0014851876892786578\n",
            "Epoch 104 : Train loss 4.08191878022626, validation loss 7.7759928703308105\n",
            "Complete prediction MSE : 0.0014664497020052888\n",
            "Epoch 105 : Train loss 4.072332493029535, validation loss 7.973960876464844\n",
            "Complete prediction MSE : 0.0015764792705953298\n",
            "Epoch 106 : Train loss 4.065792984794825, validation loss 7.95056676864624\n",
            "Complete prediction MSE : 0.0015620820257776064\n",
            "Epoch 107 : Train loss 4.067309848498553, validation loss 7.919430255889893\n",
            "Complete prediction MSE : 0.0014423571423860504\n",
            "Epoch 108 : Train loss 4.049184754025191, validation loss 7.848618984222412\n",
            "Complete prediction MSE : 0.0014398378042263526\n",
            "Epoch 109 : Train loss 4.047742743045092, validation loss 8.03874683380127\n",
            "Complete prediction MSE : 0.0015182391497273085\n",
            "Epoch 110 : Train loss 4.041118287481368, validation loss 8.077195167541504\n",
            "Complete prediction MSE : 0.0013579610105725148\n",
            "Epoch 111 : Train loss 4.025796869769692, validation loss 7.833000183105469\n",
            "Complete prediction MSE : 0.0015136365964228823\n",
            "Epoch 112 : Train loss 4.024697618559003, validation loss 7.70230770111084\n",
            "Complete prediction MSE : 0.0013775168438280474\n",
            "Epoch 113 : Train loss 4.013562472071499, validation loss 7.630599021911621\n",
            "Complete prediction MSE : 0.0013741055846239038\n",
            "Epoch 114 : Train loss 4.012086819857359, validation loss 7.806955814361572\n",
            "Complete prediction MSE : 0.0015067012707674382\n",
            "Epoch 115 : Train loss 4.003793889191002, validation loss 7.944955348968506\n",
            "Complete prediction MSE : 0.0014129386156499603\n",
            "Epoch 116 : Train loss 4.003022002056241, validation loss 8.132445335388184\n",
            "Complete prediction MSE : 0.001649833116356476\n",
            "Epoch 117 : Train loss 3.997719789389521, validation loss 8.032637596130371\n",
            "Complete prediction MSE : 0.0014288457008450085\n",
            "Epoch 118 : Train loss 3.995449440088123, validation loss 7.840409755706787\n",
            "Complete prediction MSE : 0.0014419457822609878\n",
            "Epoch 119 : Train loss 3.982857176568359, validation loss 7.938485622406006\n",
            "Complete prediction MSE : 0.001429870932499018\n",
            "Epoch 120 : Train loss 3.97707112878561, validation loss 7.908567905426025\n",
            "Complete prediction MSE : 0.0014712327960149803\n",
            "Epoch 121 : Train loss 3.969389338977635, validation loss 7.881640434265137\n",
            "Complete prediction MSE : 0.0014649658243357751\n",
            "Epoch 122 : Train loss 3.968933278694749, validation loss 7.811277866363525\n",
            "Complete prediction MSE : 0.0014281071439545669\n",
            "Epoch 123 : Train loss 3.960739986039698, validation loss 7.702797889709473\n",
            "Complete prediction MSE : 0.0013831853786684153\n",
            "Epoch 124 : Train loss 3.9553118320181966, validation loss 7.538609027862549\n",
            "Complete prediction MSE : 0.0013410075773313997\n",
            "Saving model\n",
            "Epoch 125 : Train loss 3.955726192332804, validation loss 7.906179428100586\n",
            "Complete prediction MSE : 0.0014511547736879532\n",
            "Epoch 126 : Train loss 3.943702536635101, validation loss 7.677484035491943\n",
            "Complete prediction MSE : 0.001360180264131573\n",
            "Epoch 127 : Train loss 3.939560861326754, validation loss 7.899550437927246\n",
            "Complete prediction MSE : 0.001339644356200149\n",
            "Saving model\n",
            "Epoch 128 : Train loss 3.931499646510929, validation loss 7.821446418762207\n",
            "Complete prediction MSE : 0.001384971268188154\n",
            "Epoch 129 : Train loss 3.940624001901597, validation loss 7.842158317565918\n",
            "Complete prediction MSE : 0.0013698160113918174\n",
            "Epoch 130 : Train loss 3.9341722819954157, validation loss 7.880883693695068\n",
            "Complete prediction MSE : 0.0013221774724478704\n",
            "Saving model\n",
            "Epoch 131 : Train loss 3.919443645514548, validation loss 7.769896507263184\n",
            "Complete prediction MSE : 0.0014589819955620822\n",
            "Epoch 132 : Train loss 3.9066599532961845, validation loss 7.832835674285889\n",
            "Complete prediction MSE : 0.0014392647969346287\n",
            "Epoch 133 : Train loss 3.915583809837699, validation loss 7.989997386932373\n",
            "Complete prediction MSE : 0.0014121069795349369\n",
            "Epoch 134 : Train loss 3.9092269856482744, validation loss 7.8652520179748535\n",
            "Complete prediction MSE : 0.001407125858242707\n",
            "Epoch 135 : Train loss 3.907152943313122, validation loss 7.771183967590332\n",
            "Complete prediction MSE : 0.0013497453870576351\n",
            "Epoch 136 : Train loss 3.9022127822972834, validation loss 7.942953109741211\n",
            "Complete prediction MSE : 0.0013639500352648866\n",
            "Epoch 137 : Train loss 3.895836395677179, validation loss 7.903745651245117\n",
            "Complete prediction MSE : 0.0013113591742549278\n",
            "Saving model\n",
            "Epoch 138 : Train loss 3.893683787435293, validation loss 7.877867221832275\n",
            "Complete prediction MSE : 0.0013589552240073658\n",
            "Epoch 139 : Train loss 3.88328754901886, validation loss 7.82043981552124\n",
            "Complete prediction MSE : 0.0013886048251368164\n",
            "Epoch 140 : Train loss 3.884428007993847, validation loss 7.561196327209473\n",
            "Complete prediction MSE : 0.0013861056058491973\n",
            "Epoch 141 : Train loss 3.8820084584876895, validation loss 7.750977993011475\n",
            "Complete prediction MSE : 0.0013228972840743343\n",
            "Epoch 142 : Train loss 3.8773392979055643, validation loss 7.6402411460876465\n",
            "Complete prediction MSE : 0.0013963149563863586\n",
            "Epoch 143 : Train loss 3.8727921820245683, validation loss 7.85518217086792\n",
            "Complete prediction MSE : 0.001333815098067181\n",
            "Epoch 144 : Train loss 3.8653816347941756, validation loss 7.640270709991455\n",
            "Complete prediction MSE : 0.0014985555682224948\n",
            "Epoch 145 : Train loss 3.8666489962488413, validation loss 7.889072895050049\n",
            "Complete prediction MSE : 0.0014388159720509438\n",
            "Epoch 146 : Train loss 3.8586706896312535, validation loss 7.7313618659973145\n",
            "Complete prediction MSE : 0.0013736663729916998\n",
            "Epoch 147 : Train loss 3.8490929258987308, validation loss 7.616949558258057\n",
            "Complete prediction MSE : 0.001346775197427342\n",
            "Epoch 148 : Train loss 3.847650290466845, validation loss 7.979938983917236\n",
            "Complete prediction MSE : 0.0013191356801890476\n",
            "Epoch 149 : Train loss 3.852541512809694, validation loss 7.849701404571533\n",
            "Complete prediction MSE : 0.0013232169041662387\n",
            "Epoch 150 : Train loss 3.843781325034797, validation loss 7.8652520179748535\n",
            "Complete prediction MSE : 0.001440240174173795\n",
            "Epoch 151 : Train loss 3.8325742459855974, validation loss 7.902358055114746\n",
            "Complete prediction MSE : 0.0013355297363493578\n",
            "Epoch 152 : Train loss 3.8414423032663763, validation loss 7.6871442794799805\n",
            "Complete prediction MSE : 0.0015324361296195628\n",
            "Epoch 153 : Train loss 3.8295650188811123, validation loss 7.83546257019043\n",
            "Complete prediction MSE : 0.001507863839377473\n",
            "Epoch 154 : Train loss 3.8277444248087704, validation loss 7.746231555938721\n",
            "Complete prediction MSE : 0.0014044354373814259\n",
            "Epoch 155 : Train loss 3.8186826230958104, validation loss 8.02839183807373\n",
            "Complete prediction MSE : 0.0014231044738863448\n",
            "Epoch 156 : Train loss 3.8183464691974223, validation loss 7.862258434295654\n",
            "Complete prediction MSE : 0.0015087040923826348\n",
            "Epoch 157 : Train loss 3.819090088829398, validation loss 7.789059638977051\n",
            "Complete prediction MSE : 0.0013850925623254543\n",
            "Epoch 158 : Train loss 3.8107106778770685, validation loss 7.7066192626953125\n",
            "Complete prediction MSE : 0.0015810618254249412\n",
            "Epoch 159 : Train loss 3.811894791200757, validation loss 7.63275146484375\n",
            "Complete prediction MSE : 0.0016213340323730893\n",
            "Epoch 160 : Train loss 3.8053665412589908, validation loss 7.915287494659424\n",
            "Complete prediction MSE : 0.0014375459355007649\n",
            "Epoch 161 : Train loss 3.7975278892554343, validation loss 7.781095504760742\n",
            "Complete prediction MSE : 0.001390235625507455\n",
            "Epoch 162 : Train loss 3.797891952097416, validation loss 7.75216817855835\n",
            "Complete prediction MSE : 0.0015239650565703937\n",
            "Epoch 163 : Train loss 3.7933107428252697, validation loss 7.883784770965576\n",
            "Complete prediction MSE : 0.0014998814264221819\n",
            "Epoch 164 : Train loss 3.784991935826838, validation loss 7.736790180206299\n",
            "Complete prediction MSE : 0.001495999145630171\n",
            "Epoch 165 : Train loss 3.7839633943513036, validation loss 7.585622310638428\n",
            "Complete prediction MSE : 0.001451257461120476\n",
            "Epoch 166 : Train loss 3.7848493913188577, validation loss 7.732393264770508\n",
            "Complete prediction MSE : 0.0014510032094808309\n",
            "Epoch 167 : Train loss 3.777179806958884, validation loss 7.656920909881592\n",
            "Complete prediction MSE : 0.0015551312839218675\n",
            "Epoch 168 : Train loss 3.7762572546489537, validation loss 7.732894420623779\n",
            "Complete prediction MSE : 0.0014677741715457872\n",
            "Epoch 169 : Train loss 3.767413714900613, validation loss 7.960728645324707\n",
            "Complete prediction MSE : 0.0013620401432162506\n",
            "Epoch 170 : Train loss 3.767158968374133, validation loss 7.937726974487305\n",
            "Complete prediction MSE : 0.0014004331067856697\n",
            "Epoch 171 : Train loss 3.76665072189644, validation loss 7.9106221199035645\n",
            "Complete prediction MSE : 0.0014077428140618904\n",
            "Epoch 172 : Train loss 3.757267417386174, validation loss 7.745858669281006\n",
            "Complete prediction MSE : 0.0015286812142426068\n",
            "Epoch 173 : Train loss 3.7627554908394814, validation loss 7.81000280380249\n",
            "Complete prediction MSE : 0.0015049170623806136\n",
            "Epoch 174 : Train loss 3.7504593855701387, validation loss 7.691410064697266\n",
            "Complete prediction MSE : 0.0013910450243318463\n",
            "Epoch 175 : Train loss 3.755744776688516, validation loss 7.884319305419922\n",
            "Complete prediction MSE : 0.0014482774772526807\n",
            "Epoch 176 : Train loss 3.751046888064593, validation loss 8.045248031616211\n",
            "Complete prediction MSE : 0.0014041859793399046\n",
            "Epoch 177 : Train loss 3.7457396164536476, validation loss 7.919493675231934\n",
            "Complete prediction MSE : 0.0014593930997673183\n",
            "Epoch 178 : Train loss 3.7438331758603454, validation loss 8.049230575561523\n",
            "Complete prediction MSE : 0.0012521526115037384\n",
            "Saving model\n",
            "Epoch 179 : Train loss 3.744357037357986, validation loss 7.661660194396973\n",
            "Complete prediction MSE : 0.00145244471003236\n",
            "Epoch 180 : Train loss 3.7385670277290046, validation loss 7.992214202880859\n",
            "Complete prediction MSE : 0.0014227590674028752\n",
            "Epoch 181 : Train loss 3.738560603465885, validation loss 7.9352216720581055\n",
            "Complete prediction MSE : 0.0012912780089576186\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e2993942211d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m#scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnb_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "nb_seeds = 5\n",
        "for seed in range(nb_seeds):\n",
        "  torch.manual_seed(seed)\n",
        "  model = KoopmanAE.KoopmanAE(20, [512,256,32], device=device).to(device)\n",
        "  print(f'Training model with seed {seed}')\n",
        "  epochs = 500\n",
        "  opt = model.configure_optimizers(lr=1e-3)\n",
        "  #opt = model.configure_optimizers(lr=1e-3, weight_decay=1e-6) # With weight decay\n",
        "  max_patience = 50\n",
        "  patience = 0\n",
        "  time_span = 100\n",
        "  alpha = 0\n",
        "  lamda = 100.\n",
        "  model.best_epoch, model.best_val = 0, 1e15\n",
        "  last_train_index = 53\n",
        "  model.train_losses = []\n",
        "  model.val_losses = []\n",
        "  model.val_losses2 = []\n",
        "  model.val_losses3 = []\n",
        "  starting_point = 0\n",
        "  loss_every = 1\n",
        "\n",
        "  for epoch in range(epochs+1) :\n",
        "    if patience >= max_patience:\n",
        "      print('Early stopping due to no more improvement')\n",
        "      break\n",
        "    epoch_loss = 0\n",
        "    epoch_val_loss = 0\n",
        "    model.train()\n",
        "    for batch in range(nb_batches) :\n",
        "      opt.zero_grad()\n",
        "      x0 = state_batches[0,batch].to(device)\n",
        "      gt = state_batches[:,batch].to(device)\n",
        "      latent_states = model.encode(gt)\n",
        "      #print(gt.shape, latent_states.shape, x0.shape)\n",
        "      xt, phis = model.forward_n_remember(x0, time_span)\n",
        "      phi_0 = phis[0]\n",
        "      loss = 0\n",
        "      # Prediction loss\n",
        "      #print(phis.shape, latent_states.shape, gt.shape)\n",
        "      loss += model.mse_loss(model.decode(phis), gt)\n",
        "      # Reconstruction loss\n",
        "      loss += model.mse_loss(model.decode(latent_states), gt)\n",
        "      # Linearity loss\n",
        "      loss += model.mse_loss(phis, latent_states)\n",
        "      # Orthogonality loss\n",
        "      loss += lamda * model.mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      epoch_loss += loss.detach().item()\n",
        "    #scheduler.step()\n",
        "    epoch_loss /= nb_batches\n",
        "    model.train_losses.append(epoch_loss)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    x0 = states_val[0].to(device)\n",
        "    gt = states_val.to(device)\n",
        "    latent_states = model.encode(states_val.to(device))\n",
        "    xt, phis = model.forward_n_remember(x0, time_span)\n",
        "    phi_0 = phis[0]\n",
        "    loss = 0\n",
        "    # Prediction loss\n",
        "    val_loss += model.mse_loss(model.decode(phis), gt)\n",
        "    # Reconstruction loss\n",
        "    val_loss += model.mse_loss(model.decode(latent_states), gt)\n",
        "    # Linearity loss\n",
        "    val_loss += model.mse_loss(phis, latent_states)\n",
        "    # Orthogonality loss\n",
        "    val_loss += lamda * model.mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "    model.val_losses2.append(val_loss.item())\n",
        "    #epoch_val_loss = val_loss.item()\n",
        "\n",
        "    whole_predictions = np.zeros((data_small.shape[0]-101, data_small.shape[1]//10, data_small.shape[2], data_small.shape[3]))\n",
        "    for column in range(data_small.shape[1] // 10) :\n",
        "      states = torch.Tensor(data_small[1:,10*column]).to(device)\n",
        "      states = torch.cat([states, states - torch.Tensor(data_small[:-1,10*column]).to(device)], dim=2) # Add derivatives\n",
        "      predictions, phis = model.forward_n_remember(states[starting_point],241)\n",
        "      #whole_predictions[starting_point:, column] = predictions[:342-starting_point,:10].cpu().detach()\n",
        "      decoded = model.decode(phis)\n",
        "      whole_predictions[starting_point:, column] = decoded[:whole_predictions.shape[0]-starting_point,:,:10].cpu().detach()\n",
        "\n",
        "    val_loss3 = np.mean((data_small[starting_point+1:starting_point+243,::10] - whole_predictions)[starting_point:] **2)\n",
        "    model.val_losses3.append(val_loss3.item())\n",
        "    epoch_val_loss = val_loss3.item()\n",
        "    if epoch % loss_every == 0 :\n",
        "      print(f\"Epoch {epoch+1} : Train loss {model.train_losses[-1]}, validation loss {model.val_losses2[-1]}\")\n",
        "      print(f\"Complete prediction MSE : {model.val_losses3[-1]}\")\n",
        "    if epoch_val_loss < model.best_val : # Save the model parameters\n",
        "      model.best_val = epoch_val_loss\n",
        "      model.best_epoch = epoch\n",
        "      torch.save(model.state_dict(), models_path+f'best_model_{seed}.pt')\n",
        "      torch.save(model.K, models_path+f'best_K_{seed}.pt')\n",
        "      patience = 0\n",
        "      print('Saving model')\n",
        "    else:\n",
        "      patience += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16a6ckR6fQQJ"
      },
      "source": [
        "# IKAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk6SqFIgfdVb"
      },
      "outputs": [],
      "source": [
        "model = IKAE.IKAE(input_dim=20, hidden_dim=512, n_layers_encoder=6, positive_nonlin=nn.Softplus(), flow='RNVP', device=device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GonetAiBqcy5",
        "outputId": "26e4a6ec-df48-46eb-feb3-58e4aa722154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 32316\n",
            "IKAE(\n",
            "  (positive_nonlin): Softplus(beta=1.0, threshold=20.0)\n",
            "  (invertible_encoder): stacked_NICE(\n",
            "    (bijectors): ModuleList(\n",
            "      (0-5): 6 x NICE(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=10, out_features=256, bias=True)\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "model = IKAE.IKAE(input_dim=20, hidden_dim=256, n_layers_encoder=6, positive_nonlin=nn.Softplus(), flow='NICE', device=device).to(device)\n",
        "\n",
        "print(f\"Number of parameters: {count_parameters(model)}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZvRs9j97XuSc",
        "outputId": "6d067ef4-1aa4-434e-c3fd-86eb265782a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 0\n",
            "Epoch 1 : Train loss 37.014617839828134, validation loss 20.245361328125\n",
            "Complete prediction MSE : 0.0037657297953353577\n",
            "Saving model\n",
            "Epoch 2 : Train loss 16.711873963475227, validation loss 19.921512603759766\n",
            "Complete prediction MSE : 0.004068091678733972\n",
            "Epoch 3 : Train loss 14.605594091117382, validation loss 13.90436840057373\n",
            "Complete prediction MSE : 0.0032485510468282888\n",
            "Saving model\n",
            "Epoch 4 : Train loss 14.230510007590055, validation loss 10.763667106628418\n",
            "Complete prediction MSE : 0.0026631838362406444\n",
            "Saving model\n",
            "Epoch 5 : Train loss 12.813452452421188, validation loss 9.88741683959961\n",
            "Complete prediction MSE : 0.002544638098104507\n",
            "Saving model\n",
            "Epoch 6 : Train loss 12.193345600739121, validation loss 9.983470916748047\n",
            "Complete prediction MSE : 0.003826228240275347\n",
            "Epoch 7 : Train loss 12.126866331323981, validation loss 10.23216724395752\n",
            "Complete prediction MSE : 0.0026522661456572735\n",
            "Epoch 8 : Train loss 11.963246000930667, validation loss 9.410883903503418\n",
            "Complete prediction MSE : 0.0025563000589766288\n",
            "Epoch 9 : Train loss 11.246774166822433, validation loss 11.079894065856934\n",
            "Complete prediction MSE : 0.002824421448396298\n",
            "Epoch 10 : Train loss 23.818382423371077, validation loss 14.427412033081055\n",
            "Complete prediction MSE : 0.0028356820128139525\n",
            "Epoch 11 : Train loss 13.824182512238622, validation loss 12.627666473388672\n",
            "Complete prediction MSE : 0.0028005038851057376\n",
            "Epoch 12 : Train loss 12.028085833415389, validation loss 11.804964065551758\n",
            "Complete prediction MSE : 0.002944585963583508\n",
            "Epoch 13 : Train loss 11.304259968921542, validation loss 9.527009963989258\n",
            "Complete prediction MSE : 0.003078509682450923\n",
            "Epoch 14 : Train loss 10.731407906860113, validation loss 10.692422866821289\n",
            "Complete prediction MSE : 0.0037905489524909263\n",
            "Epoch 15 : Train loss 10.53177840448916, validation loss 10.531732559204102\n",
            "Complete prediction MSE : 0.003149661121899934\n",
            "Epoch 16 : Train loss 10.135988764464855, validation loss 15.669917106628418\n",
            "Complete prediction MSE : 0.0027900775576010306\n",
            "Epoch 17 : Train loss 10.192450378090143, validation loss 9.752453804016113\n",
            "Complete prediction MSE : 0.00274360026928939\n",
            "Epoch 18 : Train loss 9.825485529378057, validation loss 10.633068084716797\n",
            "Complete prediction MSE : 0.0035524135336079117\n",
            "Epoch 19 : Train loss 9.645806630142033, validation loss 10.24410629272461\n",
            "Complete prediction MSE : 0.003436793187845101\n",
            "Epoch 20 : Train loss 9.599796046502888, validation loss 9.82693862915039\n",
            "Complete prediction MSE : 0.0036691655458454685\n",
            "Epoch 21 : Train loss 9.36819173861295, validation loss 10.159489631652832\n",
            "Complete prediction MSE : 0.003627130197030581\n",
            "Epoch 22 : Train loss 9.187816188670695, validation loss 9.758247375488281\n",
            "Complete prediction MSE : 0.0035537147484594506\n",
            "Epoch 23 : Train loss 9.034607835114002, validation loss 9.63437557220459\n",
            "Complete prediction MSE : 0.003618480417841221\n",
            "Epoch 24 : Train loss 8.870963487774134, validation loss 9.4359130859375\n",
            "Complete prediction MSE : 0.002968084559346485\n",
            "Epoch 25 : Train loss 8.826744602061808, validation loss 10.374253273010254\n",
            "Complete prediction MSE : 0.0034474317794840744\n",
            "Epoch 26 : Train loss 9.219783717766404, validation loss 9.90981388092041\n",
            "Complete prediction MSE : 0.003439332400513298\n",
            "Epoch 27 : Train loss 8.50086178816855, validation loss 9.520445823669434\n",
            "Complete prediction MSE : 0.0025254142032581296\n",
            "Saving model\n",
            "Epoch 28 : Train loss 8.504889735020697, validation loss 9.511266708374023\n",
            "Complete prediction MSE : 0.002813888886448994\n",
            "Epoch 29 : Train loss 9.520800130441785, validation loss 8.828349113464355\n",
            "Complete prediction MSE : 0.003024557823673926\n",
            "Epoch 30 : Train loss 8.214178475551307, validation loss 8.799786567687988\n",
            "Complete prediction MSE : 0.003028699738953276\n",
            "Epoch 31 : Train loss 8.202998449094594, validation loss 8.610541343688965\n",
            "Complete prediction MSE : 0.0028784192461585203\n",
            "Epoch 32 : Train loss 8.133443943224847, validation loss 8.534272193908691\n",
            "Complete prediction MSE : 0.002977524949204423\n",
            "Epoch 33 : Train loss 8.268279157578945, validation loss 8.95812702178955\n",
            "Complete prediction MSE : 0.0034210369891477534\n",
            "Epoch 34 : Train loss 7.993011301383376, validation loss 8.928130149841309\n",
            "Complete prediction MSE : 0.0026000528165356536\n",
            "Epoch 35 : Train loss 7.887137625366449, validation loss 9.073534965515137\n",
            "Complete prediction MSE : 0.0026454707501076665\n",
            "Epoch 36 : Train loss 7.86288895085454, validation loss 8.827253341674805\n",
            "Complete prediction MSE : 0.0026202010529975768\n",
            "Epoch 37 : Train loss 7.776344353333116, validation loss 8.73153018951416\n",
            "Complete prediction MSE : 0.002800830998509116\n",
            "Epoch 38 : Train loss 7.746148327365518, validation loss 9.297209739685059\n",
            "Complete prediction MSE : 0.0025419445381169277\n",
            "Epoch 39 : Train loss 7.621113026514649, validation loss 8.725001335144043\n",
            "Complete prediction MSE : 0.0025172048885892654\n",
            "Saving model\n",
            "Epoch 40 : Train loss 7.612713583745062, validation loss 9.480144500732422\n",
            "Complete prediction MSE : 0.002493039163825518\n",
            "Saving model\n",
            "Epoch 41 : Train loss 7.522387157194316, validation loss 9.062657356262207\n",
            "Complete prediction MSE : 0.002906658348392492\n",
            "Epoch 42 : Train loss 7.524193896912038, validation loss 9.020500183105469\n",
            "Complete prediction MSE : 0.002381203193332404\n",
            "Saving model\n",
            "Epoch 43 : Train loss 7.396322147920728, validation loss 9.09793472290039\n",
            "Complete prediction MSE : 0.002659247112780919\n",
            "Epoch 44 : Train loss 7.310787175782025, validation loss 9.394816398620605\n",
            "Complete prediction MSE : 0.0024806075236438897\n",
            "Epoch 45 : Train loss 7.2996555753052235, validation loss 9.90424919128418\n",
            "Complete prediction MSE : 0.002398471214013439\n",
            "Epoch 46 : Train loss 7.207549140788615, validation loss 8.716614723205566\n",
            "Complete prediction MSE : 0.002330474338216727\n",
            "Saving model\n",
            "Epoch 47 : Train loss 7.174477292224765, validation loss 8.672356605529785\n",
            "Complete prediction MSE : 0.0023332245000543214\n",
            "Epoch 48 : Train loss 7.133555886335671, validation loss 8.9620943069458\n",
            "Complete prediction MSE : 0.002301194231914897\n",
            "Saving model\n",
            "Epoch 49 : Train loss 7.096182403154671, validation loss 8.770345687866211\n",
            "Complete prediction MSE : 0.002470077121966377\n",
            "Epoch 50 : Train loss 7.063011946156621, validation loss 8.946533203125\n",
            "Complete prediction MSE : 0.0025894538626031246\n",
            "Epoch 51 : Train loss 6.947015557438135, validation loss 9.012861251831055\n",
            "Complete prediction MSE : 0.002569324349738291\n",
            "Epoch 52 : Train loss 6.928768469020724, validation loss 9.256152153015137\n",
            "Complete prediction MSE : 0.0023422214749153213\n",
            "Epoch 53 : Train loss 6.896461120806634, validation loss 8.682931900024414\n",
            "Complete prediction MSE : 0.002091725692571099\n",
            "Saving model\n",
            "Epoch 54 : Train loss 6.78980696387589, validation loss 9.170805931091309\n",
            "Complete prediction MSE : 0.0020528314569822517\n",
            "Saving model\n",
            "Epoch 55 : Train loss 6.7975236074998975, validation loss 9.087462425231934\n",
            "Complete prediction MSE : 0.0020298285009075884\n",
            "Saving model\n",
            "Epoch 56 : Train loss 6.706203727051616, validation loss 9.398502349853516\n",
            "Complete prediction MSE : 0.0022909571768201424\n",
            "Epoch 57 : Train loss 6.737218061462045, validation loss 9.195164680480957\n",
            "Complete prediction MSE : 0.0024282629684549105\n",
            "Epoch 58 : Train loss 6.666519344784319, validation loss 9.08990478515625\n",
            "Complete prediction MSE : 0.0019031143216506037\n",
            "Saving model\n",
            "Epoch 59 : Train loss 6.575421833433211, validation loss 9.466787338256836\n",
            "Complete prediction MSE : 0.0019954418950210136\n",
            "Epoch 60 : Train loss 6.568794843740761, validation loss 8.97897720336914\n",
            "Complete prediction MSE : 0.001970462879344326\n",
            "Epoch 61 : Train loss 6.531164082698524, validation loss 8.91603946685791\n",
            "Complete prediction MSE : 0.001943336491357404\n",
            "Epoch 62 : Train loss 6.475339804776013, validation loss 9.2454195022583\n",
            "Complete prediction MSE : 0.0019061841610128073\n",
            "Epoch 63 : Train loss 6.446952121332288, validation loss 8.232418060302734\n",
            "Complete prediction MSE : 0.0018516367490055698\n",
            "Saving model\n",
            "Epoch 64 : Train loss 6.439277556724846, validation loss 8.887275695800781\n",
            "Complete prediction MSE : 0.0019220709399685053\n",
            "Epoch 65 : Train loss 6.376819416880608, validation loss 8.483692169189453\n",
            "Complete prediction MSE : 0.0018244522743948164\n",
            "Saving model\n",
            "Epoch 66 : Train loss 6.3202187968418, validation loss 8.950788497924805\n",
            "Complete prediction MSE : 0.0019049937306722998\n",
            "Epoch 67 : Train loss 6.306462203152478, validation loss 8.652722358703613\n",
            "Complete prediction MSE : 0.0018002906152540933\n",
            "Saving model\n",
            "Epoch 68 : Train loss 6.2615767465904355, validation loss 9.095191955566406\n",
            "Complete prediction MSE : 0.0018188277869025484\n",
            "Epoch 69 : Train loss 6.225164549425244, validation loss 8.436750411987305\n",
            "Complete prediction MSE : 0.0017321920591326914\n",
            "Saving model\n",
            "Epoch 70 : Train loss 6.262655152007937, validation loss 8.703866958618164\n",
            "Complete prediction MSE : 0.0018351347811615421\n",
            "Epoch 71 : Train loss 6.155951661989093, validation loss 8.833333969116211\n",
            "Complete prediction MSE : 0.001681030749707345\n",
            "Saving model\n",
            "Epoch 72 : Train loss 6.150452461093664, validation loss 8.188830375671387\n",
            "Complete prediction MSE : 0.0016834342644915562\n",
            "Epoch 73 : Train loss 6.1277716141194105, validation loss 8.731850624084473\n",
            "Complete prediction MSE : 0.0016994472756660965\n",
            "Epoch 74 : Train loss 6.068682438693941, validation loss 8.626250267028809\n",
            "Complete prediction MSE : 0.0015976444218369756\n",
            "Saving model\n",
            "Epoch 75 : Train loss 6.043781138956547, validation loss 8.242115020751953\n",
            "Complete prediction MSE : 0.001626649284314575\n",
            "Epoch 76 : Train loss 6.016539946198463, validation loss 8.291260719299316\n",
            "Complete prediction MSE : 0.0016642323365800055\n",
            "Epoch 77 : Train loss 6.024746688082814, validation loss 8.836743354797363\n",
            "Complete prediction MSE : 0.0016191611299729751\n",
            "Epoch 78 : Train loss 5.983650070615113, validation loss 7.9350738525390625\n",
            "Complete prediction MSE : 0.0016555932786483307\n",
            "Epoch 79 : Train loss 5.933073633350432, validation loss 8.762215614318848\n",
            "Complete prediction MSE : 0.0017392463678473744\n",
            "Epoch 80 : Train loss 5.946932912804186, validation loss 8.339606285095215\n",
            "Complete prediction MSE : 0.0016456139466801613\n",
            "Epoch 81 : Train loss 5.9063353557139635, validation loss 8.4984712600708\n",
            "Complete prediction MSE : 0.001674012180230616\n",
            "Epoch 82 : Train loss 5.8887606002390385, validation loss 8.258621215820312\n",
            "Complete prediction MSE : 0.0018173190689902037\n",
            "Epoch 83 : Train loss 5.8618529019877315, validation loss 8.538768768310547\n",
            "Complete prediction MSE : 0.0019371350281164814\n",
            "Epoch 84 : Train loss 5.836685071699321, validation loss 7.905609607696533\n",
            "Complete prediction MSE : 0.0018077936749911654\n",
            "Epoch 85 : Train loss 5.811730591580272, validation loss 9.705742835998535\n",
            "Complete prediction MSE : 0.0018103538888954436\n",
            "Epoch 86 : Train loss 5.784944248385727, validation loss 8.628210067749023\n",
            "Complete prediction MSE : 0.0017091193374845753\n",
            "Epoch 87 : Train loss 5.756245375610888, validation loss 9.340524673461914\n",
            "Complete prediction MSE : 0.0017459530656777603\n",
            "Epoch 88 : Train loss 5.784282699227333, validation loss 8.866838455200195\n",
            "Complete prediction MSE : 0.0017366343315977284\n",
            "Epoch 89 : Train loss 5.710882348008454, validation loss 8.82280445098877\n",
            "Complete prediction MSE : 0.0019586998480822784\n",
            "Epoch 90 : Train loss 5.748566502705216, validation loss 8.780584335327148\n",
            "Complete prediction MSE : 0.001627883300235803\n",
            "Epoch 91 : Train loss 5.7112170252949, validation loss 9.121395111083984\n",
            "Complete prediction MSE : 0.0017244381742639381\n",
            "Epoch 92 : Train loss 5.702343387529254, validation loss 9.445873260498047\n",
            "Complete prediction MSE : 0.0017703079868754308\n",
            "Epoch 93 : Train loss 5.687369968742132, validation loss 8.242355346679688\n",
            "Complete prediction MSE : 0.0017742119814914375\n",
            "Epoch 94 : Train loss 5.666979480534792, validation loss 8.65352725982666\n",
            "Complete prediction MSE : 0.00183850264518868\n",
            "Epoch 95 : Train loss 5.629881816916168, validation loss 8.671148300170898\n",
            "Complete prediction MSE : 0.0016091398492478182\n",
            "Epoch 96 : Train loss 5.636193069629371, validation loss 8.564069747924805\n",
            "Complete prediction MSE : 0.0016278685379003273\n",
            "Epoch 97 : Train loss 5.609098117798567, validation loss 9.221721649169922\n",
            "Complete prediction MSE : 0.0015686531955583453\n",
            "Saving model\n",
            "Epoch 98 : Train loss 5.568661599420011, validation loss 8.373139381408691\n",
            "Complete prediction MSE : 0.0017187423757921455\n",
            "Epoch 99 : Train loss 5.576634363271296, validation loss 8.794758796691895\n",
            "Complete prediction MSE : 0.0018592513875305711\n",
            "Epoch 100 : Train loss 5.545867097564042, validation loss 9.25479793548584\n",
            "Complete prediction MSE : 0.001610020585384785\n",
            "Epoch 101 : Train loss 5.5842097122222185, validation loss 9.798537254333496\n",
            "Complete prediction MSE : 0.0014955746583176037\n",
            "Saving model\n",
            "Epoch 102 : Train loss 5.542583957314491, validation loss 9.097240447998047\n",
            "Complete prediction MSE : 0.0016287730222966734\n",
            "Epoch 103 : Train loss 5.549861785955727, validation loss 9.85809326171875\n",
            "Complete prediction MSE : 0.0016332333625719401\n",
            "Epoch 104 : Train loss 5.459308687597513, validation loss 9.905069351196289\n",
            "Complete prediction MSE : 0.0015910338811608617\n",
            "Epoch 105 : Train loss 5.4908456671983, validation loss 8.770772933959961\n",
            "Complete prediction MSE : 0.0016790410169215198\n",
            "Epoch 106 : Train loss 5.479584246873856, validation loss 9.64704704284668\n",
            "Complete prediction MSE : 0.001696021507255595\n",
            "Epoch 107 : Train loss 5.449241849593818, validation loss 9.704606056213379\n",
            "Complete prediction MSE : 0.001424726874631544\n",
            "Saving model\n",
            "Epoch 108 : Train loss 5.452149851247668, validation loss 9.46634292602539\n",
            "Complete prediction MSE : 0.0016031768850240857\n",
            "Epoch 109 : Train loss 5.471778737381101, validation loss 9.436820030212402\n",
            "Complete prediction MSE : 0.0015100153149000077\n",
            "Epoch 110 : Train loss 5.394206807948649, validation loss 8.792860984802246\n",
            "Complete prediction MSE : 0.0013839355244271657\n",
            "Saving model\n",
            "Epoch 111 : Train loss 5.4433380998671055, validation loss 9.542501449584961\n",
            "Complete prediction MSE : 0.0016829303920777056\n",
            "Epoch 112 : Train loss 5.377869230695069, validation loss 9.850537300109863\n",
            "Complete prediction MSE : 0.0015066435095368767\n",
            "Epoch 113 : Train loss 5.3902576472610235, validation loss 10.04052734375\n",
            "Complete prediction MSE : 0.0015168669571221265\n",
            "Epoch 114 : Train loss 5.3959195809438825, validation loss 9.744583129882812\n",
            "Complete prediction MSE : 0.0015153304775558367\n",
            "Epoch 115 : Train loss 5.335414697416127, validation loss 9.645368576049805\n",
            "Complete prediction MSE : 0.0015442379838191322\n",
            "Epoch 116 : Train loss 5.32910852599889, validation loss 10.511688232421875\n",
            "Complete prediction MSE : 0.001554562870025386\n",
            "Epoch 117 : Train loss 5.324927920475602, validation loss 10.226228713989258\n",
            "Complete prediction MSE : 0.0016081387093280705\n",
            "Epoch 118 : Train loss 5.310718908905983, validation loss 9.469735145568848\n",
            "Complete prediction MSE : 0.0016190390353185786\n",
            "Epoch 119 : Train loss 5.27005628682673, validation loss 9.805688858032227\n",
            "Complete prediction MSE : 0.0015641752040223454\n",
            "Epoch 120 : Train loss 5.26908546499908, validation loss 9.519125938415527\n",
            "Complete prediction MSE : 0.0016229075823749961\n",
            "Epoch 121 : Train loss 5.283264306373894, validation loss 9.423993110656738\n",
            "Complete prediction MSE : 0.0015514462978112747\n",
            "Epoch 122 : Train loss 5.26710407063365, validation loss 9.96572494506836\n",
            "Complete prediction MSE : 0.0016145022019588646\n",
            "Epoch 123 : Train loss 5.21535774692893, validation loss 9.852476119995117\n",
            "Complete prediction MSE : 0.0016781176699788196\n",
            "Epoch 124 : Train loss 5.214846357703209, validation loss 9.147268295288086\n",
            "Complete prediction MSE : 0.001612192247121043\n",
            "Epoch 125 : Train loss 5.212643180042505, validation loss 9.955144882202148\n",
            "Complete prediction MSE : 0.001537233926080438\n",
            "Epoch 126 : Train loss 5.182647026143968, validation loss 9.29599380493164\n",
            "Complete prediction MSE : 0.0015111781743885504\n",
            "Epoch 127 : Train loss 5.13999417796731, validation loss 9.129613876342773\n",
            "Complete prediction MSE : 0.001376220650132728\n",
            "Saving model\n",
            "Epoch 128 : Train loss 5.1618496757000685, validation loss 9.948122024536133\n",
            "Complete prediction MSE : 0.001610324231251311\n",
            "Epoch 129 : Train loss 5.156455392949283, validation loss 8.883960723876953\n",
            "Complete prediction MSE : 0.0013879992534621217\n",
            "Epoch 130 : Train loss 5.124787583947182, validation loss 9.343626022338867\n",
            "Complete prediction MSE : 0.0014201109227582164\n",
            "Epoch 131 : Train loss 5.171401012688875, validation loss 8.998885154724121\n",
            "Complete prediction MSE : 0.0014873758825439311\n",
            "Epoch 132 : Train loss 5.1433234214782715, validation loss 9.2149019241333\n",
            "Complete prediction MSE : 0.001373700561479232\n",
            "Saving model\n",
            "Epoch 133 : Train loss 5.1315374514088035, validation loss 9.819615364074707\n",
            "Complete prediction MSE : 0.0014069047069756565\n",
            "Epoch 134 : Train loss 5.0798361245542765, validation loss 9.390867233276367\n",
            "Complete prediction MSE : 0.0014069342430185088\n",
            "Epoch 135 : Train loss 5.10047114174813, validation loss 9.32577133178711\n",
            "Complete prediction MSE : 0.0013195104014663197\n",
            "Saving model\n",
            "Epoch 136 : Train loss 5.057960221543908, validation loss 9.380820274353027\n",
            "Complete prediction MSE : 0.0015146511538279425\n",
            "Epoch 137 : Train loss 5.0485111232846975, validation loss 9.409383773803711\n",
            "Complete prediction MSE : 0.001528914372334858\n",
            "Epoch 138 : Train loss 5.058666178025305, validation loss 9.165974617004395\n",
            "Complete prediction MSE : 0.0014277693719616461\n",
            "Epoch 139 : Train loss 5.059732500463724, validation loss 9.27975845336914\n",
            "Complete prediction MSE : 0.0014374585442670268\n",
            "Epoch 140 : Train loss 5.042520137503743, validation loss 9.766948699951172\n",
            "Complete prediction MSE : 0.0014949715603425602\n",
            "Epoch 141 : Train loss 5.06422106269747, validation loss 8.858250617980957\n",
            "Complete prediction MSE : 0.0013506216617113192\n",
            "Epoch 142 : Train loss 5.002577411942184, validation loss 9.916569709777832\n",
            "Complete prediction MSE : 0.0014855007096991216\n",
            "Epoch 143 : Train loss 5.003471342846751, validation loss 9.511689186096191\n",
            "Complete prediction MSE : 0.0013880758583285034\n",
            "Epoch 144 : Train loss 4.973402829840779, validation loss 9.805978775024414\n",
            "Complete prediction MSE : 0.0015953874998874517\n",
            "Epoch 145 : Train loss 5.011755678802729, validation loss 9.10175609588623\n",
            "Complete prediction MSE : 0.0014425266127412243\n",
            "Epoch 146 : Train loss 4.965391268022358, validation loss 9.608094215393066\n",
            "Complete prediction MSE : 0.0013845028288009757\n",
            "Epoch 147 : Train loss 5.016104023903608, validation loss 9.861929893493652\n",
            "Complete prediction MSE : 0.0015047337951038149\n",
            "Epoch 148 : Train loss 4.9749202337116, validation loss 9.498191833496094\n",
            "Complete prediction MSE : 0.0013970449782019505\n",
            "Epoch 149 : Train loss 4.9263475043699145, validation loss 9.940520286560059\n",
            "Complete prediction MSE : 0.0015044302655676128\n",
            "Epoch 150 : Train loss 4.90358027163893, validation loss 9.126432418823242\n",
            "Complete prediction MSE : 0.0017262921047360702\n",
            "Epoch 151 : Train loss 4.940996379591525, validation loss 9.492289543151855\n",
            "Complete prediction MSE : 0.0013154469412023683\n",
            "Saving model\n",
            "Epoch 152 : Train loss 4.899258595891297, validation loss 9.201923370361328\n",
            "Complete prediction MSE : 0.0013519999193065718\n",
            "Epoch 153 : Train loss 4.895026868209243, validation loss 9.361448287963867\n",
            "Complete prediction MSE : 0.001409289136808553\n",
            "Epoch 154 : Train loss 4.905044411309063, validation loss 9.035993576049805\n",
            "Complete prediction MSE : 0.0013425373541157426\n",
            "Epoch 155 : Train loss 4.929633002728224, validation loss 9.060376167297363\n",
            "Complete prediction MSE : 0.001386439261885996\n",
            "Epoch 156 : Train loss 4.910885929130018, validation loss 9.344286918640137\n",
            "Complete prediction MSE : 0.0012278068586184636\n",
            "Saving model\n",
            "Epoch 157 : Train loss 4.8775816252455115, validation loss 9.617620468139648\n",
            "Complete prediction MSE : 0.001553368625892402\n",
            "Epoch 158 : Train loss 4.872631663456559, validation loss 9.499542236328125\n",
            "Complete prediction MSE : 0.0015733956889245268\n",
            "Epoch 159 : Train loss 4.937300715595484, validation loss 8.79443645477295\n",
            "Complete prediction MSE : 0.0014140610400148418\n",
            "Epoch 160 : Train loss 4.891171610914171, validation loss 9.828959465026855\n",
            "Complete prediction MSE : 0.0016217853286358654\n",
            "Epoch 161 : Train loss 4.906858119182289, validation loss 10.939311027526855\n",
            "Complete prediction MSE : 0.0014692561090322294\n",
            "Epoch 162 : Train loss 4.827296801842749, validation loss 9.702471733093262\n",
            "Complete prediction MSE : 0.0014449039524878496\n",
            "Epoch 163 : Train loss 4.859854467213154, validation loss 9.220614433288574\n",
            "Complete prediction MSE : 0.001494561898053704\n",
            "Epoch 164 : Train loss 4.861438806168735, validation loss 9.367144584655762\n",
            "Complete prediction MSE : 0.0013958974779475202\n",
            "Epoch 165 : Train loss 4.799298592843115, validation loss 8.965768814086914\n",
            "Complete prediction MSE : 0.0014157661800433478\n",
            "Epoch 166 : Train loss 4.847226069308817, validation loss 10.770244598388672\n",
            "Complete prediction MSE : 0.0014781070552745002\n",
            "Epoch 167 : Train loss 4.837664559483528, validation loss 9.395153045654297\n",
            "Complete prediction MSE : 0.0013785436532807555\n",
            "Epoch 168 : Train loss 4.844923640601337, validation loss 9.345170021057129\n",
            "Complete prediction MSE : 0.0015750391498251448\n",
            "Epoch 169 : Train loss 4.781591615639627, validation loss 9.954916000366211\n",
            "Complete prediction MSE : 0.001385470610961189\n",
            "Epoch 170 : Train loss 4.80498216021806, validation loss 9.368917465209961\n",
            "Complete prediction MSE : 0.0013142334501788108\n",
            "Epoch 171 : Train loss 4.784490664489567, validation loss 9.321463584899902\n",
            "Complete prediction MSE : 0.0016096214336260802\n",
            "Epoch 172 : Train loss 4.779435764066875, validation loss 10.136975288391113\n",
            "Complete prediction MSE : 0.001561299928082906\n",
            "Epoch 173 : Train loss 4.7748104482889175, validation loss 10.14985179901123\n",
            "Complete prediction MSE : 0.0011785163091290775\n",
            "Saving model\n",
            "Epoch 174 : Train loss 4.788002886809409, validation loss 9.642251968383789\n",
            "Complete prediction MSE : 0.0012939549908240553\n",
            "Epoch 175 : Train loss 4.815615667961538, validation loss 8.454033851623535\n",
            "Complete prediction MSE : 0.0015354082034226375\n",
            "Epoch 176 : Train loss 4.770037020556629, validation loss 10.421213150024414\n",
            "Complete prediction MSE : 0.0016474416640807276\n",
            "Epoch 177 : Train loss 4.777960645966232, validation loss 8.577454566955566\n",
            "Complete prediction MSE : 0.0016645772059325798\n",
            "Epoch 178 : Train loss 4.77301680855453, validation loss 9.757287979125977\n",
            "Complete prediction MSE : 0.0014879403832564312\n",
            "Epoch 179 : Train loss 4.752694963477552, validation loss 9.478900909423828\n",
            "Complete prediction MSE : 0.0015848584163937883\n",
            "Epoch 180 : Train loss 4.710708473809063, validation loss 9.591090202331543\n",
            "Complete prediction MSE : 0.0013197795668683256\n",
            "Epoch 181 : Train loss 4.752602763473988, validation loss 9.075709342956543\n",
            "Complete prediction MSE : 0.0014341819432255579\n",
            "Epoch 182 : Train loss 4.77253773342818, validation loss 9.594221115112305\n",
            "Complete prediction MSE : 0.0014631091901370673\n",
            "Epoch 183 : Train loss 4.7421771213412285, validation loss 9.030318260192871\n",
            "Complete prediction MSE : 0.0016007694749857594\n",
            "Epoch 184 : Train loss 4.721527496352792, validation loss 8.970961570739746\n",
            "Complete prediction MSE : 0.001616225132660579\n",
            "Epoch 185 : Train loss 4.692770127207041, validation loss 9.455926895141602\n",
            "Complete prediction MSE : 0.0015334025769882876\n",
            "Epoch 186 : Train loss 4.7458587465807796, validation loss 9.64267349243164\n",
            "Complete prediction MSE : 0.0014710807778202445\n",
            "Epoch 187 : Train loss 4.6549156829714775, validation loss 8.840119361877441\n",
            "Complete prediction MSE : 0.0016692202967239268\n",
            "Epoch 188 : Train loss 4.719991074874997, validation loss 8.951678276062012\n",
            "Complete prediction MSE : 0.0015900846888928552\n",
            "Epoch 189 : Train loss 4.677774454466999, validation loss 8.829129219055176\n",
            "Complete prediction MSE : 0.001559354640357232\n",
            "Epoch 190 : Train loss 4.74078169092536, validation loss 8.767735481262207\n",
            "Complete prediction MSE : 0.001534361380238909\n",
            "Epoch 191 : Train loss 4.669726352207363, validation loss 9.466582298278809\n",
            "Complete prediction MSE : 0.0014677762522560653\n",
            "Epoch 192 : Train loss 4.683612930588424, validation loss 9.03812313079834\n",
            "Complete prediction MSE : 0.0014896782098062704\n",
            "Epoch 193 : Train loss 4.645094625651836, validation loss 9.131340980529785\n",
            "Complete prediction MSE : 0.0013368513625231354\n",
            "Epoch 194 : Train loss 4.692512243054807, validation loss 10.03285026550293\n",
            "Complete prediction MSE : 0.0014612862767599652\n",
            "Epoch 195 : Train loss 4.646686455234885, validation loss 8.895505905151367\n",
            "Complete prediction MSE : 0.0013670541005157645\n",
            "Epoch 196 : Train loss 4.656991105061024, validation loss 8.880744934082031\n",
            "Complete prediction MSE : 0.001352744922481736\n",
            "Epoch 197 : Train loss 4.639098348096013, validation loss 8.501008987426758\n",
            "Complete prediction MSE : 0.0014028985717309483\n",
            "Epoch 198 : Train loss 4.666967197787017, validation loss 8.838774681091309\n",
            "Complete prediction MSE : 0.0014509641367356954\n",
            "Epoch 199 : Train loss 4.6689010499976575, validation loss 8.961041450500488\n",
            "Complete prediction MSE : 0.0015476863425966441\n",
            "Epoch 200 : Train loss 4.607445895206183, validation loss 8.85018539428711\n",
            "Complete prediction MSE : 0.0015830655996560087\n",
            "Epoch 201 : Train loss 4.687530673108995, validation loss 9.882003784179688\n",
            "Complete prediction MSE : 0.0014460353384179458\n",
            "Epoch 202 : Train loss 4.647051049396396, validation loss 8.91972541809082\n",
            "Complete prediction MSE : 0.0013723402920837473\n",
            "Epoch 203 : Train loss 4.664986425545067, validation loss 9.144786834716797\n",
            "Complete prediction MSE : 0.0014765736797706114\n",
            "Epoch 204 : Train loss 4.638676573056728, validation loss 8.86115550994873\n",
            "Complete prediction MSE : 0.0015442714583592668\n",
            "Epoch 205 : Train loss 4.622282775118947, validation loss 9.203082084655762\n",
            "Complete prediction MSE : 0.0013329398343438186\n",
            "Epoch 206 : Train loss 4.616503296419978, validation loss 9.262407302856445\n",
            "Complete prediction MSE : 0.001638031006991427\n",
            "Epoch 207 : Train loss 4.595701210200787, validation loss 9.251233100891113\n",
            "Complete prediction MSE : 0.0016835994137535382\n",
            "Epoch 208 : Train loss 4.593345261644572, validation loss 8.765790939331055\n",
            "Complete prediction MSE : 0.0015064317943182827\n",
            "Epoch 209 : Train loss 4.590999132953584, validation loss 9.109942436218262\n",
            "Complete prediction MSE : 0.0014585196477240904\n",
            "Epoch 210 : Train loss 4.624262107536197, validation loss 9.05331802368164\n",
            "Complete prediction MSE : 0.0014176510492524758\n",
            "Epoch 211 : Train loss 4.632406589109451, validation loss 9.04605484008789\n",
            "Complete prediction MSE : 0.0014743936839319203\n",
            "Epoch 212 : Train loss 4.653196750674397, validation loss 8.694769859313965\n",
            "Complete prediction MSE : 0.0014397761399242478\n",
            "Epoch 213 : Train loss 4.584218239411712, validation loss 9.69111156463623\n",
            "Complete prediction MSE : 0.0014373273015380105\n",
            "Epoch 214 : Train loss 4.580966635141522, validation loss 9.266691207885742\n",
            "Complete prediction MSE : 0.0014987646630135582\n",
            "Epoch 215 : Train loss 4.5428648996166885, validation loss 9.34050464630127\n",
            "Complete prediction MSE : 0.0014046611926806472\n",
            "Epoch 216 : Train loss 4.563279813155532, validation loss 9.5166597366333\n",
            "Complete prediction MSE : 0.0014847452917801287\n",
            "Epoch 217 : Train loss 4.583351185079664, validation loss 9.179279327392578\n",
            "Complete prediction MSE : 0.0016200067410128507\n",
            "Epoch 218 : Train loss 4.591916206292808, validation loss 9.182907104492188\n",
            "Complete prediction MSE : 0.0013919478180878869\n",
            "Epoch 219 : Train loss 4.570545190013945, validation loss 8.724851608276367\n",
            "Complete prediction MSE : 0.0015194444229495274\n",
            "Epoch 220 : Train loss 4.565096518024802, validation loss 9.383902549743652\n",
            "Complete prediction MSE : 0.0013590286680181304\n",
            "Epoch 221 : Train loss 4.588512520771474, validation loss 9.527286529541016\n",
            "Complete prediction MSE : 0.0013583336279038855\n",
            "Epoch 222 : Train loss 4.562735194340348, validation loss 9.148077964782715\n",
            "Complete prediction MSE : 0.0013856338092562283\n",
            "Epoch 223 : Train loss 4.523488583043218, validation loss 9.933798789978027\n",
            "Complete prediction MSE : 0.0013129661200998075\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 1\n",
            "Epoch 1 : Train loss 34.12858534231782, validation loss 14.780783653259277\n",
            "Complete prediction MSE : 0.003064878956193735\n",
            "Saving model\n",
            "Epoch 2 : Train loss 15.28063092008233, validation loss 12.726273536682129\n",
            "Complete prediction MSE : 0.0028964462246556864\n",
            "Saving model\n",
            "Epoch 3 : Train loss 13.463026681914926, validation loss 11.119230270385742\n",
            "Complete prediction MSE : 0.0029112164634889667\n",
            "Epoch 4 : Train loss 12.732508771121502, validation loss 10.084293365478516\n",
            "Complete prediction MSE : 0.002697396768993035\n",
            "Saving model\n",
            "Epoch 5 : Train loss 12.090081077069044, validation loss 11.029687881469727\n",
            "Complete prediction MSE : 0.0028127931872335868\n",
            "Epoch 6 : Train loss 11.629034774377942, validation loss 10.636344909667969\n",
            "Complete prediction MSE : 0.003132877014055865\n",
            "Epoch 7 : Train loss 26.66305766068399, validation loss 18.008378982543945\n",
            "Complete prediction MSE : 0.003245033366398614\n",
            "Epoch 8 : Train loss 15.174546541646123, validation loss 12.779195785522461\n",
            "Complete prediction MSE : 0.002995345584424052\n",
            "Epoch 9 : Train loss 13.217552663758397, validation loss 11.328935623168945\n",
            "Complete prediction MSE : 0.0027900045404216966\n",
            "Epoch 10 : Train loss 12.003803499042988, validation loss 11.708057403564453\n",
            "Complete prediction MSE : 0.0029362674007655755\n",
            "Epoch 11 : Train loss 11.455574685707688, validation loss 11.207996368408203\n",
            "Complete prediction MSE : 0.002852255296500927\n",
            "Epoch 12 : Train loss 10.926418982446194, validation loss 10.538872718811035\n",
            "Complete prediction MSE : 0.0026693486193462537\n",
            "Saving model\n",
            "Epoch 13 : Train loss 10.680325547233224, validation loss 13.292598724365234\n",
            "Complete prediction MSE : 0.0031463456234789456\n",
            "Epoch 14 : Train loss 10.366435272619128, validation loss 12.173123359680176\n",
            "Complete prediction MSE : 0.002632239925404247\n",
            "Saving model\n",
            "Epoch 15 : Train loss 10.17455655708909, validation loss 10.208796501159668\n",
            "Complete prediction MSE : 0.0029436688275221337\n",
            "Epoch 16 : Train loss 9.97946230508387, validation loss 12.616243362426758\n",
            "Complete prediction MSE : 0.0027588067668463203\n",
            "Epoch 17 : Train loss 9.836158955469728, validation loss 12.048968315124512\n",
            "Complete prediction MSE : 0.0026494057131222788\n",
            "Epoch 18 : Train loss 20.671763451769948, validation loss 12.155930519104004\n",
            "Complete prediction MSE : 0.0026991481203143732\n",
            "Epoch 19 : Train loss 11.527539236471057, validation loss 12.156839370727539\n",
            "Complete prediction MSE : 0.00249943829443116\n",
            "Saving model\n",
            "Epoch 20 : Train loss 10.140944017097354, validation loss 10.410652160644531\n",
            "Complete prediction MSE : 0.0025372678265799527\n",
            "Epoch 21 : Train loss 9.651167761534452, validation loss 10.703944206237793\n",
            "Complete prediction MSE : 0.002471947365030727\n",
            "Saving model\n",
            "Epoch 22 : Train loss 9.423492427915335, validation loss 10.788986206054688\n",
            "Complete prediction MSE : 0.002529828202634534\n",
            "Epoch 23 : Train loss 9.2247826885432, validation loss 10.98410415649414\n",
            "Complete prediction MSE : 0.0026026191390730257\n",
            "Epoch 24 : Train loss 9.057078245095909, validation loss 11.112567901611328\n",
            "Complete prediction MSE : 0.0025966531205600823\n",
            "Epoch 25 : Train loss 8.942957580089569, validation loss 11.026535987854004\n",
            "Complete prediction MSE : 0.0028871501387003544\n",
            "Epoch 26 : Train loss 8.87615424580872, validation loss 10.150223731994629\n",
            "Complete prediction MSE : 0.0023800048504716413\n",
            "Saving model\n",
            "Epoch 27 : Train loss 8.717575689777732, validation loss 10.454401969909668\n",
            "Complete prediction MSE : 0.002534016404989694\n",
            "Epoch 28 : Train loss 8.585319609381258, validation loss 12.01781940460205\n",
            "Complete prediction MSE : 0.0027043599416382044\n",
            "Epoch 29 : Train loss 8.4819244928658, validation loss 10.368447303771973\n",
            "Complete prediction MSE : 0.0028767555781479414\n",
            "Epoch 30 : Train loss 8.321161000989377, validation loss 10.684099197387695\n",
            "Complete prediction MSE : 0.0031960315948844557\n",
            "Epoch 31 : Train loss 8.276100755669177, validation loss 9.802658081054688\n",
            "Complete prediction MSE : 0.0026973917249161574\n",
            "Epoch 32 : Train loss 8.139942390844226, validation loss 10.256632804870605\n",
            "Complete prediction MSE : 0.0025953584496661943\n",
            "Epoch 33 : Train loss 8.113258199766278, validation loss 10.547157287597656\n",
            "Complete prediction MSE : 0.00304865538315792\n",
            "Epoch 34 : Train loss 7.979096010327339, validation loss 9.367304801940918\n",
            "Complete prediction MSE : 0.002154461473791023\n",
            "Saving model\n",
            "Epoch 35 : Train loss 7.896911460906267, validation loss 10.609785079956055\n",
            "Complete prediction MSE : 0.002516490772703555\n",
            "Epoch 36 : Train loss 7.795041260309517, validation loss 10.33725643157959\n",
            "Complete prediction MSE : 0.0028078770851495804\n",
            "Epoch 37 : Train loss 7.7147638173773885, validation loss 9.817830085754395\n",
            "Complete prediction MSE : 0.0025298640799254713\n",
            "Epoch 38 : Train loss 7.648526274599135, validation loss 9.813255310058594\n",
            "Complete prediction MSE : 0.00241012920507216\n",
            "Epoch 39 : Train loss 7.535487120039761, validation loss 10.36814022064209\n",
            "Complete prediction MSE : 0.0024822820768730654\n",
            "Epoch 40 : Train loss 7.502822925336659, validation loss 8.740650177001953\n",
            "Complete prediction MSE : 0.002357679030499964\n",
            "Epoch 41 : Train loss 7.380953596904874, validation loss 9.06102466583252\n",
            "Complete prediction MSE : 0.0025303632518506713\n",
            "Epoch 42 : Train loss 7.365882765501738, validation loss 8.789766311645508\n",
            "Complete prediction MSE : 0.002472910489409496\n",
            "Epoch 43 : Train loss 7.310536566190422, validation loss 8.96118450164795\n",
            "Complete prediction MSE : 0.0027547415003999647\n",
            "Epoch 44 : Train loss 7.225505907088518, validation loss 8.437987327575684\n",
            "Complete prediction MSE : 0.0022904520706251907\n",
            "Epoch 45 : Train loss 7.198247054591775, validation loss 9.049786567687988\n",
            "Complete prediction MSE : 0.0021803392328164075\n",
            "Epoch 46 : Train loss 7.12723446264863, validation loss 9.17265796661377\n",
            "Complete prediction MSE : 0.002154084179693262\n",
            "Saving model\n",
            "Epoch 47 : Train loss 7.0393314035609365, validation loss 9.131054878234863\n",
            "Complete prediction MSE : 0.002334207063034768\n",
            "Epoch 48 : Train loss 6.998898619785905, validation loss 8.974639892578125\n",
            "Complete prediction MSE : 0.001978110919377565\n",
            "Saving model\n",
            "Epoch 49 : Train loss 6.985611915588379, validation loss 8.71707820892334\n",
            "Complete prediction MSE : 0.0020259725657234395\n",
            "Epoch 50 : Train loss 6.848412464372814, validation loss 8.944427490234375\n",
            "Complete prediction MSE : 0.0021728191609896538\n",
            "Epoch 51 : Train loss 6.849135274998844, validation loss 8.558327674865723\n",
            "Complete prediction MSE : 0.002517053426833049\n",
            "Epoch 52 : Train loss 6.776776756159961, validation loss 8.535222053527832\n",
            "Complete prediction MSE : 0.0021934474197300054\n",
            "Epoch 53 : Train loss 6.738778122700751, validation loss 8.634785652160645\n",
            "Complete prediction MSE : 0.002171603299459417\n",
            "Epoch 54 : Train loss 6.672730525024235, validation loss 8.454179763793945\n",
            "Complete prediction MSE : 0.0020783178800409894\n",
            "Epoch 55 : Train loss 6.641234565526247, validation loss 8.621988296508789\n",
            "Complete prediction MSE : 0.002075485150000424\n",
            "Epoch 56 : Train loss 6.591874479316175, validation loss 9.41151237487793\n",
            "Complete prediction MSE : 0.001998099014583263\n",
            "Epoch 57 : Train loss 6.569397112354636, validation loss 8.699963569641113\n",
            "Complete prediction MSE : 0.0020032834006208\n",
            "Epoch 58 : Train loss 6.492205834016204, validation loss 8.918848037719727\n",
            "Complete prediction MSE : 0.0019433011270374384\n",
            "Saving model\n",
            "Epoch 59 : Train loss 6.475497603416443, validation loss 8.645106315612793\n",
            "Complete prediction MSE : 0.0019205566094103697\n",
            "Saving model\n",
            "Epoch 60 : Train loss 6.45595679525286, validation loss 8.887207984924316\n",
            "Complete prediction MSE : 0.0021582278669722336\n",
            "Epoch 61 : Train loss 6.403528593480587, validation loss 8.635265350341797\n",
            "Complete prediction MSE : 0.0020281441763669804\n",
            "Epoch 62 : Train loss 6.345053373835981, validation loss 8.534195899963379\n",
            "Complete prediction MSE : 0.0020894944737904274\n",
            "Epoch 63 : Train loss 6.345328605733812, validation loss 8.737027168273926\n",
            "Complete prediction MSE : 0.0018449532765114874\n",
            "Saving model\n",
            "Epoch 64 : Train loss 6.299017844721675, validation loss 8.438613891601562\n",
            "Complete prediction MSE : 0.00197820068641412\n",
            "Epoch 65 : Train loss 6.2551237074658275, validation loss 8.373963356018066\n",
            "Complete prediction MSE : 0.002060154653183661\n",
            "Epoch 66 : Train loss 6.244483653455973, validation loss 8.586325645446777\n",
            "Complete prediction MSE : 0.0018675261289567019\n",
            "Epoch 67 : Train loss 6.196319562382996, validation loss 8.636363983154297\n",
            "Complete prediction MSE : 0.0019312601858204896\n",
            "Epoch 68 : Train loss 6.191462096758187, validation loss 8.387681007385254\n",
            "Complete prediction MSE : 0.001992372094769434\n",
            "Epoch 69 : Train loss 6.141655515879393, validation loss 8.691619873046875\n",
            "Complete prediction MSE : 0.0020543389005467203\n",
            "Epoch 70 : Train loss 6.088494136929512, validation loss 8.410859107971191\n",
            "Complete prediction MSE : 0.002027811776648563\n",
            "Epoch 71 : Train loss 6.073605357669294, validation loss 8.522292137145996\n",
            "Complete prediction MSE : 0.002060796523635268\n",
            "Epoch 72 : Train loss 6.039723717607558, validation loss 8.339174270629883\n",
            "Complete prediction MSE : 0.0020141326963878585\n",
            "Epoch 73 : Train loss 6.014951964840293, validation loss 8.722715377807617\n",
            "Complete prediction MSE : 0.002032840695342336\n",
            "Epoch 74 : Train loss 5.999356027692556, validation loss 8.447546005249023\n",
            "Complete prediction MSE : 0.0020008259737700896\n",
            "Epoch 75 : Train loss 5.960412723943591, validation loss 8.690115928649902\n",
            "Complete prediction MSE : 0.0019316688318030439\n",
            "Epoch 76 : Train loss 5.913843411952257, validation loss 8.591280937194824\n",
            "Complete prediction MSE : 0.0018050863048370358\n",
            "Saving model\n",
            "Epoch 77 : Train loss 5.895821592770517, validation loss 8.44101619720459\n",
            "Complete prediction MSE : 0.00191984764263963\n",
            "Epoch 78 : Train loss 5.90123257599771, validation loss 8.516404151916504\n",
            "Complete prediction MSE : 0.001950242912322657\n",
            "Epoch 79 : Train loss 5.820086515508592, validation loss 7.972234725952148\n",
            "Complete prediction MSE : 0.0018153678943378703\n",
            "Epoch 80 : Train loss 5.820931078866124, validation loss 8.372405052185059\n",
            "Complete prediction MSE : 0.001761109633868658\n",
            "Saving model\n",
            "Epoch 81 : Train loss 5.782159672118723, validation loss 9.118102073669434\n",
            "Complete prediction MSE : 0.0016176946145268411\n",
            "Saving model\n",
            "Epoch 82 : Train loss 5.750038501806557, validation loss 8.516134262084961\n",
            "Complete prediction MSE : 0.0016837756277401988\n",
            "Epoch 83 : Train loss 5.750546030700207, validation loss 8.504340171813965\n",
            "Complete prediction MSE : 0.0016565699890134854\n",
            "Epoch 84 : Train loss 5.724834704771638, validation loss 8.557366371154785\n",
            "Complete prediction MSE : 0.0016399509239532644\n",
            "Epoch 85 : Train loss 5.687743832357228, validation loss 8.756507873535156\n",
            "Complete prediction MSE : 0.0016575577743525615\n",
            "Epoch 86 : Train loss 5.658012671396136, validation loss 8.468361854553223\n",
            "Complete prediction MSE : 0.0016493683700653224\n",
            "Epoch 87 : Train loss 5.646141027100384, validation loss 8.835844039916992\n",
            "Complete prediction MSE : 0.0016894656205017318\n",
            "Epoch 88 : Train loss 5.637726293876767, validation loss 8.740656852722168\n",
            "Complete prediction MSE : 0.0016112283718271528\n",
            "Saving model\n",
            "Epoch 89 : Train loss 5.623628447763622, validation loss 8.505860328674316\n",
            "Complete prediction MSE : 0.001845119296142671\n",
            "Epoch 90 : Train loss 5.5945519069209695, validation loss 8.690567970275879\n",
            "Complete prediction MSE : 0.0016162002123086949\n",
            "Epoch 91 : Train loss 5.593534701503813, validation loss 8.838626861572266\n",
            "Complete prediction MSE : 0.001784225586704756\n",
            "Epoch 92 : Train loss 5.570871346630156, validation loss 8.441309928894043\n",
            "Complete prediction MSE : 0.001556730589657374\n",
            "Saving model\n",
            "Epoch 93 : Train loss 5.539985733106732, validation loss 8.678627967834473\n",
            "Complete prediction MSE : 0.0016267645211877244\n",
            "Epoch 94 : Train loss 5.510929091833532, validation loss 8.246148109436035\n",
            "Complete prediction MSE : 0.001744008103259958\n",
            "Epoch 95 : Train loss 5.484045796096325, validation loss 8.248127937316895\n",
            "Complete prediction MSE : 0.001526936830243917\n",
            "Saving model\n",
            "Epoch 96 : Train loss 5.479162455536425, validation loss 8.327192306518555\n",
            "Complete prediction MSE : 0.0016641710370677435\n",
            "Epoch 97 : Train loss 5.492817631922662, validation loss 8.290087699890137\n",
            "Complete prediction MSE : 0.001521573939143856\n",
            "Saving model\n",
            "Epoch 98 : Train loss 5.430780660361052, validation loss 8.570233345031738\n",
            "Complete prediction MSE : 0.0016921233005142422\n",
            "Epoch 99 : Train loss 5.4486962873488665, validation loss 8.541194915771484\n",
            "Complete prediction MSE : 0.0015263420643837863\n",
            "Epoch 100 : Train loss 5.42849696893245, validation loss 8.733901023864746\n",
            "Complete prediction MSE : 0.0017598156132513085\n",
            "Epoch 101 : Train loss 5.398463235236704, validation loss 8.88869857788086\n",
            "Complete prediction MSE : 0.0014490968195924527\n",
            "Saving model\n",
            "Epoch 102 : Train loss 5.362354706041515, validation loss 8.68930435180664\n",
            "Complete prediction MSE : 0.0014671996553752289\n",
            "Epoch 103 : Train loss 5.344335633330047, validation loss 8.915750503540039\n",
            "Complete prediction MSE : 0.0016502219249142308\n",
            "Epoch 104 : Train loss 5.37767830491066, validation loss 8.352564811706543\n",
            "Complete prediction MSE : 0.0014776274103821077\n",
            "Epoch 105 : Train loss 5.354247578419745, validation loss 8.788228034973145\n",
            "Complete prediction MSE : 0.0015800946536031302\n",
            "Epoch 106 : Train loss 5.326019308529794, validation loss 8.755441665649414\n",
            "Complete prediction MSE : 0.001404005341067236\n",
            "Saving model\n",
            "Epoch 107 : Train loss 5.343028036877513, validation loss 8.97132396697998\n",
            "Complete prediction MSE : 0.001386327718900805\n",
            "Saving model\n",
            "Epoch 108 : Train loss 5.274085979908705, validation loss 8.46655559539795\n",
            "Complete prediction MSE : 0.0014629130404060886\n",
            "Epoch 109 : Train loss 5.287272593006492, validation loss 8.707847595214844\n",
            "Complete prediction MSE : 0.0014662105659517693\n",
            "Epoch 110 : Train loss 5.283456852659583, validation loss 8.945472717285156\n",
            "Complete prediction MSE : 0.0016092950628910645\n",
            "Epoch 111 : Train loss 5.244349428452551, validation loss 8.946998596191406\n",
            "Complete prediction MSE : 0.0013895716439946118\n",
            "Epoch 112 : Train loss 5.2412506472319365, validation loss 8.814188957214355\n",
            "Complete prediction MSE : 0.001439348009436053\n",
            "Epoch 113 : Train loss 5.25336570572108, validation loss 9.01208209991455\n",
            "Complete prediction MSE : 0.0014866366348214074\n",
            "Epoch 114 : Train loss 5.260019589215517, validation loss 8.758905410766602\n",
            "Complete prediction MSE : 0.0014338948484594232\n",
            "Epoch 115 : Train loss 5.240317972376943, validation loss 8.589640617370605\n",
            "Complete prediction MSE : 0.0015548025305699568\n",
            "Epoch 116 : Train loss 5.236618365161121, validation loss 8.886128425598145\n",
            "Complete prediction MSE : 0.0013570591090191627\n",
            "Saving model\n",
            "Epoch 117 : Train loss 5.19173071347177, validation loss 9.157984733581543\n",
            "Complete prediction MSE : 0.0013165096195225173\n",
            "Saving model\n",
            "Epoch 118 : Train loss 5.191317167133093, validation loss 9.101304054260254\n",
            "Complete prediction MSE : 0.0014487359241115577\n",
            "Epoch 119 : Train loss 5.2302742805331945, validation loss 8.964831352233887\n",
            "Complete prediction MSE : 0.00143490323738611\n",
            "Epoch 120 : Train loss 5.142134941183031, validation loss 8.683805465698242\n",
            "Complete prediction MSE : 0.0013034181849090175\n",
            "Saving model\n",
            "Epoch 121 : Train loss 5.166204878129065, validation loss 8.818989753723145\n",
            "Complete prediction MSE : 0.0013874304128388348\n",
            "Epoch 122 : Train loss 5.126816072501242, validation loss 9.999041557312012\n",
            "Complete prediction MSE : 0.001417115668032172\n",
            "Epoch 123 : Train loss 5.161181994713843, validation loss 9.111860275268555\n",
            "Complete prediction MSE : 0.0014097755387536685\n",
            "Epoch 124 : Train loss 5.157102306373417, validation loss 8.813440322875977\n",
            "Complete prediction MSE : 0.0014772023380365405\n",
            "Epoch 125 : Train loss 5.13956786505878, validation loss 8.951990127563477\n",
            "Complete prediction MSE : 0.0016185352680577571\n",
            "Epoch 126 : Train loss 5.075803627260029, validation loss 8.880936622619629\n",
            "Complete prediction MSE : 0.0014173682906200927\n",
            "Epoch 127 : Train loss 5.108603999018669, validation loss 8.407073974609375\n",
            "Complete prediction MSE : 0.0016676067601591516\n",
            "Epoch 128 : Train loss 5.060385644435883, validation loss 9.503275871276855\n",
            "Complete prediction MSE : 0.0013374768367375406\n",
            "Epoch 129 : Train loss 5.093544989824295, validation loss 8.958929061889648\n",
            "Complete prediction MSE : 0.001311906937336321\n",
            "Epoch 130 : Train loss 5.065595301799476, validation loss 8.78860855102539\n",
            "Complete prediction MSE : 0.0013624219506105653\n",
            "Epoch 131 : Train loss 5.040532721206546, validation loss 8.877679824829102\n",
            "Complete prediction MSE : 0.0015277613354449898\n",
            "Epoch 132 : Train loss 5.036743809469044, validation loss 8.52346420288086\n",
            "Complete prediction MSE : 0.0013114057973142583\n",
            "Epoch 133 : Train loss 5.040424347855151, validation loss 8.222935676574707\n",
            "Complete prediction MSE : 0.0014725374203514113\n",
            "Epoch 134 : Train loss 5.060790134593844, validation loss 8.471636772155762\n",
            "Complete prediction MSE : 0.0012754751609984974\n",
            "Saving model\n",
            "Epoch 135 : Train loss 4.993247428908944, validation loss 8.748769760131836\n",
            "Complete prediction MSE : 0.001302034356487043\n",
            "Epoch 136 : Train loss 4.9985955990850925, validation loss 8.717973709106445\n",
            "Complete prediction MSE : 0.0014063972032940498\n",
            "Epoch 137 : Train loss 4.981909110210836, validation loss 8.896055221557617\n",
            "Complete prediction MSE : 0.0012558628386655475\n",
            "Saving model\n",
            "Epoch 138 : Train loss 5.00766461994499, validation loss 8.338172912597656\n",
            "Complete prediction MSE : 0.001362013484600729\n",
            "Epoch 139 : Train loss 5.009338170289993, validation loss 8.43982219696045\n",
            "Complete prediction MSE : 0.0012698573822747749\n",
            "Epoch 140 : Train loss 4.949932343326509, validation loss 8.429201126098633\n",
            "Complete prediction MSE : 0.0012888803821337932\n",
            "Epoch 141 : Train loss 4.97510539367795, validation loss 8.36657428741455\n",
            "Complete prediction MSE : 0.0012420877343996032\n",
            "Saving model\n",
            "Epoch 142 : Train loss 4.974393702112138, validation loss 8.901165008544922\n",
            "Complete prediction MSE : 0.001182471074749408\n",
            "Saving model\n",
            "Epoch 143 : Train loss 4.9505070289596915, validation loss 8.43706226348877\n",
            "Complete prediction MSE : 0.0014066902385353535\n",
            "Epoch 144 : Train loss 4.929108117707074, validation loss 8.446528434753418\n",
            "Complete prediction MSE : 0.001292351956492013\n",
            "Epoch 145 : Train loss 4.92511154897511, validation loss 8.553413391113281\n",
            "Complete prediction MSE : 0.0012044878945764751\n",
            "Epoch 146 : Train loss 4.891714175231755, validation loss 8.666747093200684\n",
            "Complete prediction MSE : 0.001317424640966293\n",
            "Epoch 147 : Train loss 4.934481734409928, validation loss 8.37134075164795\n",
            "Complete prediction MSE : 0.0013980758111846797\n",
            "Epoch 148 : Train loss 4.907233159057796, validation loss 8.347344398498535\n",
            "Complete prediction MSE : 0.0012855718216721029\n",
            "Epoch 149 : Train loss 4.899856138043106, validation loss 7.848886489868164\n",
            "Complete prediction MSE : 0.0013239132860377834\n",
            "Epoch 150 : Train loss 4.925871425308287, validation loss 7.98674201965332\n",
            "Complete prediction MSE : 0.0012636862791579676\n",
            "Epoch 151 : Train loss 4.874430970288813, validation loss 8.253827095031738\n",
            "Complete prediction MSE : 0.0013226974558956583\n",
            "Epoch 152 : Train loss 4.886573159135878, validation loss 7.664276599884033\n",
            "Complete prediction MSE : 0.001571967464552687\n",
            "Epoch 153 : Train loss 4.885741000063717, validation loss 8.118523597717285\n",
            "Complete prediction MSE : 0.00134299627296063\n",
            "Epoch 154 : Train loss 4.852076229639351, validation loss 7.978860378265381\n",
            "Complete prediction MSE : 0.0013544219570010045\n",
            "Epoch 155 : Train loss 4.863949696533382, validation loss 8.23877239227295\n",
            "Complete prediction MSE : 0.0013246412902494446\n",
            "Epoch 156 : Train loss 4.848740573041141, validation loss 8.223421096801758\n",
            "Complete prediction MSE : 0.001289368456080518\n",
            "Epoch 157 : Train loss 4.849281600676477, validation loss 8.302143096923828\n",
            "Complete prediction MSE : 0.0011778950789640937\n",
            "Saving model\n",
            "Epoch 158 : Train loss 4.844313742592931, validation loss 8.601747512817383\n",
            "Complete prediction MSE : 0.0013223927047190441\n",
            "Epoch 159 : Train loss 4.817229751497507, validation loss 8.273098945617676\n",
            "Complete prediction MSE : 0.0013051736780566661\n",
            "Epoch 160 : Train loss 4.8622917626053095, validation loss 8.12401008605957\n",
            "Complete prediction MSE : 0.0013479143598763771\n",
            "Epoch 161 : Train loss 4.812009263783693, validation loss 8.561107635498047\n",
            "Complete prediction MSE : 0.0012212949150620734\n",
            "Epoch 162 : Train loss 4.833378215320408, validation loss 8.178004264831543\n",
            "Complete prediction MSE : 0.0014090952368978594\n",
            "Epoch 163 : Train loss 4.778854343108833, validation loss 8.875972747802734\n",
            "Complete prediction MSE : 0.0013491440961651941\n",
            "Epoch 164 : Train loss 4.8028346206992865, validation loss 8.206050872802734\n",
            "Complete prediction MSE : 0.0014383123630748549\n",
            "Epoch 165 : Train loss 4.785339058376849, validation loss 8.0635404586792\n",
            "Complete prediction MSE : 0.0012877883043255173\n",
            "Epoch 166 : Train loss 4.809609681367874, validation loss 8.504142761230469\n",
            "Complete prediction MSE : 0.0013353152449943279\n",
            "Epoch 167 : Train loss 4.744147980585694, validation loss 8.355491638183594\n",
            "Complete prediction MSE : 0.0012471803413337283\n",
            "Epoch 168 : Train loss 4.7696455754339695, validation loss 8.510270118713379\n",
            "Complete prediction MSE : 0.0012676783956156008\n",
            "Epoch 169 : Train loss 4.741516099311411, validation loss 8.544648170471191\n",
            "Complete prediction MSE : 0.001264744622943656\n",
            "Epoch 170 : Train loss 4.7770955404266715, validation loss 8.486628532409668\n",
            "Complete prediction MSE : 0.001269199058508293\n",
            "Epoch 171 : Train loss 4.80288549233228, validation loss 8.193042755126953\n",
            "Complete prediction MSE : 0.001332284625199167\n",
            "Epoch 172 : Train loss 4.736113220453262, validation loss 8.43539810180664\n",
            "Complete prediction MSE : 0.0012363172878890692\n",
            "Epoch 173 : Train loss 4.751718919724226, validation loss 8.046517372131348\n",
            "Complete prediction MSE : 0.0012515824266947865\n",
            "Epoch 174 : Train loss 4.7408814541995525, validation loss 8.264252662658691\n",
            "Complete prediction MSE : 0.0013516782521308386\n",
            "Epoch 175 : Train loss 4.718924282118678, validation loss 8.396125793457031\n",
            "Complete prediction MSE : 0.0012830909778370576\n",
            "Epoch 176 : Train loss 4.735245536081493, validation loss 7.760356903076172\n",
            "Complete prediction MSE : 0.0013344435396553383\n",
            "Epoch 177 : Train loss 4.748240515589714, validation loss 7.953495979309082\n",
            "Complete prediction MSE : 0.0012874366245683988\n",
            "Epoch 178 : Train loss 4.738348787650466, validation loss 8.446484565734863\n",
            "Complete prediction MSE : 0.0012893524460562459\n",
            "Epoch 179 : Train loss 4.722217181697488, validation loss 8.295038223266602\n",
            "Complete prediction MSE : 0.0012869801348890913\n",
            "Epoch 180 : Train loss 4.702539787627757, validation loss 8.157780647277832\n",
            "Complete prediction MSE : 0.0012996584994902506\n",
            "Epoch 181 : Train loss 4.717472624965012, validation loss 8.21818733215332\n",
            "Complete prediction MSE : 0.0013938804901764059\n",
            "Epoch 182 : Train loss 4.6861709277145565, validation loss 8.033571243286133\n",
            "Complete prediction MSE : 0.0013642782332843992\n",
            "Epoch 183 : Train loss 4.678606177680194, validation loss 8.460620880126953\n",
            "Complete prediction MSE : 0.0012923979901972417\n",
            "Epoch 184 : Train loss 4.6886802623048425, validation loss 8.44931697845459\n",
            "Complete prediction MSE : 0.0012680206373201445\n",
            "Epoch 185 : Train loss 4.650674218311906, validation loss 7.965030193328857\n",
            "Complete prediction MSE : 0.001244757160975657\n",
            "Epoch 186 : Train loss 4.6958765015006065, validation loss 7.743818283081055\n",
            "Complete prediction MSE : 0.0014946928372246966\n",
            "Epoch 187 : Train loss 4.69026127550751, validation loss 7.988528251647949\n",
            "Complete prediction MSE : 0.0012388201585969015\n",
            "Epoch 188 : Train loss 4.644710421562195, validation loss 8.21945858001709\n",
            "Complete prediction MSE : 0.001268494457643433\n",
            "Epoch 189 : Train loss 4.666381333954632, validation loss 8.35632610321045\n",
            "Complete prediction MSE : 0.0012654723640718808\n",
            "Epoch 190 : Train loss 4.659938430413604, validation loss 8.24868106842041\n",
            "Complete prediction MSE : 0.001264243050366888\n",
            "Epoch 191 : Train loss 4.6522085862234235, validation loss 8.215349197387695\n",
            "Complete prediction MSE : 0.0012253838602763337\n",
            "Epoch 192 : Train loss 4.658219942823052, validation loss 8.479440689086914\n",
            "Complete prediction MSE : 0.001325917549003854\n",
            "Epoch 193 : Train loss 4.630445756949484, validation loss 7.713015556335449\n",
            "Complete prediction MSE : 0.0011864590076912382\n",
            "Epoch 194 : Train loss 4.643093577586114, validation loss 8.201654434204102\n",
            "Complete prediction MSE : 0.0013219741631066162\n",
            "Epoch 195 : Train loss 4.618385400623083, validation loss 8.135618209838867\n",
            "Complete prediction MSE : 0.0012012078945545918\n",
            "Epoch 196 : Train loss 4.605239662807435, validation loss 8.197173118591309\n",
            "Complete prediction MSE : 0.001162410329625906\n",
            "Saving model\n",
            "Epoch 197 : Train loss 4.608186394907534, validation loss 8.06972885131836\n",
            "Complete prediction MSE : 0.0011649098583478316\n",
            "Epoch 198 : Train loss 4.592905655037612, validation loss 9.201224327087402\n",
            "Complete prediction MSE : 0.0013843276781952117\n",
            "Epoch 199 : Train loss 4.64517607120797, validation loss 8.515519142150879\n",
            "Complete prediction MSE : 0.0012925952141585287\n",
            "Epoch 200 : Train loss 4.6046427842229605, validation loss 7.880265712738037\n",
            "Complete prediction MSE : 0.0013175541256955677\n",
            "Epoch 201 : Train loss 4.600911654531956, validation loss 8.947661399841309\n",
            "Complete prediction MSE : 0.0012229342485857787\n",
            "Epoch 202 : Train loss 4.582228746265173, validation loss 8.32705020904541\n",
            "Complete prediction MSE : 0.001290685718432293\n",
            "Epoch 203 : Train loss 4.580039174761623, validation loss 8.051176071166992\n",
            "Complete prediction MSE : 0.0013933145311818477\n",
            "Epoch 204 : Train loss 4.604171025101095, validation loss 8.381913185119629\n",
            "Complete prediction MSE : 0.0014534189289686073\n",
            "Epoch 205 : Train loss 4.5955696743912995, validation loss 8.648022651672363\n",
            "Complete prediction MSE : 0.0013347359670894433\n",
            "Epoch 206 : Train loss 4.586537259165198, validation loss 8.602066993713379\n",
            "Complete prediction MSE : 0.0014588681222162214\n",
            "Epoch 207 : Train loss 4.593953766860068, validation loss 7.985825061798096\n",
            "Complete prediction MSE : 0.0012658940963415047\n",
            "Epoch 208 : Train loss 4.607864944264293, validation loss 7.7796430587768555\n",
            "Complete prediction MSE : 0.0014230290416600672\n",
            "Epoch 209 : Train loss 4.564973809290677, validation loss 8.137468338012695\n",
            "Complete prediction MSE : 0.0015810054158106024\n",
            "Epoch 210 : Train loss 4.591412197332829, validation loss 7.9569268226623535\n",
            "Complete prediction MSE : 0.0014956061676984142\n",
            "Epoch 211 : Train loss 4.530452587641776, validation loss 8.784936904907227\n",
            "Complete prediction MSE : 0.0012081274982258118\n",
            "Epoch 212 : Train loss 4.607708793133497, validation loss 8.12949275970459\n",
            "Complete prediction MSE : 0.001569542973399554\n",
            "Epoch 213 : Train loss 4.530119094531983, validation loss 8.689078330993652\n",
            "Complete prediction MSE : 0.0013401920456484005\n",
            "Epoch 214 : Train loss 4.558081497438252, validation loss 8.771471977233887\n",
            "Complete prediction MSE : 0.0012834060644606538\n",
            "Epoch 215 : Train loss 4.583271913230419, validation loss 7.7145586013793945\n",
            "Complete prediction MSE : 0.0013026424443903868\n",
            "Epoch 216 : Train loss 4.519794013351202, validation loss 8.2760591506958\n",
            "Complete prediction MSE : 0.0013189339902153403\n",
            "Epoch 217 : Train loss 4.5392667865380645, validation loss 8.540908813476562\n",
            "Complete prediction MSE : 0.0015035099263852204\n",
            "Epoch 218 : Train loss 4.577085576020181, validation loss 8.245488166809082\n",
            "Complete prediction MSE : 0.001419959276722064\n",
            "Epoch 219 : Train loss 4.528532907832414, validation loss 8.09719467163086\n",
            "Complete prediction MSE : 0.0013364177224642001\n",
            "Epoch 220 : Train loss 4.547258672770113, validation loss 8.20871639251709\n",
            "Complete prediction MSE : 0.0014362773082063729\n",
            "Epoch 221 : Train loss 4.543613345362246, validation loss 8.046728134155273\n",
            "Complete prediction MSE : 0.0012780333682973482\n",
            "Epoch 222 : Train loss 4.5526424162089825, validation loss 8.102446556091309\n",
            "Complete prediction MSE : 0.001582859392868008\n",
            "Epoch 223 : Train loss 4.578402206301689, validation loss 8.48717212677002\n",
            "Complete prediction MSE : 0.0015728820911587646\n",
            "Epoch 224 : Train loss 4.5390123897232115, validation loss 8.418757438659668\n",
            "Complete prediction MSE : 0.0013982494799597328\n",
            "Epoch 225 : Train loss 4.506893769837916, validation loss 8.755504608154297\n",
            "Complete prediction MSE : 0.0012690294216330924\n",
            "Epoch 226 : Train loss 4.47922550002113, validation loss 8.397076606750488\n",
            "Complete prediction MSE : 0.001365088853263165\n",
            "Epoch 227 : Train loss 4.508649535477161, validation loss 8.69527816772461\n",
            "Complete prediction MSE : 0.0013116963482303371\n",
            "Epoch 228 : Train loss 4.507890899199992, validation loss 8.702412605285645\n",
            "Complete prediction MSE : 0.0013098155765700165\n",
            "Epoch 229 : Train loss 4.554483621381223, validation loss 8.172143936157227\n",
            "Complete prediction MSE : 0.001227486900628709\n",
            "Epoch 230 : Train loss 4.497498947195709, validation loss 8.195712089538574\n",
            "Complete prediction MSE : 0.0015235393393179765\n",
            "Epoch 231 : Train loss 4.533136545214802, validation loss 8.364778518676758\n",
            "Complete prediction MSE : 0.0014260518045919844\n",
            "Epoch 232 : Train loss 4.516382293775678, validation loss 9.46275806427002\n",
            "Complete prediction MSE : 0.0013507754857376003\n",
            "Epoch 233 : Train loss 4.51234435569495, validation loss 8.59046459197998\n",
            "Complete prediction MSE : 0.001341335456048235\n",
            "Epoch 234 : Train loss 4.518050124403089, validation loss 8.359980583190918\n",
            "Complete prediction MSE : 0.0015528115180351726\n",
            "Epoch 235 : Train loss 4.536379627417773, validation loss 8.237309455871582\n",
            "Complete prediction MSE : 0.0014549281183697162\n",
            "Epoch 236 : Train loss 4.4769667643122375, validation loss 8.82435417175293\n",
            "Complete prediction MSE : 0.001359313394484327\n",
            "Epoch 237 : Train loss 4.542220734525472, validation loss 8.686457633972168\n",
            "Complete prediction MSE : 0.0015795151451511137\n",
            "Epoch 238 : Train loss 4.493007496930659, validation loss 8.459859848022461\n",
            "Complete prediction MSE : 0.001332539629506612\n",
            "Epoch 239 : Train loss 4.5107417539693415, validation loss 8.500022888183594\n",
            "Complete prediction MSE : 0.0014213958964213662\n",
            "Epoch 240 : Train loss 4.48289550235495, validation loss 8.350737571716309\n",
            "Complete prediction MSE : 0.001536830025369776\n",
            "Epoch 241 : Train loss 4.492496626917273, validation loss 7.94312047958374\n",
            "Complete prediction MSE : 0.0013762633048277641\n",
            "Epoch 242 : Train loss 4.471928216982633, validation loss 9.119684219360352\n",
            "Complete prediction MSE : 0.0013623838281058363\n",
            "Epoch 243 : Train loss 4.429582098033279, validation loss 8.398412704467773\n",
            "Complete prediction MSE : 0.00138397134395261\n",
            "Epoch 244 : Train loss 4.493959779851139, validation loss 8.695396423339844\n",
            "Complete prediction MSE : 0.0016187121577137958\n",
            "Epoch 245 : Train loss 4.543015008792281, validation loss 7.943339824676514\n",
            "Complete prediction MSE : 0.001401732568506005\n",
            "Epoch 246 : Train loss 4.543468881864101, validation loss 8.428271293640137\n",
            "Complete prediction MSE : 0.0013399847178271012\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 2\n",
            "Epoch 1 : Train loss 35.159496165812016, validation loss 14.90665054321289\n",
            "Complete prediction MSE : 0.004038905072565854\n",
            "Saving model\n",
            "Epoch 2 : Train loss 15.835443878546357, validation loss 12.120369911193848\n",
            "Complete prediction MSE : 0.0029885259431411204\n",
            "Saving model\n",
            "Epoch 3 : Train loss 13.86907802335918, validation loss 11.434041976928711\n",
            "Complete prediction MSE : 0.00297547261252282\n",
            "Saving model\n",
            "Epoch 4 : Train loss 12.828160408884287, validation loss 10.186149597167969\n",
            "Complete prediction MSE : 0.0024938037059956232\n",
            "Saving model\n",
            "Epoch 5 : Train loss 12.238302532583475, validation loss 10.55480670928955\n",
            "Complete prediction MSE : 0.0030605229509089115\n",
            "Epoch 6 : Train loss 34.330116080120206, validation loss 18.294721603393555\n",
            "Complete prediction MSE : 0.0033011909370585387\n",
            "Epoch 7 : Train loss 18.072815530002117, validation loss 14.097331047058105\n",
            "Complete prediction MSE : 0.002656358369233711\n",
            "Epoch 8 : Train loss 15.729993034154177, validation loss 13.355575561523438\n",
            "Complete prediction MSE : 0.002658530082046222\n",
            "Epoch 9 : Train loss 14.659007128328085, validation loss 12.360443115234375\n",
            "Complete prediction MSE : 0.0028582296453514423\n",
            "Epoch 10 : Train loss 13.768069410696626, validation loss 11.089247703552246\n",
            "Complete prediction MSE : 0.002728960634039383\n",
            "Epoch 11 : Train loss 13.241188881918788, validation loss 10.526914596557617\n",
            "Complete prediction MSE : 0.0027816534219268865\n",
            "Epoch 12 : Train loss 12.565446600317955, validation loss 10.020745277404785\n",
            "Complete prediction MSE : 0.002880834595822717\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1d2f9ede86ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#print(f\"pred loss = {pred_loss}, ae loss = {ae_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#print(f\"pred loss = {pred_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m       \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "nb_seeds = 5\n",
        "for seed in range(nb_seeds):\n",
        "  torch.manual_seed(seed)\n",
        "  model = IKAE.IKAE(input_dim=20, hidden_dim=256, n_layers_encoder=6, positive_nonlin=nn.Softplus(), flow='NICE', device=device).to(device)\n",
        "  print(f'Training model with seed {seed}')\n",
        "  epochs = 500\n",
        "  opt = model.configure_optimizers(lr=1e-3)\n",
        "  #opt = model.configure_optimizers(lr=1e-3, weight_decay=1e-6) # With weight decay\n",
        "  max_patience = 50\n",
        "  patience = 0\n",
        "  time_span = 100\n",
        "  alpha = 0\n",
        "  lamda = 100.\n",
        "  model.best_epoch, model.best_val = 0, 1e15\n",
        "  last_train_index = 53\n",
        "  model.train_losses = []\n",
        "  model.val_losses = []\n",
        "  model.val_losses2 = []\n",
        "  model.val_losses3 = []\n",
        "  starting_point = 0\n",
        "  loss_every = 1\n",
        "\n",
        "  for epoch in range(epochs+1) :\n",
        "    if patience >= max_patience:\n",
        "      print('Early stopping due to no more improvement and/or unstable training')\n",
        "      break\n",
        "    epoch_loss = 0\n",
        "    epoch_val_loss = 0\n",
        "    model.train()\n",
        "    for batch in range(nb_batches) :\n",
        "      opt.zero_grad()\n",
        "      x0 = state_batches[0,batch].to(device)\n",
        "      gt = state_batches[:,batch].to(device)\n",
        "      latent_states = model.encode(gt.flatten(0,1))\n",
        "      #print(gt.shape, latent_states.shape, x0.shape)\n",
        "      xt, phis = model.forward_n_remember(x0, time_span)\n",
        "      phi_0 = phis[0]\n",
        "      loss = 0\n",
        "      # Prediction loss\n",
        "      #print(phis.shape, latent_states.shape, gt.shape)\n",
        "      pred_loss = mse_loss(model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], phis.shape[2])), gt)\n",
        "      loss += pred_loss\n",
        "      # Reconstruction loss\n",
        "      #ae_loss = mse_loss(model.decode(latent_states).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "      #loss += ae_loss\n",
        "      # Linearity loss\n",
        "      lin_loss = mse_loss(phis, latent_states.reshape((phis.shape[0], phis.shape[1], phis.shape[2])))\n",
        "      loss += lin_loss\n",
        "      # Orthogonality loss\n",
        "      orth_loss = lamda * mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "      loss += orth_loss\n",
        "      #if batch % 100 == 0:\n",
        "        #print(f\"Batch {batch}: loss = {loss}\")\n",
        "        #print(f\"pred loss = {pred_loss}, ae loss = {ae_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\n",
        "        #print(f\"pred loss = {pred_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      epoch_loss += loss.detach().item()\n",
        "\n",
        "    #scheduler.step()\n",
        "    epoch_loss /= nb_batches\n",
        "    model.train_losses.append(epoch_loss)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    x0 = states_val[0].to(device)\n",
        "    gt = states_val.to(device)\n",
        "    latent_states = model.encode(states_val.to(device).flatten(0,1))\n",
        "    xt, phis = model.forward_n_remember(x0, time_span)\n",
        "    phi_0 = phis[0]\n",
        "    # Prediction loss\n",
        "    val_loss += mse_loss(model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], phis.shape[2])), gt)\n",
        "    # Reconstruction loss\n",
        "    #val_loss += mse_loss(model.decode(latent_states).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "    # Linearity loss\n",
        "    val_loss += mse_loss(phis, latent_states.reshape((phis.shape[0], phis.shape[1], phis.shape[2])))\n",
        "    # Orthogonality loss\n",
        "    val_loss += lamda * mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "    model.val_losses2.append(val_loss.item())\n",
        "    #epoch_val_loss = val_loss.item()\n",
        "    whole_predictions = np.zeros((data_small.shape[0]-101, data_small.shape[1]//10, data_small.shape[2], data_small.shape[3]))\n",
        "    for column in range(data_small.shape[1] // 10) :\n",
        "      states = torch.Tensor(data_small[1:,10*column]).to(device)\n",
        "      states = torch.cat([states, states - torch.Tensor(data_small[:-1,10*column]).to(device)], dim=2) # Add derivatives\n",
        "      predictions, phis = model.forward_n_remember(states[starting_point],241)\n",
        "      #whole_predictions[starting_point:, column] = predictions[:342-starting_point,:10].cpu().detach()\n",
        "      decoded = model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], phis.shape[2]))\n",
        "      whole_predictions[starting_point:, column] = decoded[:whole_predictions.shape[0]-starting_point,:,:10].cpu().detach()\n",
        "\n",
        "    val_loss3 = np.mean((data_small[starting_point+1:starting_point+243,::10] - whole_predictions)[starting_point:] **2)\n",
        "    model.val_losses3.append(val_loss3.item())\n",
        "    epoch_val_loss = val_loss3.item()\n",
        "    if epoch % loss_every == 0 :\n",
        "      print(f\"Epoch {epoch+1} : Train loss {model.train_losses[-1]}, validation loss {model.val_losses2[-1]}\")\n",
        "      print(f\"Complete prediction MSE : {model.val_losses3[-1]}\")\n",
        "    if epoch_val_loss < model.best_val : # Save the model parameters\n",
        "      model.best_val = epoch_val_loss\n",
        "      model.best_epoch = epoch\n",
        "      torch.save(model.state_dict(), models_path+f'best_model_{seed}.pt')\n",
        "      torch.save(model.K, models_path+f'best_K_{seed}.pt')\n",
        "      patience = 0\n",
        "      print('Saving model')\n",
        "    else:\n",
        "      patience += 1\n",
        "      if math.isnan(epoch_val_loss) or model.train_losses[-1] > 1000:\n",
        "        patience += 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU9CTdljmlHj"
      },
      "source": [
        "# IKAE-zp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rZXnRFRmwBu",
        "outputId": "4b15b1b8-1727-4002-8b1a-7648ba10ef28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 56940\n",
            "IKAE(\n",
            "  (positive_nonlin): Softplus(beta=1.0, threshold=20.0)\n",
            "  (invertible_encoder): stacked_NICE(\n",
            "    (bijectors): ModuleList(\n",
            "      (0-5): 6 x NICE(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=18, out_features=256, bias=True)\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Linear(in_features=256, out_features=18, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "model = IKAE_zp(input_dim=20, hidden_dim=256, n_layers_encoder=6, zero_padding=16,\n",
        "                   positive_nonlin=nn.Softplus(), flow='NICE', device=device).to(device)\n",
        "\n",
        "print(f\"Number of parameters: {count_parameters(model)}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUmOI6CNvj0O",
        "outputId": "84bfb686-0c06-4852-959f-a5464aba2d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with seed 0\n",
            "Epoch 1 : Train loss 40.90683432482183, validation loss 19.194581985473633\n",
            "Complete prediction MSE : 0.004046380256563871\n",
            "Saving model\n",
            "Epoch 2 : Train loss 15.730235120281577, validation loss 21.397802352905273\n",
            "Complete prediction MSE : 0.004166098449029065\n",
            "Epoch 3 : Train loss 13.483702862635255, validation loss 11.893830299377441\n",
            "Complete prediction MSE : 0.002712641375348511\n",
            "Saving model\n",
            "Epoch 4 : Train loss 12.536097005009651, validation loss 15.259390830993652\n",
            "Complete prediction MSE : 0.0037292211096682276\n",
            "Epoch 5 : Train loss 11.34023954346776, validation loss 12.03137493133545\n",
            "Complete prediction MSE : 0.0029895456343050166\n",
            "Epoch 6 : Train loss 10.700973888859153, validation loss 9.807804107666016\n",
            "Complete prediction MSE : 0.0025839907017764607\n",
            "Saving model\n",
            "Epoch 7 : Train loss 10.19399026595056, validation loss 9.25197982788086\n",
            "Complete prediction MSE : 0.002692544856376165\n",
            "Epoch 8 : Train loss 10.208275001496077, validation loss 10.13748836517334\n",
            "Complete prediction MSE : 0.0024893308579572323\n",
            "Saving model\n",
            "Epoch 9 : Train loss 9.442484715022147, validation loss 10.437790870666504\n",
            "Complete prediction MSE : 0.0026461424885493717\n",
            "Epoch 10 : Train loss 39.60850661806762, validation loss 16.28545570373535\n",
            "Complete prediction MSE : 0.0028721674896507753\n",
            "Epoch 11 : Train loss 15.766566812992096, validation loss 13.687676429748535\n",
            "Complete prediction MSE : 0.0028363684348062697\n",
            "Epoch 12 : Train loss 13.869578594341874, validation loss 12.671246528625488\n",
            "Complete prediction MSE : 0.002799072633956158\n",
            "Epoch 13 : Train loss 12.423894677311182, validation loss 11.01822566986084\n",
            "Complete prediction MSE : 0.002692535930218054\n",
            "Epoch 14 : Train loss 11.281642485409975, validation loss 10.64091968536377\n",
            "Complete prediction MSE : 0.002491960076183791\n",
            "Epoch 15 : Train loss 10.378520783036947, validation loss 9.70112419128418\n",
            "Complete prediction MSE : 0.002730687164874782\n",
            "Epoch 16 : Train loss 9.742360414937139, validation loss 9.565558433532715\n",
            "Complete prediction MSE : 0.0026292611968973044\n",
            "Epoch 17 : Train loss 9.331919995136559, validation loss 10.176340103149414\n",
            "Complete prediction MSE : 0.00248613163605266\n",
            "Saving model\n",
            "Epoch 18 : Train loss 8.916869142092764, validation loss 9.25136947631836\n",
            "Complete prediction MSE : 0.0027101095218341536\n",
            "Epoch 19 : Train loss 8.641641859896481, validation loss 8.169022560119629\n",
            "Complete prediction MSE : 0.0025376923948866735\n",
            "Epoch 20 : Train loss 8.504419211298227, validation loss 9.084771156311035\n",
            "Complete prediction MSE : 0.002332760280488692\n",
            "Saving model\n",
            "Epoch 21 : Train loss 8.290358166210353, validation loss 8.783844947814941\n",
            "Complete prediction MSE : 0.0024730670568019163\n",
            "Epoch 22 : Train loss 8.126485067419708, validation loss 9.132417678833008\n",
            "Complete prediction MSE : 0.002419824604395204\n",
            "Epoch 23 : Train loss 7.94410743098706, validation loss 8.384125709533691\n",
            "Complete prediction MSE : 0.002299542027135463\n",
            "Saving model\n",
            "Epoch 24 : Train loss 7.752622313797474, validation loss 8.628286361694336\n",
            "Complete prediction MSE : 0.0023869512830909227\n",
            "Epoch 25 : Train loss 7.559196553193033, validation loss 8.048986434936523\n",
            "Complete prediction MSE : 0.002506690932039383\n",
            "Epoch 26 : Train loss 7.454651862382889, validation loss 8.990606307983398\n",
            "Complete prediction MSE : 0.002185762855885184\n",
            "Saving model\n",
            "Epoch 27 : Train loss 7.213995737954974, validation loss 7.857858657836914\n",
            "Complete prediction MSE : 0.0023207691044931176\n",
            "Epoch 28 : Train loss 7.096358926035464, validation loss 8.219446182250977\n",
            "Complete prediction MSE : 0.0024159907479567254\n",
            "Epoch 29 : Train loss 7.398574460297823, validation loss 9.093526840209961\n",
            "Complete prediction MSE : 0.002214027439954338\n",
            "Epoch 30 : Train loss 6.817880312912166, validation loss 8.483325958251953\n",
            "Complete prediction MSE : 0.002719083557648263\n",
            "Epoch 31 : Train loss 6.727278271690011, validation loss 8.786409378051758\n",
            "Complete prediction MSE : 0.002220906487336502\n",
            "Epoch 32 : Train loss 6.611187791451812, validation loss 8.241775512695312\n",
            "Complete prediction MSE : 0.0022911309840762356\n",
            "Epoch 33 : Train loss 6.549525081180036, validation loss 7.894819736480713\n",
            "Complete prediction MSE : 0.001972199791606777\n",
            "Saving model\n",
            "Epoch 34 : Train loss 6.427676174789667, validation loss 7.597239971160889\n",
            "Complete prediction MSE : 0.002220937145141535\n",
            "Epoch 35 : Train loss 6.335613574832678, validation loss 7.659921646118164\n",
            "Complete prediction MSE : 0.0021848928304105527\n",
            "Epoch 36 : Train loss 6.254260270856321, validation loss 7.716395378112793\n",
            "Complete prediction MSE : 0.0025299514568647547\n",
            "Epoch 37 : Train loss 6.183471815660596, validation loss 7.5961456298828125\n",
            "Complete prediction MSE : 0.002220191414461318\n",
            "Epoch 38 : Train loss 6.0989093426615, validation loss 8.012641906738281\n",
            "Complete prediction MSE : 0.002050442861199011\n",
            "Epoch 39 : Train loss 6.046757718548179, validation loss 8.158693313598633\n",
            "Complete prediction MSE : 0.0020448752321832945\n",
            "Epoch 40 : Train loss 5.963176188990474, validation loss 8.471578598022461\n",
            "Complete prediction MSE : 0.002070562756367276\n",
            "Epoch 41 : Train loss 5.916873750276864, validation loss 8.163616180419922\n",
            "Complete prediction MSE : 0.002004662066399356\n",
            "Epoch 42 : Train loss 5.877510190941393, validation loss 8.477938652038574\n",
            "Complete prediction MSE : 0.002048901045501979\n",
            "Epoch 43 : Train loss 5.81135995965451, validation loss 8.568350791931152\n",
            "Complete prediction MSE : 0.0019542599308423644\n",
            "Saving model\n",
            "Epoch 44 : Train loss 5.752486337907612, validation loss 8.152555465698242\n",
            "Complete prediction MSE : 0.00200823396793405\n",
            "Epoch 45 : Train loss 5.650776439346373, validation loss 8.537335395812988\n",
            "Complete prediction MSE : 0.001847583864703191\n",
            "Saving model\n",
            "Epoch 46 : Train loss 5.665733023546636, validation loss 8.947366714477539\n",
            "Complete prediction MSE : 0.0020574247063386893\n",
            "Epoch 47 : Train loss 5.582591648213565, validation loss 8.299210548400879\n",
            "Complete prediction MSE : 0.001954990778824168\n",
            "Epoch 48 : Train loss 5.553089456632733, validation loss 8.789111137390137\n",
            "Complete prediction MSE : 0.0021226679379678214\n",
            "Epoch 49 : Train loss 5.4979275884106755, validation loss 8.351632118225098\n",
            "Complete prediction MSE : 0.0018588929486759024\n",
            "Epoch 50 : Train loss 5.442604067735374, validation loss 9.105971336364746\n",
            "Complete prediction MSE : 0.0016953118304548888\n",
            "Saving model\n",
            "Epoch 51 : Train loss 5.401357715949416, validation loss 8.304695129394531\n",
            "Complete prediction MSE : 0.0018880083812816875\n",
            "Epoch 52 : Train loss 5.364432788453996, validation loss 8.593831062316895\n",
            "Complete prediction MSE : 0.0015977569049892917\n",
            "Saving model\n",
            "Epoch 53 : Train loss 5.304675170220435, validation loss 8.334831237792969\n",
            "Complete prediction MSE : 0.0014494262489116614\n",
            "Saving model\n",
            "Epoch 54 : Train loss 5.260228103026748, validation loss 8.708372116088867\n",
            "Complete prediction MSE : 0.0016543413069799466\n",
            "Epoch 55 : Train loss 5.245640148408711, validation loss 7.928967475891113\n",
            "Complete prediction MSE : 0.001714073942827202\n",
            "Epoch 56 : Train loss 5.200355256907642, validation loss 8.326798439025879\n",
            "Complete prediction MSE : 0.0015040692441540113\n",
            "Epoch 57 : Train loss 5.159941718913615, validation loss 8.364476203918457\n",
            "Complete prediction MSE : 0.0016248438730122041\n",
            "Epoch 58 : Train loss 5.1436589462682605, validation loss 7.59427547454834\n",
            "Complete prediction MSE : 0.0016094539694037045\n",
            "Epoch 59 : Train loss 5.0988706247881055, validation loss 8.781835556030273\n",
            "Complete prediction MSE : 0.0014015974629497377\n",
            "Saving model\n",
            "Epoch 60 : Train loss 5.088769621215761, validation loss 7.907772541046143\n",
            "Complete prediction MSE : 0.0017055038876377516\n",
            "Epoch 61 : Train loss 5.052141858264804, validation loss 8.30608081817627\n",
            "Complete prediction MSE : 0.0014673976248952563\n",
            "Epoch 62 : Train loss 5.023674672469497, validation loss 7.339798450469971\n",
            "Complete prediction MSE : 0.0015199220496462781\n",
            "Epoch 63 : Train loss 5.004079518839717, validation loss 9.02993392944336\n",
            "Complete prediction MSE : 0.0013364052568525092\n",
            "Saving model\n",
            "Epoch 64 : Train loss 4.911564368754625, validation loss 8.68177318572998\n",
            "Complete prediction MSE : 0.0012229591448807877\n",
            "Saving model\n",
            "Epoch 65 : Train loss 4.948618062771857, validation loss 8.414130210876465\n",
            "Complete prediction MSE : 0.0011185989871781534\n",
            "Saving model\n",
            "Epoch 66 : Train loss 4.8812523214146495, validation loss 8.479736328125\n",
            "Complete prediction MSE : 0.0012586671391248228\n",
            "Epoch 67 : Train loss 4.869032293558121, validation loss 8.378714561462402\n",
            "Complete prediction MSE : 0.001187838276030333\n",
            "Epoch 68 : Train loss 4.866072446107864, validation loss 8.620538711547852\n",
            "Complete prediction MSE : 0.0012983982139766622\n",
            "Epoch 69 : Train loss 4.831795123405755, validation loss 7.995010852813721\n",
            "Complete prediction MSE : 0.0012161229938368802\n",
            "Epoch 70 : Train loss 4.8195251962170005, validation loss 9.300135612487793\n",
            "Complete prediction MSE : 0.001383527059666027\n",
            "Epoch 71 : Train loss 4.782400599680841, validation loss 8.677659034729004\n",
            "Complete prediction MSE : 0.0011815518625651238\n",
            "Epoch 72 : Train loss 4.77514679171145, validation loss 9.052407264709473\n",
            "Complete prediction MSE : 0.0013052487678176761\n",
            "Epoch 73 : Train loss 4.739625950343907, validation loss 8.532812118530273\n",
            "Complete prediction MSE : 0.001123508625387994\n",
            "Epoch 74 : Train loss 4.711173335555941, validation loss 8.49986457824707\n",
            "Complete prediction MSE : 0.001252439751783377\n",
            "Epoch 75 : Train loss 4.715813014656305, validation loss 9.096174240112305\n",
            "Complete prediction MSE : 0.0012898085519105727\n",
            "Epoch 76 : Train loss 4.688153475057334, validation loss 8.370006561279297\n",
            "Complete prediction MSE : 0.0011855428808985181\n",
            "Epoch 77 : Train loss 4.6512568313628435, validation loss 9.508460998535156\n",
            "Complete prediction MSE : 0.0012342230349311515\n",
            "Epoch 78 : Train loss 4.6680316580459476, validation loss 9.312996864318848\n",
            "Complete prediction MSE : 0.0012472121948363091\n",
            "Epoch 79 : Train loss 4.607944249175489, validation loss 9.050077438354492\n",
            "Complete prediction MSE : 0.0014538057634350622\n",
            "Epoch 80 : Train loss 4.597987511195242, validation loss 8.615175247192383\n",
            "Complete prediction MSE : 0.001277481121382967\n",
            "Epoch 81 : Train loss 4.590748264454305, validation loss 8.931422233581543\n",
            "Complete prediction MSE : 0.0012861628672718173\n",
            "Epoch 82 : Train loss 4.593235454987735, validation loss 8.99376392364502\n",
            "Complete prediction MSE : 0.0014112860730836625\n",
            "Epoch 83 : Train loss 4.569153903052211, validation loss 8.50603199005127\n",
            "Complete prediction MSE : 0.0013317183294591025\n",
            "Epoch 84 : Train loss 4.527423613704741, validation loss 9.493352890014648\n",
            "Complete prediction MSE : 0.001292541584016953\n",
            "Epoch 85 : Train loss 4.509713837876916, validation loss 9.095126152038574\n",
            "Complete prediction MSE : 0.001243314669669242\n",
            "Epoch 86 : Train loss 4.53172774752602, validation loss 9.302645683288574\n",
            "Complete prediction MSE : 0.001304522282631808\n",
            "Epoch 87 : Train loss 4.487497823312879, validation loss 8.471301078796387\n",
            "Complete prediction MSE : 0.0012908871402601888\n",
            "Epoch 88 : Train loss 4.49686169764027, validation loss 8.743704795837402\n",
            "Complete prediction MSE : 0.0014558639415826525\n",
            "Epoch 89 : Train loss 4.46549553796649, validation loss 8.793121337890625\n",
            "Complete prediction MSE : 0.0013090863770760302\n",
            "Epoch 90 : Train loss 4.4690502397716045, validation loss 8.391207695007324\n",
            "Complete prediction MSE : 0.0011794866754288086\n",
            "Epoch 91 : Train loss 4.442494063172489, validation loss 8.822985649108887\n",
            "Complete prediction MSE : 0.001154310752229244\n",
            "Epoch 92 : Train loss 4.449470907449722, validation loss 8.819828987121582\n",
            "Complete prediction MSE : 0.0010997243085748604\n",
            "Saving model\n",
            "Epoch 93 : Train loss 4.434860528912395, validation loss 8.867159843444824\n",
            "Complete prediction MSE : 0.001318238059483613\n",
            "Epoch 94 : Train loss 4.417532611172646, validation loss 8.511433601379395\n",
            "Complete prediction MSE : 0.0013029004919023742\n",
            "Epoch 95 : Train loss 4.386898249853402, validation loss 8.837316513061523\n",
            "Complete prediction MSE : 0.0011836843359125239\n",
            "Epoch 96 : Train loss 4.397809475194663, validation loss 8.50508975982666\n",
            "Complete prediction MSE : 0.0010851566261723066\n",
            "Saving model\n",
            "Epoch 97 : Train loss 4.408170908689499, validation loss 8.97477912902832\n",
            "Complete prediction MSE : 0.0011299412366615564\n",
            "Epoch 98 : Train loss 4.386265818960965, validation loss 8.992849349975586\n",
            "Complete prediction MSE : 0.0013080796695393773\n",
            "Epoch 99 : Train loss 4.378741149324924, validation loss 8.283909797668457\n",
            "Complete prediction MSE : 0.0011723993939323708\n",
            "Epoch 100 : Train loss 4.357662561815232, validation loss 8.883041381835938\n",
            "Complete prediction MSE : 0.001189494286116182\n",
            "Epoch 101 : Train loss 4.313443199265748, validation loss 7.978422164916992\n",
            "Complete prediction MSE : 0.001198277039628364\n",
            "Epoch 102 : Train loss 4.312916908878833, validation loss 9.125548362731934\n",
            "Complete prediction MSE : 0.0011419316782825515\n",
            "Epoch 103 : Train loss 4.307482744567096, validation loss 8.400650024414062\n",
            "Complete prediction MSE : 0.0014001768517221001\n",
            "Epoch 104 : Train loss 4.321120937820524, validation loss 8.802203178405762\n",
            "Complete prediction MSE : 0.0012473131286250172\n",
            "Epoch 105 : Train loss 4.282555689103901, validation loss 8.357824325561523\n",
            "Complete prediction MSE : 0.0016315163901729447\n",
            "Epoch 106 : Train loss 4.271424348000437, validation loss 8.493053436279297\n",
            "Complete prediction MSE : 0.0012840352202464582\n",
            "Epoch 107 : Train loss 4.302669885568321, validation loss 8.649065971374512\n",
            "Complete prediction MSE : 0.0011095680026719731\n",
            "Epoch 108 : Train loss 4.2430001688189805, validation loss 8.926603317260742\n",
            "Complete prediction MSE : 0.0013253908114047649\n",
            "Epoch 109 : Train loss 4.23210894363001, validation loss 8.191824913024902\n",
            "Complete prediction MSE : 0.0013072551789257978\n",
            "Epoch 110 : Train loss 4.249243163038045, validation loss 9.435503959655762\n",
            "Complete prediction MSE : 0.0013174218576617923\n",
            "Epoch 111 : Train loss 4.221122459042817, validation loss 9.3744478225708\n",
            "Complete prediction MSE : 0.0012913666551347834\n",
            "Epoch 112 : Train loss 4.199567994102836, validation loss 10.349848747253418\n",
            "Complete prediction MSE : 0.0009907076437577613\n",
            "Saving model\n",
            "Epoch 113 : Train loss 4.246812349651009, validation loss 8.548809051513672\n",
            "Complete prediction MSE : 0.0011250533461750723\n",
            "Epoch 114 : Train loss 4.238996061496437, validation loss 8.532147407531738\n",
            "Complete prediction MSE : 0.001060564043530069\n",
            "Epoch 115 : Train loss 4.224460587371141, validation loss 8.727992057800293\n",
            "Complete prediction MSE : 0.001425142039633935\n",
            "Epoch 116 : Train loss 4.219488167203963, validation loss 8.339741706848145\n",
            "Complete prediction MSE : 0.0011896701339625293\n",
            "Epoch 117 : Train loss 4.17318314127624, validation loss 8.309957504272461\n",
            "Complete prediction MSE : 0.0011929083294654772\n",
            "Epoch 118 : Train loss 4.213081237394363, validation loss 8.723602294921875\n",
            "Complete prediction MSE : 0.0010588018714784693\n",
            "Epoch 119 : Train loss 4.145939274225384, validation loss 8.809523582458496\n",
            "Complete prediction MSE : 0.0012640115135515457\n",
            "Epoch 120 : Train loss 4.147821527440101, validation loss 8.890336990356445\n",
            "Complete prediction MSE : 0.0011495662304387842\n",
            "Epoch 121 : Train loss 4.170601022429764, validation loss 8.61610221862793\n",
            "Complete prediction MSE : 0.0012000281896521433\n",
            "Epoch 122 : Train loss 4.125347217544913, validation loss 8.583841323852539\n",
            "Complete prediction MSE : 0.0012100874322749629\n",
            "Epoch 123 : Train loss 4.119833234231919, validation loss 8.668180465698242\n",
            "Complete prediction MSE : 0.0011054459826506428\n",
            "Epoch 124 : Train loss 4.118454570882022, validation loss 9.46231746673584\n",
            "Complete prediction MSE : 0.0010952165207109088\n",
            "Epoch 125 : Train loss 4.15273645799607, validation loss 8.729735374450684\n",
            "Complete prediction MSE : 0.0012390638600496\n",
            "Epoch 126 : Train loss 4.109170692041516, validation loss 8.780196189880371\n",
            "Complete prediction MSE : 0.001118851861862539\n",
            "Epoch 127 : Train loss 4.0965537475422025, validation loss 8.472973823547363\n",
            "Complete prediction MSE : 0.0011548178966736022\n",
            "Epoch 128 : Train loss 4.130705025512725, validation loss 8.681415557861328\n",
            "Complete prediction MSE : 0.0011029494544547531\n",
            "Epoch 129 : Train loss 4.07226661266759, validation loss 8.297677993774414\n",
            "Complete prediction MSE : 0.0010833050255163283\n",
            "Epoch 130 : Train loss 4.107946666423231, validation loss 9.347722053527832\n",
            "Complete prediction MSE : 0.0011290697301704023\n",
            "Epoch 131 : Train loss 4.042940926738083, validation loss 8.632242202758789\n",
            "Complete prediction MSE : 0.0010802412546324117\n",
            "Epoch 132 : Train loss 4.0934832454659045, validation loss 9.118964195251465\n",
            "Complete prediction MSE : 0.0011559528958644159\n",
            "Epoch 133 : Train loss 4.050677089951932, validation loss 9.60496997833252\n",
            "Complete prediction MSE : 0.0010949797138254615\n",
            "Epoch 134 : Train loss 4.058870990760624, validation loss 8.293079376220703\n",
            "Complete prediction MSE : 0.0010257247790526607\n",
            "Epoch 135 : Train loss 4.045900609809905, validation loss 9.044868469238281\n",
            "Complete prediction MSE : 0.0010395992579316758\n",
            "Epoch 136 : Train loss 4.071039214730263, validation loss 8.681341171264648\n",
            "Complete prediction MSE : 0.0012149398283740744\n",
            "Epoch 137 : Train loss 4.037836321629584, validation loss 8.150854110717773\n",
            "Complete prediction MSE : 0.0011503951593117064\n",
            "Epoch 138 : Train loss 3.99987969128415, validation loss 8.62573528289795\n",
            "Complete prediction MSE : 0.0011560853650488903\n",
            "Epoch 139 : Train loss 4.024865129496902, validation loss 9.211164474487305\n",
            "Complete prediction MSE : 0.001149264311798425\n",
            "Epoch 140 : Train loss 4.067434350494295, validation loss 8.88782787322998\n",
            "Complete prediction MSE : 0.0010361299693903909\n",
            "Epoch 141 : Train loss 4.004031370859593, validation loss 8.406829833984375\n",
            "Complete prediction MSE : 0.0012652428468657674\n",
            "Epoch 142 : Train loss 3.963676830753684, validation loss 8.54697036743164\n",
            "Complete prediction MSE : 0.0010995733161444057\n",
            "Epoch 143 : Train loss 4.018607513047755, validation loss 8.35329532623291\n",
            "Complete prediction MSE : 0.001102076922921201\n",
            "Epoch 144 : Train loss 4.036157403606921, validation loss 8.663544654846191\n",
            "Complete prediction MSE : 0.0010511851424975182\n",
            "Epoch 145 : Train loss 3.988279585260898, validation loss 8.350248336791992\n",
            "Complete prediction MSE : 0.0011021134418260328\n",
            "Epoch 146 : Train loss 3.98323906539008, validation loss 8.979215621948242\n",
            "Complete prediction MSE : 0.0009934653922714781\n",
            "Epoch 147 : Train loss 4.005873758811504, validation loss 8.3919038772583\n",
            "Complete prediction MSE : 0.0011920594187359971\n",
            "Epoch 148 : Train loss 3.971691006794572, validation loss 8.97994327545166\n",
            "Complete prediction MSE : 0.001276497885148217\n",
            "Epoch 149 : Train loss 3.9676227159798145, validation loss 8.25229549407959\n",
            "Complete prediction MSE : 0.0011395568882513894\n",
            "Epoch 150 : Train loss 3.9846652881242335, validation loss 8.841910362243652\n",
            "Complete prediction MSE : 0.0010263847698953105\n",
            "Epoch 151 : Train loss 3.933904230594635, validation loss 8.73493480682373\n",
            "Complete prediction MSE : 0.0011436280176258396\n",
            "Epoch 152 : Train loss 3.957765887491405, validation loss 8.089287757873535\n",
            "Complete prediction MSE : 0.0010596594027006087\n",
            "Epoch 153 : Train loss 3.9454160071909428, validation loss 8.738020896911621\n",
            "Complete prediction MSE : 0.0011212957072175512\n",
            "Epoch 154 : Train loss 3.9277010657824576, validation loss 9.223471641540527\n",
            "Complete prediction MSE : 0.0009889079978708146\n",
            "Saving model\n",
            "Epoch 155 : Train loss 3.964884460903704, validation loss 8.296631813049316\n",
            "Complete prediction MSE : 0.0010490639015390067\n",
            "Epoch 156 : Train loss 3.9085489735007286, validation loss 8.3236665725708\n",
            "Complete prediction MSE : 0.0010624239860454535\n",
            "Epoch 157 : Train loss 3.9093405227176845, validation loss 8.514451026916504\n",
            "Complete prediction MSE : 0.000969037843239825\n",
            "Saving model\n",
            "Epoch 158 : Train loss 3.922578661236912, validation loss 8.087725639343262\n",
            "Complete prediction MSE : 0.0009834489404344175\n",
            "Epoch 159 : Train loss 3.925982788670808, validation loss 8.793886184692383\n",
            "Complete prediction MSE : 0.0009708224089588882\n",
            "Epoch 160 : Train loss 3.9533293689601123, validation loss 8.016718864440918\n",
            "Complete prediction MSE : 0.0011700517778121355\n",
            "Epoch 161 : Train loss 3.946336744353175, validation loss 8.573229789733887\n",
            "Complete prediction MSE : 0.001063325445552163\n",
            "Epoch 162 : Train loss 3.909968418069184, validation loss 8.164055824279785\n",
            "Complete prediction MSE : 0.001063224208947948\n",
            "Epoch 163 : Train loss 3.9306228742934763, validation loss 8.132509231567383\n",
            "Complete prediction MSE : 0.0011482942873727118\n",
            "Epoch 164 : Train loss 3.899233581032604, validation loss 8.561079025268555\n",
            "Complete prediction MSE : 0.0009785994852238025\n",
            "Epoch 165 : Train loss 3.933977419976145, validation loss 8.123958587646484\n",
            "Complete prediction MSE : 0.0009693274271726984\n",
            "Epoch 166 : Train loss 3.9142617573961616, validation loss 8.214033126831055\n",
            "Complete prediction MSE : 0.0012727623929511265\n",
            "Epoch 167 : Train loss 3.903181793168187, validation loss 8.87002182006836\n",
            "Complete prediction MSE : 0.0011491061847234197\n",
            "Epoch 168 : Train loss 3.8708945396356285, validation loss 9.078993797302246\n",
            "Complete prediction MSE : 0.0010209214188150368\n",
            "Epoch 169 : Train loss 3.881818888243288, validation loss 8.29621696472168\n",
            "Complete prediction MSE : 0.0011424530741292848\n",
            "Epoch 170 : Train loss 3.8822662052698433, validation loss 8.678122520446777\n",
            "Complete prediction MSE : 0.001015781282814557\n",
            "Epoch 171 : Train loss 3.866573166102171, validation loss 8.647128105163574\n",
            "Complete prediction MSE : 0.0010389683099519041\n",
            "Epoch 172 : Train loss 3.8943050224334, validation loss 8.113184928894043\n",
            "Complete prediction MSE : 0.0010387952370365138\n",
            "Epoch 173 : Train loss 3.879188198596239, validation loss 8.477654457092285\n",
            "Complete prediction MSE : 0.0011017175570650285\n",
            "Epoch 174 : Train loss 3.87418162683025, validation loss 8.149748802185059\n",
            "Complete prediction MSE : 0.0009464601959575932\n",
            "Saving model\n",
            "Epoch 175 : Train loss 3.8636460630223155, validation loss 8.2869291305542\n",
            "Complete prediction MSE : 0.0009947648116052795\n",
            "Epoch 176 : Train loss 3.905468745622784, validation loss 8.389535903930664\n",
            "Complete prediction MSE : 0.0009715116791096161\n",
            "Epoch 177 : Train loss 3.8689151350408792, validation loss 8.470541954040527\n",
            "Complete prediction MSE : 0.0010881569277737366\n",
            "Epoch 178 : Train loss 3.8952426644973457, validation loss 9.053084373474121\n",
            "Complete prediction MSE : 0.0012836639609859468\n",
            "Epoch 179 : Train loss 3.8341517904773355, validation loss 8.238737106323242\n",
            "Complete prediction MSE : 0.001003909334993159\n",
            "Epoch 180 : Train loss 3.8215077430941164, validation loss 8.460685729980469\n",
            "Complete prediction MSE : 0.00104133768084846\n",
            "Epoch 181 : Train loss 3.8704095748253167, validation loss 8.196310043334961\n",
            "Complete prediction MSE : 0.0015503255263265518\n",
            "Epoch 182 : Train loss 3.8454468976706266, validation loss 9.277607917785645\n",
            "Complete prediction MSE : 0.00110641035061905\n",
            "Epoch 183 : Train loss 3.7873459104448557, validation loss 8.997742652893066\n",
            "Complete prediction MSE : 0.0010233644782004306\n",
            "Epoch 184 : Train loss 3.8905198550783098, validation loss 8.5953950881958\n",
            "Complete prediction MSE : 0.0009564840926442416\n",
            "Epoch 185 : Train loss 3.797514710109681, validation loss 8.281150817871094\n",
            "Complete prediction MSE : 0.0011101629167623616\n",
            "Epoch 186 : Train loss 3.8179103918373585, validation loss 7.832920074462891\n",
            "Complete prediction MSE : 0.0010424939747277527\n",
            "Epoch 187 : Train loss 3.8271515388041735, validation loss 8.501005172729492\n",
            "Complete prediction MSE : 0.0012392064205151293\n",
            "Epoch 188 : Train loss 3.805185246746987, validation loss 9.072197914123535\n",
            "Complete prediction MSE : 0.001024213162731133\n",
            "Epoch 189 : Train loss 3.8129588728770614, validation loss 8.700913429260254\n",
            "Complete prediction MSE : 0.0009331568776945815\n",
            "Saving model\n",
            "Epoch 190 : Train loss 3.784659023396671, validation loss 8.438124656677246\n",
            "Complete prediction MSE : 0.0013283462651309066\n",
            "Epoch 191 : Train loss 3.8164298040792346, validation loss 8.245473861694336\n",
            "Complete prediction MSE : 0.0011197046713015077\n",
            "Epoch 192 : Train loss 3.8521069795824587, validation loss 8.432927131652832\n",
            "Complete prediction MSE : 0.0011843487323906121\n",
            "Epoch 193 : Train loss 3.778284854721278, validation loss 8.430929183959961\n",
            "Complete prediction MSE : 0.0009515012499972671\n",
            "Epoch 194 : Train loss 3.7980954805389047, validation loss 8.502267837524414\n",
            "Complete prediction MSE : 0.0010071727258463997\n",
            "Epoch 195 : Train loss 3.825604636222124, validation loss 8.962509155273438\n",
            "Complete prediction MSE : 0.0011478863886927259\n",
            "Epoch 196 : Train loss 3.8094623587094247, validation loss 8.344371795654297\n",
            "Complete prediction MSE : 0.0010636576014340167\n",
            "Epoch 197 : Train loss 3.7904258989728987, validation loss 8.819947242736816\n",
            "Complete prediction MSE : 0.0010349514882112625\n",
            "Epoch 198 : Train loss 3.7773755621165037, validation loss 8.96346664428711\n",
            "Complete prediction MSE : 0.0009326516600620604\n",
            "Saving model\n",
            "Epoch 199 : Train loss 3.8687067036516964, validation loss 8.738490104675293\n",
            "Complete prediction MSE : 0.0012829257884221516\n",
            "Epoch 200 : Train loss 3.7940793111920357, validation loss 8.909796714782715\n",
            "Complete prediction MSE : 0.0010487570345864888\n",
            "Epoch 201 : Train loss 3.7663252484053373, validation loss 8.418705940246582\n",
            "Complete prediction MSE : 0.0012336336461230772\n",
            "Epoch 202 : Train loss 3.7862318512052298, validation loss 9.03502082824707\n",
            "Complete prediction MSE : 0.0009238581040354938\n",
            "Saving model\n",
            "Epoch 203 : Train loss 3.7760306959971786, validation loss 9.041740417480469\n",
            "Complete prediction MSE : 0.0010797884232074536\n",
            "Epoch 204 : Train loss 3.739753597881645, validation loss 7.917428970336914\n",
            "Complete prediction MSE : 0.0009940561474546896\n",
            "Epoch 205 : Train loss 3.7755637387745082, validation loss 8.390765190124512\n",
            "Complete prediction MSE : 0.0011895694190069566\n",
            "Epoch 206 : Train loss 3.769050680100918, validation loss 8.389435768127441\n",
            "Complete prediction MSE : 0.001103805781454437\n",
            "Epoch 207 : Train loss 3.7409616471268237, validation loss 8.853994369506836\n",
            "Complete prediction MSE : 0.0009896400723756452\n",
            "Epoch 208 : Train loss 3.758337660692632, validation loss 8.572957992553711\n",
            "Complete prediction MSE : 0.0010812777488263842\n",
            "Epoch 209 : Train loss 3.8152567269280553, validation loss 8.578498840332031\n",
            "Complete prediction MSE : 0.0011112089421146515\n",
            "Epoch 210 : Train loss 3.7126857810653746, validation loss 8.390602111816406\n",
            "Complete prediction MSE : 0.001002887481264193\n",
            "Epoch 211 : Train loss 3.7371362769044936, validation loss 8.149758338928223\n",
            "Complete prediction MSE : 0.0009902922768889493\n",
            "Epoch 212 : Train loss 3.788912361022085, validation loss 9.060323715209961\n",
            "Complete prediction MSE : 0.001193650008809755\n",
            "Epoch 213 : Train loss 3.7357325656339526, validation loss 9.066984176635742\n",
            "Complete prediction MSE : 0.0014501712386524835\n",
            "Epoch 214 : Train loss 3.74489766638726, validation loss 8.387882232666016\n",
            "Complete prediction MSE : 0.0011372614438928726\n",
            "Epoch 215 : Train loss 3.778759785462171, validation loss 9.119433403015137\n",
            "Complete prediction MSE : 0.0012467417448234405\n",
            "Epoch 216 : Train loss 3.7416256377473474, validation loss 9.219762802124023\n",
            "Complete prediction MSE : 0.0009910291842209404\n",
            "Epoch 217 : Train loss 3.7122876662760973, validation loss 8.846811294555664\n",
            "Complete prediction MSE : 0.0010771053224062418\n",
            "Epoch 218 : Train loss 3.76448015216738, validation loss 8.726373672485352\n",
            "Complete prediction MSE : 0.0009793246826883199\n",
            "Epoch 219 : Train loss 3.724670968018472, validation loss 8.420031547546387\n",
            "Complete prediction MSE : 0.0014178439894313995\n",
            "Epoch 220 : Train loss 3.7530685290694237, validation loss 8.799108505249023\n",
            "Complete prediction MSE : 0.0010391194298731744\n",
            "Epoch 221 : Train loss 3.7271981555968523, validation loss 8.105886459350586\n",
            "Complete prediction MSE : 0.0010096334766737133\n",
            "Epoch 222 : Train loss 3.7040236513130367, validation loss 8.797447204589844\n",
            "Complete prediction MSE : 0.001172788529576562\n",
            "Epoch 223 : Train loss 3.732444698456675, validation loss 8.750601768493652\n",
            "Complete prediction MSE : 0.0012932165137080126\n",
            "Epoch 224 : Train loss 3.7638876303099096, validation loss 8.213556289672852\n",
            "Complete prediction MSE : 0.0010744825478790172\n",
            "Epoch 225 : Train loss 3.6981711853295565, validation loss 8.465448379516602\n",
            "Complete prediction MSE : 0.001150029119259627\n",
            "Epoch 226 : Train loss 3.7299036723561585, validation loss 8.349120140075684\n",
            "Complete prediction MSE : 0.0020056454757897864\n",
            "Epoch 227 : Train loss 3.7412610151804984, validation loss 8.741644859313965\n",
            "Complete prediction MSE : 0.0012784219050641888\n",
            "Epoch 228 : Train loss 3.6670111566781998, validation loss 8.924288749694824\n",
            "Complete prediction MSE : 0.0013343791296526368\n",
            "Epoch 229 : Train loss 3.701802277006209, validation loss 8.568413734436035\n",
            "Complete prediction MSE : 0.001001153172801601\n",
            "Epoch 230 : Train loss 3.700071258470416, validation loss 9.005834579467773\n",
            "Complete prediction MSE : 0.0011874099903265108\n",
            "Epoch 231 : Train loss 3.7124933884479105, validation loss 8.817936897277832\n",
            "Complete prediction MSE : 0.0009565226701722414\n",
            "Epoch 232 : Train loss 3.7257094983942807, validation loss 9.00484848022461\n",
            "Complete prediction MSE : 0.00116737317736899\n",
            "Epoch 233 : Train loss 3.711426787544042, validation loss 8.895856857299805\n",
            "Complete prediction MSE : 0.0011528838103876313\n",
            "Epoch 234 : Train loss 3.6816341737285256, validation loss 8.41891098022461\n",
            "Complete prediction MSE : 0.0010577324471193405\n",
            "Epoch 235 : Train loss 3.7263541133143008, validation loss 8.292521476745605\n",
            "Complete prediction MSE : 0.0010353931859749268\n",
            "Epoch 236 : Train loss 3.7070734882727265, validation loss 8.476190567016602\n",
            "Complete prediction MSE : 0.0014580525542245096\n",
            "Epoch 237 : Train loss 3.6967537961900234, validation loss 8.272980690002441\n",
            "Complete prediction MSE : 0.001093813620487952\n",
            "Epoch 238 : Train loss 3.6687481123954058, validation loss 9.129890441894531\n",
            "Complete prediction MSE : 0.0010862993886734892\n",
            "Epoch 239 : Train loss 3.6741697271354496, validation loss 8.7646484375\n",
            "Complete prediction MSE : 0.0012276448035230575\n",
            "Epoch 240 : Train loss 3.6925792205147445, validation loss 9.589118003845215\n",
            "Complete prediction MSE : 0.0014003211817784657\n",
            "Epoch 241 : Train loss 3.693575437180698, validation loss 8.938274383544922\n",
            "Complete prediction MSE : 0.0009889946689626123\n",
            "Epoch 242 : Train loss 3.6523989657871425, validation loss 8.651375770568848\n",
            "Complete prediction MSE : 0.0010087949127611546\n",
            "Epoch 243 : Train loss 3.6606597807258368, validation loss 8.766949653625488\n",
            "Complete prediction MSE : 0.0012046118461818984\n",
            "Epoch 244 : Train loss 3.7331814682111144, validation loss 8.253410339355469\n",
            "Complete prediction MSE : 0.001147309176751285\n",
            "Epoch 245 : Train loss 3.695483621675521, validation loss 9.559850692749023\n",
            "Complete prediction MSE : 0.000870320974827061\n",
            "Saving model\n",
            "Epoch 246 : Train loss 3.6903858319856226, validation loss 8.467055320739746\n",
            "Complete prediction MSE : 0.0013203188737314422\n",
            "Epoch 247 : Train loss 3.6747753536328673, validation loss 9.23543643951416\n",
            "Complete prediction MSE : 0.0009221850250421524\n",
            "Epoch 248 : Train loss 3.6533156274817884, validation loss 8.576496124267578\n",
            "Complete prediction MSE : 0.000933262155210404\n",
            "Epoch 249 : Train loss 3.63318576477468, validation loss 8.236234664916992\n",
            "Complete prediction MSE : 0.0009737540097246734\n",
            "Epoch 250 : Train loss 3.6625021127983928, validation loss 7.98212194442749\n",
            "Complete prediction MSE : 0.0009211255268991349\n",
            "Epoch 251 : Train loss 3.7339530871249735, validation loss 8.62778377532959\n",
            "Complete prediction MSE : 0.0014938725145270603\n",
            "Epoch 252 : Train loss 3.622720697429031, validation loss 8.236614227294922\n",
            "Complete prediction MSE : 0.0010773656924216717\n",
            "Epoch 253 : Train loss 3.6516873915679753, validation loss 8.080153465270996\n",
            "Complete prediction MSE : 0.0013731983760239663\n",
            "Epoch 254 : Train loss 3.6774009596556425, validation loss 8.808087348937988\n",
            "Complete prediction MSE : 0.0008634606568788665\n",
            "Saving model\n",
            "Epoch 255 : Train loss 3.6372599215246737, validation loss 8.731161117553711\n",
            "Complete prediction MSE : 0.0011767607764955083\n",
            "Epoch 256 : Train loss 3.656116128899157, validation loss 8.674506187438965\n",
            "Complete prediction MSE : 0.0013728340271520051\n",
            "Epoch 257 : Train loss 3.6799532510340214, validation loss 9.03976058959961\n",
            "Complete prediction MSE : 0.001502476876596333\n",
            "Epoch 258 : Train loss 3.6830691192299128, validation loss 9.08343505859375\n",
            "Complete prediction MSE : 0.0014591012196982418\n",
            "Epoch 259 : Train loss 3.665337307844311, validation loss 8.367345809936523\n",
            "Complete prediction MSE : 0.0008796312336794207\n",
            "Epoch 260 : Train loss 3.6662886710837483, validation loss 8.296592712402344\n",
            "Complete prediction MSE : 0.0010469312434119487\n",
            "Epoch 261 : Train loss 3.6584333004429936, validation loss 8.31395149230957\n",
            "Complete prediction MSE : 0.000904161851577264\n",
            "Epoch 262 : Train loss 3.651319124735892, validation loss 8.482197761535645\n",
            "Complete prediction MSE : 0.0009846859649032755\n",
            "Epoch 263 : Train loss 3.67111360700801, validation loss 8.766918182373047\n",
            "Complete prediction MSE : 0.0008794879335049952\n",
            "Epoch 264 : Train loss 3.5977826421149075, validation loss 8.623937606811523\n",
            "Complete prediction MSE : 0.0008586768853211028\n",
            "Saving model\n",
            "Epoch 265 : Train loss 3.6582446065731347, validation loss 9.657700538635254\n",
            "Complete prediction MSE : 0.0008997622225760051\n",
            "Epoch 266 : Train loss 3.6459841039031744, validation loss 9.093802452087402\n",
            "Complete prediction MSE : 0.0009950649700678914\n",
            "Epoch 267 : Train loss 3.641187235713005, validation loss 8.411630630493164\n",
            "Complete prediction MSE : 0.001019380327035353\n",
            "Epoch 268 : Train loss 3.6565409544855356, validation loss 9.242547035217285\n",
            "Complete prediction MSE : 0.0010207640857889397\n",
            "Epoch 269 : Train loss 3.6609053784050047, validation loss 8.272478103637695\n",
            "Complete prediction MSE : 0.0011689556806067053\n",
            "Epoch 270 : Train loss 3.634055469650775, validation loss 8.747291564941406\n",
            "Complete prediction MSE : 0.0008865064469008585\n",
            "Epoch 271 : Train loss 3.636596334632486, validation loss 8.597562789916992\n",
            "Complete prediction MSE : 0.0012479144589248377\n",
            "Epoch 272 : Train loss 3.644576229620725, validation loss 8.215529441833496\n",
            "Complete prediction MSE : 0.001313452769620437\n",
            "Epoch 273 : Train loss 3.6332980915904045, validation loss 8.47538948059082\n",
            "Complete prediction MSE : 0.0013005747656085428\n",
            "Epoch 274 : Train loss 3.584402737673372, validation loss 8.920788764953613\n",
            "Complete prediction MSE : 0.0009418666041855999\n",
            "Epoch 275 : Train loss 3.609101607464254, validation loss 8.233355522155762\n",
            "Complete prediction MSE : 0.0009818931138014903\n",
            "Epoch 276 : Train loss 3.6089190584607422, validation loss 8.777183532714844\n",
            "Complete prediction MSE : 0.0008680420691412688\n",
            "Epoch 277 : Train loss 3.646888989955187, validation loss 7.86306095123291\n",
            "Complete prediction MSE : 0.0010887771823200967\n",
            "Epoch 278 : Train loss 3.594829013571143, validation loss 9.070426940917969\n",
            "Complete prediction MSE : 0.0010189562297043303\n",
            "Epoch 279 : Train loss 3.6536092213355005, validation loss 8.906580924987793\n",
            "Complete prediction MSE : 0.0010368222570945771\n",
            "Epoch 280 : Train loss 3.6089681098237634, validation loss 8.943010330200195\n",
            "Complete prediction MSE : 0.0013646443551082058\n",
            "Epoch 281 : Train loss 3.642044820357114, validation loss 9.109476089477539\n",
            "Complete prediction MSE : 0.0011490942243980195\n",
            "Epoch 282 : Train loss 3.6097724083811045, validation loss 8.950551986694336\n",
            "Complete prediction MSE : 0.0011809295918934805\n",
            "Epoch 283 : Train loss 3.597191098611802, validation loss 9.483813285827637\n",
            "Complete prediction MSE : 0.0010979816997728899\n",
            "Epoch 284 : Train loss 3.593091548420489, validation loss 8.7877779006958\n",
            "Complete prediction MSE : 0.0011464406201341767\n",
            "Epoch 285 : Train loss 3.610818101093173, validation loss 8.959956169128418\n",
            "Complete prediction MSE : 0.000867428056241565\n",
            "Epoch 286 : Train loss 3.663422374520451, validation loss 8.973344802856445\n",
            "Complete prediction MSE : 0.0010059273142552074\n",
            "Epoch 287 : Train loss 3.6010945634916425, validation loss 9.101119041442871\n",
            "Complete prediction MSE : 0.0008580298812695323\n",
            "Saving model\n",
            "Epoch 288 : Train loss 3.5927284681238234, validation loss 9.096980094909668\n",
            "Complete prediction MSE : 0.0008711892007686458\n",
            "Epoch 289 : Train loss 3.6067954222671688, validation loss 8.618587493896484\n",
            "Complete prediction MSE : 0.0010311081750891396\n",
            "Epoch 290 : Train loss 3.6165002789348364, validation loss 8.99704360961914\n",
            "Complete prediction MSE : 0.0009732762236848579\n",
            "Epoch 291 : Train loss 3.616587738506496, validation loss 8.760284423828125\n",
            "Complete prediction MSE : 0.0011965572680317919\n",
            "Epoch 292 : Train loss 3.6355878128670156, validation loss 7.883765697479248\n",
            "Complete prediction MSE : 0.0011551143917925427\n",
            "Epoch 293 : Train loss 3.565674431156367, validation loss 8.829174995422363\n",
            "Complete prediction MSE : 0.0008751075627015545\n",
            "Epoch 294 : Train loss 3.590213932096958, validation loss 8.815170288085938\n",
            "Complete prediction MSE : 0.0010027543859709108\n",
            "Epoch 295 : Train loss 3.645699479151517, validation loss 9.133560180664062\n",
            "Complete prediction MSE : 0.0008889946596298485\n",
            "Epoch 296 : Train loss 3.5799253256991506, validation loss 9.450703620910645\n",
            "Complete prediction MSE : 0.0010194632496116664\n",
            "Epoch 297 : Train loss 3.6459453818388283, validation loss 8.635088920593262\n",
            "Complete prediction MSE : 0.001479303352322233\n",
            "Epoch 298 : Train loss 3.577991815749556, validation loss 10.16771411895752\n",
            "Complete prediction MSE : 0.0008472001843332384\n",
            "Saving model\n",
            "Epoch 299 : Train loss 3.627750322688371, validation loss 8.843838691711426\n",
            "Complete prediction MSE : 0.0011285723551523645\n",
            "Epoch 300 : Train loss 3.5883318125270307, validation loss 8.609554290771484\n",
            "Complete prediction MSE : 0.000907580489225256\n",
            "Epoch 301 : Train loss 3.6410411642864347, validation loss 8.350693702697754\n",
            "Complete prediction MSE : 0.001115035349067786\n",
            "Epoch 302 : Train loss 3.557655803859234, validation loss 8.852828025817871\n",
            "Complete prediction MSE : 0.0010818786778056628\n",
            "Epoch 303 : Train loss 3.6013305066153407, validation loss 8.903755187988281\n",
            "Complete prediction MSE : 0.0013490189054225536\n",
            "Epoch 304 : Train loss 3.5913594528101385, validation loss 9.63695240020752\n",
            "Complete prediction MSE : 0.0008888543982723024\n",
            "Epoch 305 : Train loss 3.6034481250680983, validation loss 9.749570846557617\n",
            "Complete prediction MSE : 0.0011799288628444285\n",
            "Epoch 306 : Train loss 3.6199363404884934, validation loss 9.532513618469238\n",
            "Complete prediction MSE : 0.0012650803189146916\n",
            "Epoch 307 : Train loss 3.602895569987595, validation loss 8.8350830078125\n",
            "Complete prediction MSE : 0.0009049846563275717\n",
            "Epoch 308 : Train loss 3.5713947359472513, validation loss 10.077120780944824\n",
            "Complete prediction MSE : 0.0011854060307428384\n",
            "Epoch 309 : Train loss 3.608284825924784, validation loss 8.811992645263672\n",
            "Complete prediction MSE : 0.000986245169423401\n",
            "Epoch 310 : Train loss 3.5914073497988284, validation loss 8.952651977539062\n",
            "Complete prediction MSE : 0.001257487091974578\n",
            "Epoch 311 : Train loss 3.5654367553070188, validation loss 9.37394905090332\n",
            "Complete prediction MSE : 0.0013184045200027802\n",
            "Epoch 312 : Train loss 3.558648741338402, validation loss 8.280136108398438\n",
            "Complete prediction MSE : 0.001095557637283263\n",
            "Epoch 313 : Train loss 3.5861279158852994, validation loss 8.416059494018555\n",
            "Complete prediction MSE : 0.001108684635399766\n",
            "Epoch 314 : Train loss 3.5926349656656384, validation loss 8.172558784484863\n",
            "Complete prediction MSE : 0.0008592675572333471\n",
            "Epoch 315 : Train loss 3.574457138776779, validation loss 8.715758323669434\n",
            "Complete prediction MSE : 0.0010676488895234768\n",
            "Epoch 316 : Train loss 3.5913561722263694, validation loss 8.906492233276367\n",
            "Complete prediction MSE : 0.001246763174186916\n",
            "Epoch 317 : Train loss 3.567714526783675, validation loss 8.730388641357422\n",
            "Complete prediction MSE : 0.0009815481150793224\n",
            "Epoch 318 : Train loss 3.6247196290642023, validation loss 8.537131309509277\n",
            "Complete prediction MSE : 0.000999209362273798\n",
            "Epoch 319 : Train loss 3.6132507417351007, validation loss 9.11689567565918\n",
            "Complete prediction MSE : 0.0009567294038785202\n",
            "Epoch 320 : Train loss 3.5958843184635043, validation loss 9.481801986694336\n",
            "Complete prediction MSE : 0.0011145103911595908\n",
            "Epoch 321 : Train loss 3.564366640523076, validation loss 7.872045993804932\n",
            "Complete prediction MSE : 0.0008509701199014867\n",
            "Epoch 322 : Train loss 3.544936397112906, validation loss 9.303471565246582\n",
            "Complete prediction MSE : 0.001004626769820317\n",
            "Epoch 323 : Train loss 3.593227095436305, validation loss 9.151449203491211\n",
            "Complete prediction MSE : 0.001318947005801675\n",
            "Epoch 324 : Train loss 3.552217399235815, validation loss 9.237070083618164\n",
            "Complete prediction MSE : 0.0010723808452647622\n",
            "Epoch 325 : Train loss 3.547820960637182, validation loss 8.621952056884766\n",
            "Complete prediction MSE : 0.0010541421697917522\n",
            "Epoch 326 : Train loss 3.5643862611614168, validation loss 10.410710334777832\n",
            "Complete prediction MSE : 0.001066962227395354\n",
            "Epoch 327 : Train loss 3.5974334538914263, validation loss 8.568819999694824\n",
            "Complete prediction MSE : 0.0010094150902268078\n",
            "Epoch 328 : Train loss 3.5578670408576727, validation loss 8.925559997558594\n",
            "Complete prediction MSE : 0.0010147246209254843\n",
            "Epoch 329 : Train loss 3.5333742685616016, validation loss 9.454198837280273\n",
            "Complete prediction MSE : 0.0008793024942534102\n",
            "Epoch 330 : Train loss 3.530910083092749, validation loss 8.341135025024414\n",
            "Complete prediction MSE : 0.0008224826707910737\n",
            "Saving model\n",
            "Epoch 331 : Train loss 3.588736887089908, validation loss 7.9995527267456055\n",
            "Complete prediction MSE : 0.0010408914421488383\n",
            "Epoch 332 : Train loss 3.5271908743306994, validation loss 8.611187934875488\n",
            "Complete prediction MSE : 0.0010019661908519664\n",
            "Epoch 333 : Train loss 3.597619552630931, validation loss 8.649558067321777\n",
            "Complete prediction MSE : 0.0009860909145152678\n",
            "Epoch 334 : Train loss 3.572173989377916, validation loss 7.91408634185791\n",
            "Complete prediction MSE : 0.001134824216474831\n",
            "Epoch 335 : Train loss 3.60468697687611, validation loss 10.57686710357666\n",
            "Complete prediction MSE : 0.0012692438652780191\n",
            "Epoch 336 : Train loss 3.5848577334545553, validation loss 8.452726364135742\n",
            "Complete prediction MSE : 0.0009542550138190088\n",
            "Epoch 337 : Train loss 3.5498898420482874, validation loss 8.279261589050293\n",
            "Complete prediction MSE : 0.0010048194430492077\n",
            "Epoch 338 : Train loss 3.585436813533306, validation loss 8.183549880981445\n",
            "Complete prediction MSE : 0.0011594263227151503\n",
            "Epoch 339 : Train loss 3.555505894590169, validation loss 8.563544273376465\n",
            "Complete prediction MSE : 0.0011342303737853338\n",
            "Epoch 340 : Train loss 3.5430772597901523, validation loss 9.412808418273926\n",
            "Complete prediction MSE : 0.001254709063106901\n",
            "Epoch 341 : Train loss 3.5527183804661036, validation loss 8.292031288146973\n",
            "Complete prediction MSE : 0.0009246103748719544\n",
            "Epoch 342 : Train loss 3.5927819344215095, validation loss 7.828752517700195\n",
            "Complete prediction MSE : 0.0009344629116311528\n",
            "Epoch 343 : Train loss 3.4932791045866907, validation loss 8.719481468200684\n",
            "Complete prediction MSE : 0.0009633824330444746\n",
            "Epoch 344 : Train loss 3.5470620901323855, validation loss 8.489264488220215\n",
            "Complete prediction MSE : 0.000935851063458404\n",
            "Epoch 345 : Train loss 3.5586966341361403, validation loss 8.633286476135254\n",
            "Complete prediction MSE : 0.0009161470550104172\n",
            "Epoch 346 : Train loss 3.531176732853055, validation loss 8.02734375\n",
            "Complete prediction MSE : 0.0010617352904459018\n",
            "Epoch 347 : Train loss 3.5097798509523273, validation loss 8.643635749816895\n",
            "Complete prediction MSE : 0.0009121436694433091\n",
            "Epoch 348 : Train loss 3.5700538814999163, validation loss 8.59271240234375\n",
            "Complete prediction MSE : 0.0009858179343581776\n",
            "Epoch 349 : Train loss 3.5596428867429495, validation loss 8.708736419677734\n",
            "Complete prediction MSE : 0.001102629771014065\n",
            "Epoch 350 : Train loss 3.5867387293837965, validation loss 8.280388832092285\n",
            "Complete prediction MSE : 0.0010014033842582755\n",
            "Epoch 351 : Train loss 3.552083978895098, validation loss 9.0446138381958\n",
            "Complete prediction MSE : 0.0009672456591733761\n",
            "Epoch 352 : Train loss 3.522878556512296, validation loss 8.989882469177246\n",
            "Complete prediction MSE : 0.0009984301333711974\n",
            "Epoch 353 : Train loss 3.5235206414945424, validation loss 8.40713119506836\n",
            "Complete prediction MSE : 0.0008528349358827148\n",
            "Epoch 354 : Train loss 3.5588339529931545, validation loss 8.565122604370117\n",
            "Complete prediction MSE : 0.001379642635793639\n",
            "Epoch 355 : Train loss 3.5480374223552644, validation loss 8.738412857055664\n",
            "Complete prediction MSE : 0.0009082995176978702\n",
            "Epoch 356 : Train loss 3.580342845991254, validation loss 8.043676376342773\n",
            "Complete prediction MSE : 0.001039245938484617\n",
            "Epoch 357 : Train loss 3.4923404827713966, validation loss 9.080719947814941\n",
            "Complete prediction MSE : 0.000960636776680444\n",
            "Epoch 358 : Train loss 3.5404090671800077, validation loss 8.785758972167969\n",
            "Complete prediction MSE : 0.0011199184447888582\n",
            "Epoch 359 : Train loss 3.5106866783462465, validation loss 8.85520076751709\n",
            "Complete prediction MSE : 0.000905312272455682\n",
            "Epoch 360 : Train loss 3.521544886287302, validation loss 8.342947959899902\n",
            "Complete prediction MSE : 0.0009169445449124673\n",
            "Epoch 361 : Train loss 3.553196060936898, validation loss 9.659544944763184\n",
            "Complete prediction MSE : 0.0009255313572461288\n",
            "Epoch 362 : Train loss 3.5731161618605256, validation loss 9.064430236816406\n",
            "Complete prediction MSE : 0.0009668078620923088\n",
            "Epoch 363 : Train loss 3.5428991885855794, validation loss 9.011809349060059\n",
            "Complete prediction MSE : 0.0009392154303475398\n",
            "Epoch 364 : Train loss 3.5630372809246182, validation loss 8.072717666625977\n",
            "Complete prediction MSE : 0.001153021650418769\n",
            "Epoch 365 : Train loss 3.5486720707267523, validation loss 8.98471450805664\n",
            "Complete prediction MSE : 0.0012695978367482264\n",
            "Epoch 366 : Train loss 3.5531509066931903, validation loss 8.799044609069824\n",
            "Complete prediction MSE : 0.0009236496093650931\n",
            "Epoch 367 : Train loss 3.536439644638449, validation loss 8.440540313720703\n",
            "Complete prediction MSE : 0.0009310157185376374\n",
            "Epoch 368 : Train loss 3.5474602337926626, validation loss 9.156140327453613\n",
            "Complete prediction MSE : 0.0008942374627409787\n",
            "Epoch 369 : Train loss 3.4942654189653695, validation loss 8.287444114685059\n",
            "Complete prediction MSE : 0.0009167854328541762\n",
            "Epoch 370 : Train loss 3.542395715136081, validation loss 8.888635635375977\n",
            "Complete prediction MSE : 0.0010133149431209069\n",
            "Epoch 371 : Train loss 3.5081989467144012, validation loss 9.13092041015625\n",
            "Complete prediction MSE : 0.0008930260644372541\n",
            "Epoch 372 : Train loss 3.529863240662962, validation loss 9.257332801818848\n",
            "Complete prediction MSE : 0.0009572613225706497\n",
            "Epoch 373 : Train loss 3.560017828363925, validation loss 8.073089599609375\n",
            "Complete prediction MSE : 0.0009496014270049043\n",
            "Epoch 374 : Train loss 3.536293105222285, validation loss 10.023293495178223\n",
            "Complete prediction MSE : 0.0009485341967173001\n",
            "Epoch 375 : Train loss 3.520210530143231, validation loss 8.70980167388916\n",
            "Complete prediction MSE : 0.001209759461885601\n",
            "Epoch 376 : Train loss 3.528852644842118, validation loss 8.362574577331543\n",
            "Complete prediction MSE : 0.0009240350015101644\n",
            "Epoch 377 : Train loss 3.5171094750985503, validation loss 9.11404800415039\n",
            "Complete prediction MSE : 0.001319436331349731\n",
            "Epoch 378 : Train loss 3.486401761882007, validation loss 8.196748733520508\n",
            "Complete prediction MSE : 0.0010754990742696247\n",
            "Epoch 379 : Train loss 3.4971056622453034, validation loss 8.966775894165039\n",
            "Complete prediction MSE : 0.001009298363901505\n",
            "Epoch 380 : Train loss 3.491126224398613, validation loss 8.539017677307129\n",
            "Complete prediction MSE : 0.001101105311861238\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 1\n",
            "Epoch 1 : Train loss 36.147935727611184, validation loss 21.358610153198242\n",
            "Complete prediction MSE : 0.0041248350791392874\n",
            "Saving model\n",
            "Epoch 2 : Train loss 15.307176321744919, validation loss 16.387849807739258\n",
            "Complete prediction MSE : 0.003301172917535211\n",
            "Saving model\n",
            "Epoch 3 : Train loss 13.317464902997017, validation loss 12.311208724975586\n",
            "Complete prediction MSE : 0.0027884116038471114\n",
            "Saving model\n",
            "Epoch 4 : Train loss 12.830143563449383, validation loss 8.366332054138184\n",
            "Complete prediction MSE : 0.002720662566390427\n",
            "Saving model\n",
            "Epoch 5 : Train loss 11.413664504885674, validation loss 9.575331687927246\n",
            "Complete prediction MSE : 0.002942225127591899\n",
            "Epoch 6 : Train loss 10.946217911317945, validation loss 8.458000183105469\n",
            "Complete prediction MSE : 0.002762166174618019\n",
            "Epoch 7 : Train loss 11.194125436246395, validation loss 9.290701866149902\n",
            "Complete prediction MSE : 0.0030420712748568768\n",
            "Epoch 8 : Train loss 10.027150413021445, validation loss 11.00457763671875\n",
            "Complete prediction MSE : 0.002993036553188199\n",
            "Epoch 9 : Train loss 46.315373722463846, validation loss 18.945892333984375\n",
            "Complete prediction MSE : 0.0030460030831120162\n",
            "Epoch 10 : Train loss 19.204799853265285, validation loss 17.033004760742188\n",
            "Complete prediction MSE : 0.002702059003249694\n",
            "Saving model\n",
            "Epoch 11 : Train loss 16.991807729005814, validation loss 16.340137481689453\n",
            "Complete prediction MSE : 0.002608723849054949\n",
            "Saving model\n",
            "Epoch 12 : Train loss 15.41930241137743, validation loss 17.00811195373535\n",
            "Complete prediction MSE : 0.0028985353393701048\n",
            "Epoch 13 : Train loss 14.347637321799994, validation loss 15.078861236572266\n",
            "Complete prediction MSE : 0.0026394832269665503\n",
            "Epoch 14 : Train loss 13.18987413868308, validation loss 14.690766334533691\n",
            "Complete prediction MSE : 0.0028489042827654\n",
            "Epoch 15 : Train loss 12.20431138202548, validation loss 12.658578872680664\n",
            "Complete prediction MSE : 0.0029062083819153253\n",
            "Epoch 16 : Train loss 11.329089898616076, validation loss 11.186539649963379\n",
            "Complete prediction MSE : 0.0024639742278631206\n",
            "Saving model\n",
            "Epoch 17 : Train loss 10.475839929655194, validation loss 10.125591278076172\n",
            "Complete prediction MSE : 0.0022869844783099742\n",
            "Saving model\n",
            "Epoch 18 : Train loss 9.751893989741802, validation loss 10.235803604125977\n",
            "Complete prediction MSE : 0.0024694057920646027\n",
            "Epoch 19 : Train loss 9.103499416261911, validation loss 9.796195030212402\n",
            "Complete prediction MSE : 0.002414043159527745\n",
            "Epoch 20 : Train loss 8.644707090221345, validation loss 9.273698806762695\n",
            "Complete prediction MSE : 0.0021339690552942604\n",
            "Saving model\n",
            "Epoch 21 : Train loss 8.339224700815976, validation loss 8.529744148254395\n",
            "Complete prediction MSE : 0.0022553193522638596\n",
            "Epoch 22 : Train loss 8.070792001672089, validation loss 8.610142707824707\n",
            "Complete prediction MSE : 0.0022014593924305757\n",
            "Epoch 23 : Train loss 7.8571926560252905, validation loss 8.535557746887207\n",
            "Complete prediction MSE : 0.0021118866924847053\n",
            "Saving model\n",
            "Epoch 24 : Train loss 7.662747437134385, validation loss 8.114917755126953\n",
            "Complete prediction MSE : 0.002249862751422845\n",
            "Epoch 25 : Train loss 7.4880761513486505, validation loss 8.280810356140137\n",
            "Complete prediction MSE : 0.002238054300619586\n",
            "Epoch 26 : Train loss 7.355276160873473, validation loss 8.790987968444824\n",
            "Complete prediction MSE : 0.0021133965631819148\n",
            "Epoch 27 : Train loss 7.218825156800449, validation loss 8.539419174194336\n",
            "Complete prediction MSE : 0.0022898275173365177\n",
            "Epoch 28 : Train loss 7.1843012953177094, validation loss 8.523310661315918\n",
            "Complete prediction MSE : 0.001979880694114398\n",
            "Saving model\n",
            "Epoch 29 : Train loss 6.995536275207996, validation loss 8.24804973602295\n",
            "Complete prediction MSE : 0.002108731174634497\n",
            "Epoch 30 : Train loss 6.875239931978285, validation loss 8.529606819152832\n",
            "Complete prediction MSE : 0.0020568675231201813\n",
            "Epoch 31 : Train loss 6.767575932666659, validation loss 8.301854133605957\n",
            "Complete prediction MSE : 0.002155674679161299\n",
            "Epoch 32 : Train loss 6.650440386496484, validation loss 8.27013874053955\n",
            "Complete prediction MSE : 0.002013777329386143\n",
            "Epoch 33 : Train loss 6.567908177152276, validation loss 8.404698371887207\n",
            "Complete prediction MSE : 0.0019523001491218218\n",
            "Saving model\n",
            "Epoch 34 : Train loss 6.457149342633784, validation loss 8.52088451385498\n",
            "Complete prediction MSE : 0.002083136300521438\n",
            "Epoch 35 : Train loss 6.371998061425984, validation loss 8.895160675048828\n",
            "Complete prediction MSE : 0.0019558898264679294\n",
            "Epoch 36 : Train loss 6.273259539157152, validation loss 7.867870330810547\n",
            "Complete prediction MSE : 0.001738999176882889\n",
            "Saving model\n",
            "Epoch 37 : Train loss 6.175125725567341, validation loss 8.827299118041992\n",
            "Complete prediction MSE : 0.0018391866088292572\n",
            "Epoch 38 : Train loss 6.13363890349865, validation loss 8.137276649475098\n",
            "Complete prediction MSE : 0.0019406039788467564\n",
            "Epoch 39 : Train loss 6.017693859525025, validation loss 8.742484092712402\n",
            "Complete prediction MSE : 0.0018416781318490246\n",
            "Epoch 40 : Train loss 5.972019696608186, validation loss 8.399846076965332\n",
            "Complete prediction MSE : 0.0018930036083604415\n",
            "Epoch 41 : Train loss 5.87060805875808, validation loss 8.03831958770752\n",
            "Complete prediction MSE : 0.0018452204445803754\n",
            "Epoch 42 : Train loss 5.8545201271772385, validation loss 9.005803108215332\n",
            "Complete prediction MSE : 0.001736917056954871\n",
            "Saving model\n",
            "Epoch 43 : Train loss 5.759774891659617, validation loss 8.823044776916504\n",
            "Complete prediction MSE : 0.00175407906895774\n",
            "Epoch 44 : Train loss 5.709287263453007, validation loss 8.506834030151367\n",
            "Complete prediction MSE : 0.0016713847218454022\n",
            "Saving model\n",
            "Epoch 45 : Train loss 5.622729568742216, validation loss 8.420013427734375\n",
            "Complete prediction MSE : 0.0016529066087447968\n",
            "Saving model\n",
            "Epoch 46 : Train loss 5.606612142175436, validation loss 8.03668212890625\n",
            "Complete prediction MSE : 0.0015945221111826138\n",
            "Saving model\n",
            "Epoch 47 : Train loss 5.5554936761036515, validation loss 8.721305847167969\n",
            "Complete prediction MSE : 0.0015464453405853516\n",
            "Saving model\n",
            "Epoch 48 : Train loss 5.474758900702, validation loss 8.573282241821289\n",
            "Complete prediction MSE : 0.0015315804703558767\n",
            "Saving model\n",
            "Epoch 49 : Train loss 5.425982390530407, validation loss 8.352810859680176\n",
            "Complete prediction MSE : 0.0015575286878841174\n",
            "Epoch 50 : Train loss 5.421190204098821, validation loss 8.636484146118164\n",
            "Complete prediction MSE : 0.0014532205212592823\n",
            "Saving model\n",
            "Epoch 51 : Train loss 5.358739675022662, validation loss 8.685430526733398\n",
            "Complete prediction MSE : 0.0015889908679537182\n",
            "Epoch 52 : Train loss 5.309945245273411, validation loss 9.318037033081055\n",
            "Complete prediction MSE : 0.001372782635918992\n",
            "Saving model\n",
            "Epoch 53 : Train loss 5.303871872834861, validation loss 9.125872611999512\n",
            "Complete prediction MSE : 0.0013666722782343902\n",
            "Saving model\n",
            "Epoch 54 : Train loss 5.249037718400359, validation loss 8.886628150939941\n",
            "Complete prediction MSE : 0.0014996377222846278\n",
            "Epoch 55 : Train loss 5.217075681313872, validation loss 8.136256217956543\n",
            "Complete prediction MSE : 0.0014407945240260559\n",
            "Epoch 56 : Train loss 5.169094203040004, validation loss 7.877872943878174\n",
            "Complete prediction MSE : 0.0014838373386293078\n",
            "Epoch 57 : Train loss 5.137618033215404, validation loss 9.083259582519531\n",
            "Complete prediction MSE : 0.0012876380914594167\n",
            "Saving model\n",
            "Epoch 58 : Train loss 5.088199972175062, validation loss 8.635917663574219\n",
            "Complete prediction MSE : 0.0014137368949142673\n",
            "Epoch 59 : Train loss 5.086133407428861, validation loss 8.079158782958984\n",
            "Complete prediction MSE : 0.0014181798260311724\n",
            "Epoch 60 : Train loss 5.016313430853188, validation loss 8.410751342773438\n",
            "Complete prediction MSE : 0.0014167222726103731\n",
            "Epoch 61 : Train loss 4.9903405318036675, validation loss 8.107837677001953\n",
            "Complete prediction MSE : 0.0013976006765165697\n",
            "Epoch 62 : Train loss 4.96256869379431, validation loss 7.847682476043701\n",
            "Complete prediction MSE : 0.0012395957298529756\n",
            "Saving model\n",
            "Epoch 63 : Train loss 4.97104415949434, validation loss 8.121216773986816\n",
            "Complete prediction MSE : 0.0012226194892281602\n",
            "Saving model\n",
            "Epoch 64 : Train loss 4.883888406679034, validation loss 8.436144828796387\n",
            "Complete prediction MSE : 0.0011610526904697461\n",
            "Saving model\n",
            "Epoch 65 : Train loss 4.924357675015926, validation loss 8.401151657104492\n",
            "Complete prediction MSE : 0.0012339093663947694\n",
            "Epoch 66 : Train loss 4.881740085780621, validation loss 7.854715824127197\n",
            "Complete prediction MSE : 0.0012298361047752122\n",
            "Epoch 67 : Train loss 4.849564862437546, validation loss 8.36306095123291\n",
            "Complete prediction MSE : 0.0012890265469786286\n",
            "Epoch 68 : Train loss 4.83207144588232, validation loss 9.254927635192871\n",
            "Complete prediction MSE : 0.0012368594956061036\n",
            "Epoch 69 : Train loss 4.829838369041681, validation loss 9.026861190795898\n",
            "Complete prediction MSE : 0.0013764795198270053\n",
            "Epoch 70 : Train loss 4.839383497368544, validation loss 8.346866607666016\n",
            "Complete prediction MSE : 0.0012552174352864678\n",
            "Epoch 71 : Train loss 4.776470307260752, validation loss 9.455399513244629\n",
            "Complete prediction MSE : 0.001202001015964195\n",
            "Epoch 72 : Train loss 4.760809521190822, validation loss 8.509746551513672\n",
            "Complete prediction MSE : 0.0015676510595361846\n",
            "Epoch 73 : Train loss 4.710044201463461, validation loss 8.363554954528809\n",
            "Complete prediction MSE : 0.0011102492699388714\n",
            "Saving model\n",
            "Epoch 74 : Train loss 4.715207600034773, validation loss 8.637755393981934\n",
            "Complete prediction MSE : 0.0011240368686663798\n",
            "Epoch 75 : Train loss 4.691054238472134, validation loss 8.0611572265625\n",
            "Complete prediction MSE : 0.0011998799232238494\n",
            "Epoch 76 : Train loss 4.67741105472669, validation loss 8.731843948364258\n",
            "Complete prediction MSE : 0.0010499028420770714\n",
            "Saving model\n",
            "Epoch 77 : Train loss 4.658937579020858, validation loss 9.151453971862793\n",
            "Complete prediction MSE : 0.0011359093860620016\n",
            "Epoch 78 : Train loss 4.6430682353675365, validation loss 9.206986427307129\n",
            "Complete prediction MSE : 0.0010767547405051703\n",
            "Epoch 79 : Train loss 4.6281941113993526, validation loss 8.9507417678833\n",
            "Complete prediction MSE : 0.001172911457856367\n",
            "Epoch 80 : Train loss 4.613498521503061, validation loss 9.52587604522705\n",
            "Complete prediction MSE : 0.0011762664563807481\n",
            "Epoch 81 : Train loss 4.586538834962994, validation loss 8.548118591308594\n",
            "Complete prediction MSE : 0.0014471302713873328\n",
            "Epoch 82 : Train loss 4.569217082113028, validation loss 9.532818794250488\n",
            "Complete prediction MSE : 0.0012307814734523778\n",
            "Epoch 83 : Train loss 4.593796486034989, validation loss 9.293282508850098\n",
            "Complete prediction MSE : 0.0013432553973179954\n",
            "Epoch 84 : Train loss 4.537854641210288, validation loss 9.2529296875\n",
            "Complete prediction MSE : 0.0011574403596401564\n",
            "Epoch 85 : Train loss 4.538387814536691, validation loss 8.757238388061523\n",
            "Complete prediction MSE : 0.00114248486374976\n",
            "Epoch 86 : Train loss 4.494586164597422, validation loss 8.985549926757812\n",
            "Complete prediction MSE : 0.001060506711257609\n",
            "Epoch 87 : Train loss 4.53817703248933, validation loss 9.413070678710938\n",
            "Complete prediction MSE : 0.0011560003105217879\n",
            "Epoch 88 : Train loss 4.460728181991726, validation loss 9.759910583496094\n",
            "Complete prediction MSE : 0.001122955960523225\n",
            "Epoch 89 : Train loss 4.456910551059991, validation loss 9.35848331451416\n",
            "Complete prediction MSE : 0.0011932422459544317\n",
            "Epoch 90 : Train loss 4.46800570236519, validation loss 10.077142715454102\n",
            "Complete prediction MSE : 0.0010433045744324416\n",
            "Saving model\n",
            "Epoch 91 : Train loss 4.462787287775427, validation loss 8.830754280090332\n",
            "Complete prediction MSE : 0.0011544262053818594\n",
            "Epoch 92 : Train loss 4.45892271772027, validation loss 9.227325439453125\n",
            "Complete prediction MSE : 0.001119184775683327\n",
            "Epoch 93 : Train loss 4.421781377866864, validation loss 8.740316390991211\n",
            "Complete prediction MSE : 0.001064971753337247\n",
            "Epoch 94 : Train loss 4.376253711991012, validation loss 8.562397956848145\n",
            "Complete prediction MSE : 0.0011004241586986209\n",
            "Epoch 95 : Train loss 4.383582629263401, validation loss 8.555407524108887\n",
            "Complete prediction MSE : 0.0011474094352147083\n",
            "Epoch 96 : Train loss 4.438824061769992, validation loss 9.057785987854004\n",
            "Complete prediction MSE : 0.0013045942923042284\n",
            "Epoch 97 : Train loss 4.3747948869131505, validation loss 8.480425834655762\n",
            "Complete prediction MSE : 0.001191868210088705\n",
            "Epoch 98 : Train loss 4.371520581655204, validation loss 9.538322448730469\n",
            "Complete prediction MSE : 0.0012777336527096499\n",
            "Epoch 99 : Train loss 4.3172165607102215, validation loss 9.03049373626709\n",
            "Complete prediction MSE : 0.0010106945388286264\n",
            "Saving model\n",
            "Epoch 100 : Train loss 4.346305730752647, validation loss 8.594632148742676\n",
            "Complete prediction MSE : 0.0011386391076433574\n",
            "Epoch 101 : Train loss 4.362557553686202, validation loss 8.83716869354248\n",
            "Complete prediction MSE : 0.0011542851712581194\n",
            "Epoch 102 : Train loss 4.304516030009836, validation loss 8.27313232421875\n",
            "Complete prediction MSE : 0.0010075442003143914\n",
            "Saving model\n",
            "Epoch 103 : Train loss 4.290207501035184, validation loss 8.100775718688965\n",
            "Complete prediction MSE : 0.0011734739371348233\n",
            "Epoch 104 : Train loss 4.264647397678345, validation loss 7.885115623474121\n",
            "Complete prediction MSE : 0.0011513494498904227\n",
            "Epoch 105 : Train loss 4.28937888937071, validation loss 7.970343589782715\n",
            "Complete prediction MSE : 0.001138216774692356\n",
            "Epoch 106 : Train loss 4.272671207319945, validation loss 8.02029037475586\n",
            "Complete prediction MSE : 0.001091060274153838\n",
            "Epoch 107 : Train loss 4.259107171092182, validation loss 8.71812915802002\n",
            "Complete prediction MSE : 0.0012663672652678147\n",
            "Epoch 108 : Train loss 4.267886138521135, validation loss 7.606073379516602\n",
            "Complete prediction MSE : 0.001242785506010232\n",
            "Epoch 109 : Train loss 4.263768057804555, validation loss 8.042257308959961\n",
            "Complete prediction MSE : 0.001343324749444024\n",
            "Epoch 110 : Train loss 4.242101928219199, validation loss 8.117114067077637\n",
            "Complete prediction MSE : 0.001258653796613824\n",
            "Epoch 111 : Train loss 4.241405460052192, validation loss 8.195521354675293\n",
            "Complete prediction MSE : 0.0011674612064024683\n",
            "Epoch 112 : Train loss 4.2123865145258605, validation loss 8.14893627166748\n",
            "Complete prediction MSE : 0.0011680852634743746\n",
            "Epoch 113 : Train loss 4.224082233384252, validation loss 7.708474636077881\n",
            "Complete prediction MSE : 0.0010549807555166422\n",
            "Epoch 114 : Train loss 4.210398608352989, validation loss 7.722980499267578\n",
            "Complete prediction MSE : 0.0010442206983635285\n",
            "Epoch 115 : Train loss 4.179697268642485, validation loss 8.679883003234863\n",
            "Complete prediction MSE : 0.0010444628676850904\n",
            "Epoch 116 : Train loss 4.238979745190591, validation loss 8.148585319519043\n",
            "Complete prediction MSE : 0.0016615834204910477\n",
            "Epoch 117 : Train loss 4.255714436993003, validation loss 8.099688529968262\n",
            "Complete prediction MSE : 0.0011740045357688212\n",
            "Epoch 118 : Train loss 4.178513332270086, validation loss 8.29887866973877\n",
            "Complete prediction MSE : 0.00129054665967352\n",
            "Epoch 119 : Train loss 4.179021312855184, validation loss 8.458409309387207\n",
            "Complete prediction MSE : 0.0012441974595981762\n",
            "Epoch 120 : Train loss 4.182628067210317, validation loss 8.294411659240723\n",
            "Complete prediction MSE : 0.0015731872163710693\n",
            "Epoch 121 : Train loss 4.208139444235712, validation loss 8.376157760620117\n",
            "Complete prediction MSE : 0.0014630560001838505\n",
            "Epoch 122 : Train loss 4.179418140556663, validation loss 7.868370056152344\n",
            "Complete prediction MSE : 0.001178958309146471\n",
            "Epoch 123 : Train loss 4.129410220310092, validation loss 8.341946601867676\n",
            "Complete prediction MSE : 0.0016004179195070155\n",
            "Epoch 124 : Train loss 4.1545998477377, validation loss 7.951897621154785\n",
            "Complete prediction MSE : 0.001248359143537184\n",
            "Epoch 125 : Train loss 4.121841228567064, validation loss 8.109643936157227\n",
            "Complete prediction MSE : 0.0012633708989404039\n",
            "Epoch 126 : Train loss 4.144408167805523, validation loss 7.933996677398682\n",
            "Complete prediction MSE : 0.0012195989622262617\n",
            "Epoch 127 : Train loss 4.098325674887747, validation loss 7.417968273162842\n",
            "Complete prediction MSE : 0.0012556246682027294\n",
            "Epoch 128 : Train loss 4.126576323527843, validation loss 7.798381805419922\n",
            "Complete prediction MSE : 0.0015286723257033497\n",
            "Epoch 129 : Train loss 4.104172264691442, validation loss 7.689744472503662\n",
            "Complete prediction MSE : 0.0015711520228170494\n",
            "Epoch 130 : Train loss 4.090596551541239, validation loss 7.757594108581543\n",
            "Complete prediction MSE : 0.0015820058160974507\n",
            "Epoch 131 : Train loss 4.093049929942936, validation loss 7.954214572906494\n",
            "Complete prediction MSE : 0.0010667426518789563\n",
            "Epoch 132 : Train loss 4.107684583868831, validation loss 8.31664752960205\n",
            "Complete prediction MSE : 0.0013870813765935093\n",
            "Epoch 133 : Train loss 4.088753260206431, validation loss 8.085816383361816\n",
            "Complete prediction MSE : 0.001329442092487606\n",
            "Epoch 134 : Train loss 4.081196657847613, validation loss 8.194982528686523\n",
            "Complete prediction MSE : 0.0021281148216803374\n",
            "Epoch 135 : Train loss 4.048804409336299, validation loss 7.943185329437256\n",
            "Complete prediction MSE : 0.0016272118939413731\n",
            "Epoch 136 : Train loss 4.052518978249282, validation loss 8.419997215270996\n",
            "Complete prediction MSE : 0.0010304953796303965\n",
            "Epoch 137 : Train loss 3.9850174030289054, validation loss 8.026700973510742\n",
            "Complete prediction MSE : 0.0016214534263094616\n",
            "Epoch 138 : Train loss 4.107974545098841, validation loss 7.896738529205322\n",
            "Complete prediction MSE : 0.0014802040203830012\n",
            "Epoch 139 : Train loss 4.077099465299398, validation loss 7.770036697387695\n",
            "Complete prediction MSE : 0.001321754773890426\n",
            "Epoch 140 : Train loss 4.063557155430317, validation loss 7.7056145668029785\n",
            "Complete prediction MSE : 0.0012312977046864116\n",
            "Epoch 141 : Train loss 4.005448263138533, validation loss 7.443765163421631\n",
            "Complete prediction MSE : 0.0015333813526675114\n",
            "Epoch 142 : Train loss 4.059214132837951, validation loss 7.95743989944458\n",
            "Complete prediction MSE : 0.0013988872322744043\n",
            "Epoch 143 : Train loss 3.9974242504686117, validation loss 7.821949005126953\n",
            "Complete prediction MSE : 0.0018956245183214832\n",
            "Epoch 144 : Train loss 4.040879719890654, validation loss 7.77517032623291\n",
            "Complete prediction MSE : 0.0011382708882434057\n",
            "Epoch 145 : Train loss 4.033685832750052, validation loss 7.5316481590271\n",
            "Complete prediction MSE : 0.001200515681985364\n",
            "Epoch 146 : Train loss 3.987710479646921, validation loss 8.465739250183105\n",
            "Complete prediction MSE : 0.0012704233868531159\n",
            "Epoch 147 : Train loss 3.993173980154097, validation loss 7.793405055999756\n",
            "Complete prediction MSE : 0.001212555692086179\n",
            "Epoch 148 : Train loss 3.967984462622553, validation loss 8.3049955368042\n",
            "Complete prediction MSE : 0.001224170092187699\n",
            "Epoch 149 : Train loss 3.969273682218045, validation loss 8.013113975524902\n",
            "Complete prediction MSE : 0.001177098540754242\n",
            "Epoch 150 : Train loss 3.9708171361126006, validation loss 8.091364860534668\n",
            "Complete prediction MSE : 0.001248661621426217\n",
            "Epoch 151 : Train loss 3.948701470158994, validation loss 7.610177993774414\n",
            "Complete prediction MSE : 0.0010784735883839457\n",
            "Epoch 152 : Train loss 3.9735402781516314, validation loss 7.663756370544434\n",
            "Complete prediction MSE : 0.0013903352106023681\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 2\n",
            "Epoch 1 : Train loss 36.66150875762105, validation loss 14.760783195495605\n",
            "Complete prediction MSE : 0.0031738002776090595\n",
            "Saving model\n",
            "Epoch 2 : Train loss 14.648440880700946, validation loss 11.981252670288086\n",
            "Complete prediction MSE : 0.0030036521194913447\n",
            "Saving model\n",
            "Epoch 3 : Train loss 12.84726132079959, validation loss 10.981886863708496\n",
            "Complete prediction MSE : 0.002796092229081076\n",
            "Saving model\n",
            "Epoch 4 : Train loss 41.5488105583936, validation loss 16.40948486328125\n",
            "Complete prediction MSE : 0.0027024288885975733\n",
            "Saving model\n",
            "Epoch 5 : Train loss 15.716707710176706, validation loss 12.634773254394531\n",
            "Complete prediction MSE : 0.002578231729296079\n",
            "Saving model\n",
            "Epoch 6 : Train loss 14.428441870957613, validation loss 13.43908405303955\n",
            "Complete prediction MSE : 0.0028050302448784236\n",
            "Epoch 7 : Train loss 13.56569298543036, validation loss 12.45024299621582\n",
            "Complete prediction MSE : 0.0023574087146494577\n",
            "Saving model\n",
            "Epoch 8 : Train loss 12.683947948738933, validation loss 11.836128234863281\n",
            "Complete prediction MSE : 0.0025766991766713165\n",
            "Epoch 9 : Train loss 11.973799591884017, validation loss 13.201203346252441\n",
            "Complete prediction MSE : 0.002774303131521954\n",
            "Epoch 10 : Train loss 11.221443628892303, validation loss 12.495559692382812\n",
            "Complete prediction MSE : 0.002659681638553251\n",
            "Epoch 11 : Train loss 10.551673732697964, validation loss 10.764538764953613\n",
            "Complete prediction MSE : 0.002835856083167892\n",
            "Epoch 12 : Train loss 10.090901829302311, validation loss 12.396456718444824\n",
            "Complete prediction MSE : 0.0025642710294333025\n",
            "Epoch 13 : Train loss 9.678001644089818, validation loss 11.723016738891602\n",
            "Complete prediction MSE : 0.002286252050270474\n",
            "Saving model\n",
            "Epoch 14 : Train loss 9.337666470557451, validation loss 10.984663009643555\n",
            "Complete prediction MSE : 0.0024618566119926164\n",
            "Epoch 15 : Train loss 9.800516919232905, validation loss 9.265040397644043\n",
            "Complete prediction MSE : 0.0023927749791007526\n",
            "Epoch 16 : Train loss 8.970710955560207, validation loss 9.77476978302002\n",
            "Complete prediction MSE : 0.002374703012956779\n",
            "Epoch 17 : Train loss 8.584791373461485, validation loss 9.802995681762695\n",
            "Complete prediction MSE : 0.00278698571270858\n",
            "Epoch 18 : Train loss 8.357463356107473, validation loss 9.259195327758789\n",
            "Complete prediction MSE : 0.0029184499094712228\n",
            "Epoch 19 : Train loss 8.231482548639178, validation loss 9.342185020446777\n",
            "Complete prediction MSE : 0.0027574153047793064\n",
            "Epoch 20 : Train loss 7.986599274910986, validation loss 9.226984024047852\n",
            "Complete prediction MSE : 0.0025964997899786176\n",
            "Epoch 21 : Train loss 7.907655232585967, validation loss 9.229717254638672\n",
            "Complete prediction MSE : 0.0026753331983636313\n",
            "Epoch 22 : Train loss 7.62239321321249, validation loss 8.974164009094238\n",
            "Complete prediction MSE : 0.002492719926534588\n",
            "Epoch 23 : Train loss 7.579913716763258, validation loss 10.030628204345703\n",
            "Complete prediction MSE : 0.0023263796503048013\n",
            "Epoch 24 : Train loss 7.333356718532741, validation loss 9.57524585723877\n",
            "Complete prediction MSE : 0.002443439651367644\n",
            "Epoch 25 : Train loss 7.166350670158863, validation loss 8.73730182647705\n",
            "Complete prediction MSE : 0.003071917447159585\n",
            "Epoch 26 : Train loss 7.023657192476094, validation loss 9.53557014465332\n",
            "Complete prediction MSE : 0.0028806547366933047\n",
            "Epoch 27 : Train loss 6.910474197939038, validation loss 9.778851509094238\n",
            "Complete prediction MSE : 0.002395325833533866\n",
            "Epoch 28 : Train loss 6.99830692447722, validation loss 8.6323881149292\n",
            "Complete prediction MSE : 0.0020233812498670544\n",
            "Saving model\n",
            "Epoch 29 : Train loss 6.6394091648980975, validation loss 9.922660827636719\n",
            "Complete prediction MSE : 0.002128916995624112\n",
            "Epoch 30 : Train loss 6.595984812825918, validation loss 8.151094436645508\n",
            "Complete prediction MSE : 0.0020915236039163875\n",
            "Epoch 31 : Train loss 6.49580692127347, validation loss 9.36833667755127\n",
            "Complete prediction MSE : 0.0019971782488034835\n",
            "Saving model\n",
            "Epoch 32 : Train loss 6.406434169970453, validation loss 8.593010902404785\n",
            "Complete prediction MSE : 0.0019062023685711487\n",
            "Saving model\n",
            "Epoch 33 : Train loss 6.296315271407366, validation loss 9.635059356689453\n",
            "Complete prediction MSE : 0.0019225761420225316\n",
            "Epoch 34 : Train loss 6.254557932727039, validation loss 8.993952751159668\n",
            "Complete prediction MSE : 0.0018400071413136735\n",
            "Saving model\n",
            "Epoch 35 : Train loss 6.170887932181358, validation loss 8.926393508911133\n",
            "Complete prediction MSE : 0.0018329940978616941\n",
            "Saving model\n",
            "Epoch 36 : Train loss 6.088166361674666, validation loss 8.99160385131836\n",
            "Complete prediction MSE : 0.00171811641615151\n",
            "Saving model\n",
            "Epoch 37 : Train loss 6.004142868332565, validation loss 9.046788215637207\n",
            "Complete prediction MSE : 0.0016742447994263024\n",
            "Saving model\n",
            "Epoch 38 : Train loss 5.939654200337827, validation loss 8.953329086303711\n",
            "Complete prediction MSE : 0.0017602276192357862\n",
            "Epoch 39 : Train loss 5.909885477274656, validation loss 9.328863143920898\n",
            "Complete prediction MSE : 0.0018103878072050221\n",
            "Epoch 40 : Train loss 5.807722772471607, validation loss 9.344959259033203\n",
            "Complete prediction MSE : 0.0017205200258641183\n",
            "Epoch 41 : Train loss 5.755101460963488, validation loss 8.415567398071289\n",
            "Complete prediction MSE : 0.0019141686925518851\n",
            "Epoch 42 : Train loss 5.697870244272053, validation loss 9.50120735168457\n",
            "Complete prediction MSE : 0.001950901710071056\n",
            "Epoch 43 : Train loss 5.644640219397843, validation loss 10.71338939666748\n",
            "Complete prediction MSE : 0.0018703919553303325\n",
            "Epoch 44 : Train loss 5.602077620103955, validation loss 7.949211597442627\n",
            "Complete prediction MSE : 0.001839191741495875\n",
            "Epoch 45 : Train loss 5.507496258243918, validation loss 8.304000854492188\n",
            "Complete prediction MSE : 0.001887713793087099\n",
            "Epoch 46 : Train loss 5.527707188390195, validation loss 8.363513946533203\n",
            "Complete prediction MSE : 0.001924897035175043\n",
            "Epoch 47 : Train loss 5.414127268828452, validation loss 8.60532283782959\n",
            "Complete prediction MSE : 0.0015783227903600468\n",
            "Saving model\n",
            "Epoch 48 : Train loss 5.3679508324712515, validation loss 8.312119483947754\n",
            "Complete prediction MSE : 0.0017566471838684813\n",
            "Epoch 49 : Train loss 5.345236551016569, validation loss 8.374287605285645\n",
            "Complete prediction MSE : 0.0018032025712769006\n",
            "Epoch 50 : Train loss 5.285989673808217, validation loss 8.591521263122559\n",
            "Complete prediction MSE : 0.0015665534061337948\n",
            "Saving model\n",
            "Epoch 51 : Train loss 5.260329653508961, validation loss 7.286928176879883\n",
            "Complete prediction MSE : 0.0019056090208074143\n",
            "Epoch 52 : Train loss 5.196604267694056, validation loss 7.955671787261963\n",
            "Complete prediction MSE : 0.0017001200470940889\n",
            "Epoch 53 : Train loss 5.19713719189167, validation loss 7.973939895629883\n",
            "Complete prediction MSE : 0.001771726388895057\n",
            "Epoch 54 : Train loss 5.162531872279942, validation loss 7.647312164306641\n",
            "Complete prediction MSE : 0.001689416334240115\n",
            "Epoch 55 : Train loss 5.114183268509805, validation loss 7.789761543273926\n",
            "Complete prediction MSE : 0.0015926901659418639\n",
            "Epoch 56 : Train loss 5.063335109502077, validation loss 8.182794570922852\n",
            "Complete prediction MSE : 0.0015845635613984457\n",
            "Epoch 57 : Train loss 5.021873786114156, validation loss 8.13773250579834\n",
            "Complete prediction MSE : 0.0015903037868087\n",
            "Epoch 58 : Train loss 5.049146964214742, validation loss 8.361934661865234\n",
            "Complete prediction MSE : 0.0016764757073696116\n",
            "Epoch 59 : Train loss 4.997115960344672, validation loss 9.029504776000977\n",
            "Complete prediction MSE : 0.001506398883168811\n",
            "Saving model\n",
            "Epoch 60 : Train loss 4.9506186209619045, validation loss 8.688666343688965\n",
            "Complete prediction MSE : 0.0015811523834487035\n",
            "Epoch 61 : Train loss 4.9435906847938895, validation loss 8.082820892333984\n",
            "Complete prediction MSE : 0.0015797265098649006\n",
            "Epoch 62 : Train loss 4.870467427186668, validation loss 8.64149284362793\n",
            "Complete prediction MSE : 0.0014830424186570222\n",
            "Saving model\n",
            "Epoch 63 : Train loss 4.879637921229005, validation loss 9.058015823364258\n",
            "Complete prediction MSE : 0.0015275316112632197\n",
            "Epoch 64 : Train loss 4.859811702743173, validation loss 9.352212905883789\n",
            "Complete prediction MSE : 0.001470452350700014\n",
            "Saving model\n",
            "Epoch 65 : Train loss 4.853431734256446, validation loss 9.495809555053711\n",
            "Complete prediction MSE : 0.0014482287532375366\n",
            "Saving model\n",
            "Epoch 66 : Train loss 4.832080843858421, validation loss 8.646158218383789\n",
            "Complete prediction MSE : 0.0015597876689549563\n",
            "Epoch 67 : Train loss 4.776807273738086, validation loss 9.153265953063965\n",
            "Complete prediction MSE : 0.0014856445150602435\n",
            "Epoch 68 : Train loss 4.780691779684275, validation loss 9.109601974487305\n",
            "Complete prediction MSE : 0.0013592411377768528\n",
            "Saving model\n",
            "Epoch 69 : Train loss 4.774353156797588, validation loss 8.750240325927734\n",
            "Complete prediction MSE : 0.0014094641079889015\n",
            "Epoch 70 : Train loss 4.770094451494515, validation loss 9.973204612731934\n",
            "Complete prediction MSE : 0.0014958690840226336\n",
            "Epoch 71 : Train loss 4.74354675039649, validation loss 8.777774810791016\n",
            "Complete prediction MSE : 0.0014361422937659513\n",
            "Epoch 72 : Train loss 4.685192720964551, validation loss 8.73718547821045\n",
            "Complete prediction MSE : 0.001293359568548828\n",
            "Saving model\n",
            "Epoch 73 : Train loss 4.673753397073597, validation loss 9.372733116149902\n",
            "Complete prediction MSE : 0.0014785001292801211\n",
            "Epoch 74 : Train loss 4.638316436205059, validation loss 9.24438190460205\n",
            "Complete prediction MSE : 0.001379334365777738\n",
            "Epoch 75 : Train loss 4.628285171929747, validation loss 8.923774719238281\n",
            "Complete prediction MSE : 0.0013498134684249259\n",
            "Epoch 76 : Train loss 4.625785217620432, validation loss 9.026273727416992\n",
            "Complete prediction MSE : 0.001308591776808861\n",
            "Epoch 77 : Train loss 4.575728885829449, validation loss 8.901811599731445\n",
            "Complete prediction MSE : 0.001378338590431055\n",
            "Epoch 78 : Train loss 4.626165235880762, validation loss 8.721148490905762\n",
            "Complete prediction MSE : 0.0013453604865846206\n",
            "Epoch 79 : Train loss 4.57152027124539, validation loss 8.983681678771973\n",
            "Complete prediction MSE : 0.0013197483132670472\n",
            "Epoch 80 : Train loss 4.553152779117227, validation loss 8.959710121154785\n",
            "Complete prediction MSE : 0.0013458616743678\n",
            "Epoch 81 : Train loss 4.507974974811077, validation loss 9.075514793395996\n",
            "Complete prediction MSE : 0.0013263206455802186\n",
            "Epoch 82 : Train loss 4.5291881719604135, validation loss 9.07609748840332\n",
            "Complete prediction MSE : 0.0012557530867318295\n",
            "Saving model\n",
            "Epoch 83 : Train loss 4.5035400642082095, validation loss 8.526877403259277\n",
            "Complete prediction MSE : 0.0011779136967304982\n",
            "Saving model\n",
            "Epoch 84 : Train loss 4.489415791351348, validation loss 9.518661499023438\n",
            "Complete prediction MSE : 0.001260111479303612\n",
            "Epoch 85 : Train loss 4.499974580015987, validation loss 8.817079544067383\n",
            "Complete prediction MSE : 0.001332921509051946\n",
            "Epoch 86 : Train loss 4.458954205736518, validation loss 8.542961120605469\n",
            "Complete prediction MSE : 0.0014875056980760439\n",
            "Epoch 87 : Train loss 4.477271860465407, validation loss 9.5733060836792\n",
            "Complete prediction MSE : 0.0012608913187300565\n",
            "Epoch 88 : Train loss 4.400595187675208, validation loss 9.305051803588867\n",
            "Complete prediction MSE : 0.0012422668860432079\n",
            "Epoch 89 : Train loss 4.387262040749192, validation loss 8.937209129333496\n",
            "Complete prediction MSE : 0.0012899558139662247\n",
            "Epoch 90 : Train loss 4.389458188787103, validation loss 9.517078399658203\n",
            "Complete prediction MSE : 0.001318734971782162\n",
            "Epoch 91 : Train loss 4.394001742824912, validation loss 8.68707275390625\n",
            "Complete prediction MSE : 0.0012769108423110868\n",
            "Epoch 92 : Train loss 4.362528328318149, validation loss 8.58405590057373\n",
            "Complete prediction MSE : 0.0012443889726423815\n",
            "Epoch 93 : Train loss 4.349724290892482, validation loss 8.164823532104492\n",
            "Complete prediction MSE : 0.0013700737702163517\n",
            "Epoch 94 : Train loss 4.345351689029485, validation loss 8.964947700500488\n",
            "Complete prediction MSE : 0.001290339540516993\n",
            "Epoch 95 : Train loss 4.328896991442889, validation loss 9.331343650817871\n",
            "Complete prediction MSE : 0.0012307319684972727\n",
            "Epoch 96 : Train loss 4.324948387686163, validation loss 8.449533462524414\n",
            "Complete prediction MSE : 0.001397091779522721\n",
            "Epoch 97 : Train loss 4.288228415418416, validation loss 8.489392280578613\n",
            "Complete prediction MSE : 0.001394214241469343\n",
            "Epoch 98 : Train loss 4.31765324389562, validation loss 9.010321617126465\n",
            "Complete prediction MSE : 0.0014201838966336597\n",
            "Epoch 99 : Train loss 4.270713042002171, validation loss 8.769747734069824\n",
            "Complete prediction MSE : 0.0013468673823189216\n",
            "Epoch 100 : Train loss 4.296285465825349, validation loss 8.57656478881836\n",
            "Complete prediction MSE : 0.001398656988319299\n",
            "Epoch 101 : Train loss 4.294480636250228, validation loss 9.05069351196289\n",
            "Complete prediction MSE : 0.0013377095277889398\n",
            "Epoch 102 : Train loss 4.2671790542081, validation loss 9.263396263122559\n",
            "Complete prediction MSE : 0.0012315077571830055\n",
            "Epoch 103 : Train loss 4.238861362915486, validation loss 8.209774017333984\n",
            "Complete prediction MSE : 0.001227451496661139\n",
            "Epoch 104 : Train loss 4.261666549835354, validation loss 8.67194652557373\n",
            "Complete prediction MSE : 0.0012899357870595424\n",
            "Epoch 105 : Train loss 4.214709721039981, validation loss 8.723250389099121\n",
            "Complete prediction MSE : 0.0013237282768071364\n",
            "Epoch 106 : Train loss 4.193312318064272, validation loss 8.443572998046875\n",
            "Complete prediction MSE : 0.0014375885713941283\n",
            "Epoch 107 : Train loss 4.221999407745898, validation loss 8.457144737243652\n",
            "Complete prediction MSE : 0.0013464144774582869\n",
            "Epoch 108 : Train loss 4.171063646208495, validation loss 8.51404857635498\n",
            "Complete prediction MSE : 0.0013696639539868651\n",
            "Epoch 109 : Train loss 4.200436075683683, validation loss 8.88661003112793\n",
            "Complete prediction MSE : 0.0015014375182312203\n",
            "Epoch 110 : Train loss 4.1721961996518075, validation loss 8.766419410705566\n",
            "Complete prediction MSE : 0.001426411575276268\n",
            "Epoch 111 : Train loss 4.189736664760858, validation loss 7.90933895111084\n",
            "Complete prediction MSE : 0.0014971302988024508\n",
            "Epoch 112 : Train loss 4.187850898131728, validation loss 8.190020561218262\n",
            "Complete prediction MSE : 0.0011874889077061357\n",
            "Epoch 113 : Train loss 4.155313525348902, validation loss 8.65523910522461\n",
            "Complete prediction MSE : 0.0012663732063474913\n",
            "Epoch 114 : Train loss 4.155526788439602, validation loss 8.527830123901367\n",
            "Complete prediction MSE : 0.0011838883677264972\n",
            "Epoch 115 : Train loss 4.1349111795425415, validation loss 8.854757308959961\n",
            "Complete prediction MSE : 0.0012256659628071174\n",
            "Epoch 116 : Train loss 4.083037451375276, validation loss 8.302932739257812\n",
            "Complete prediction MSE : 0.0012727042471779833\n",
            "Epoch 117 : Train loss 4.134089893195778, validation loss 9.102261543273926\n",
            "Complete prediction MSE : 0.001623715803234253\n",
            "Epoch 118 : Train loss 4.071953339967877, validation loss 8.515710830688477\n",
            "Complete prediction MSE : 0.0013116077128665095\n",
            "Epoch 119 : Train loss 4.156730677932501, validation loss 8.088172912597656\n",
            "Complete prediction MSE : 0.0010894774497648549\n",
            "Saving model\n",
            "Epoch 120 : Train loss 4.1435880665667355, validation loss 8.44241714477539\n",
            "Complete prediction MSE : 0.0013538946557839176\n",
            "Epoch 121 : Train loss 4.0916785364970565, validation loss 7.990422248840332\n",
            "Complete prediction MSE : 0.001311248267289453\n",
            "Epoch 122 : Train loss 4.067854166496545, validation loss 8.678154945373535\n",
            "Complete prediction MSE : 0.0013409461144748447\n",
            "Epoch 123 : Train loss 4.075954074040055, validation loss 8.453394889831543\n",
            "Complete prediction MSE : 0.001113023508077852\n",
            "Epoch 124 : Train loss 4.031406605616212, validation loss 8.374065399169922\n",
            "Complete prediction MSE : 0.0012056262943048682\n",
            "Epoch 125 : Train loss 4.061133053619415, validation loss 8.966463088989258\n",
            "Complete prediction MSE : 0.0012598812579626775\n",
            "Epoch 126 : Train loss 4.071252693422139, validation loss 9.145325660705566\n",
            "Complete prediction MSE : 0.001315381161042724\n",
            "Epoch 127 : Train loss 4.087460570037365, validation loss 8.300697326660156\n",
            "Complete prediction MSE : 0.0013695578258973097\n",
            "Epoch 128 : Train loss 4.071725273504853, validation loss 8.20508861541748\n",
            "Complete prediction MSE : 0.001381918948566738\n",
            "Epoch 129 : Train loss 4.0284510920755565, validation loss 8.387804985046387\n",
            "Complete prediction MSE : 0.0011091478955099004\n",
            "Epoch 130 : Train loss 4.024286663625389, validation loss 9.015434265136719\n",
            "Complete prediction MSE : 0.0011660497658223113\n",
            "Epoch 131 : Train loss 4.0112827005796134, validation loss 8.207658767700195\n",
            "Complete prediction MSE : 0.0012684603635276077\n",
            "Epoch 132 : Train loss 4.03392747649923, validation loss 8.290847778320312\n",
            "Complete prediction MSE : 0.0013712711037428325\n",
            "Epoch 133 : Train loss 4.047750761732459, validation loss 8.311306953430176\n",
            "Complete prediction MSE : 0.001322063000389403\n",
            "Epoch 134 : Train loss 3.9939327822066844, validation loss 7.93898344039917\n",
            "Complete prediction MSE : 0.0013569527393846247\n",
            "Epoch 135 : Train loss 3.9572496339678764, validation loss 8.611732482910156\n",
            "Complete prediction MSE : 0.0012199363225131956\n",
            "Epoch 136 : Train loss 3.9997619218192995, validation loss 8.270076751708984\n",
            "Complete prediction MSE : 0.0012469318385016329\n",
            "Epoch 137 : Train loss 4.006447894033045, validation loss 8.384020805358887\n",
            "Complete prediction MSE : 0.0011486237715710944\n",
            "Epoch 138 : Train loss 4.026994748041034, validation loss 8.471616744995117\n",
            "Complete prediction MSE : 0.0012145084209512545\n",
            "Epoch 139 : Train loss 3.9589157523587346, validation loss 9.133028984069824\n",
            "Complete prediction MSE : 0.0012065289742411896\n",
            "Epoch 140 : Train loss 4.0057138949632645, validation loss 8.402752876281738\n",
            "Complete prediction MSE : 0.0014599118638499926\n",
            "Epoch 141 : Train loss 3.9698336753062904, validation loss 8.929546356201172\n",
            "Complete prediction MSE : 0.0011101546909262168\n",
            "Epoch 142 : Train loss 3.9322360293008387, validation loss 8.529762268066406\n",
            "Complete prediction MSE : 0.0013337873189128617\n",
            "Epoch 143 : Train loss 4.012115349527448, validation loss 8.352315902709961\n",
            "Complete prediction MSE : 0.0012726779586488676\n",
            "Epoch 144 : Train loss 3.9552812790498137, validation loss 8.039034843444824\n",
            "Complete prediction MSE : 0.001425859397155348\n",
            "Epoch 145 : Train loss 3.955638153012842, validation loss 8.743699073791504\n",
            "Complete prediction MSE : 0.001384082976413165\n",
            "Epoch 146 : Train loss 3.9756871261633933, validation loss 8.759032249450684\n",
            "Complete prediction MSE : 0.001360337277808487\n",
            "Epoch 147 : Train loss 3.9315051338635385, validation loss 8.559998512268066\n",
            "Complete prediction MSE : 0.0011179643332122082\n",
            "Epoch 148 : Train loss 3.9308585883118212, validation loss 8.03002643585205\n",
            "Complete prediction MSE : 0.0011049287919930892\n",
            "Epoch 149 : Train loss 3.9409175785258412, validation loss 7.98750638961792\n",
            "Complete prediction MSE : 0.001208098118451185\n",
            "Epoch 150 : Train loss 3.9658817779272795, validation loss 8.682699203491211\n",
            "Complete prediction MSE : 0.0014757251222230266\n",
            "Epoch 151 : Train loss 3.894325259141624, validation loss 8.664604187011719\n",
            "Complete prediction MSE : 0.001260471382402691\n",
            "Epoch 152 : Train loss 3.8714401689358056, validation loss 8.260037422180176\n",
            "Complete prediction MSE : 0.0011987902687673549\n",
            "Epoch 153 : Train loss 3.912498223595321, validation loss 8.32761001586914\n",
            "Complete prediction MSE : 0.001042928578284268\n",
            "Saving model\n",
            "Epoch 154 : Train loss 3.8771790601313114, validation loss 8.272344589233398\n",
            "Complete prediction MSE : 0.0014040912906797853\n",
            "Epoch 155 : Train loss 3.8951181429438293, validation loss 8.480225563049316\n",
            "Complete prediction MSE : 0.0011480290127182074\n",
            "Epoch 156 : Train loss 3.9375292458571494, validation loss 7.894736289978027\n",
            "Complete prediction MSE : 0.0012824754267851566\n",
            "Epoch 157 : Train loss 3.925007790327072, validation loss 7.570009231567383\n",
            "Complete prediction MSE : 0.0012936064125250578\n",
            "Epoch 158 : Train loss 3.9326998167671263, validation loss 9.061079025268555\n",
            "Complete prediction MSE : 0.001157420290953974\n",
            "Epoch 159 : Train loss 3.8708459599874914, validation loss 8.940559387207031\n",
            "Complete prediction MSE : 0.0014289051696500076\n",
            "Epoch 160 : Train loss 3.8563424390740693, validation loss 7.788805961608887\n",
            "Complete prediction MSE : 0.0010870681999085824\n",
            "Epoch 161 : Train loss 3.889855009969324, validation loss 9.202341079711914\n",
            "Complete prediction MSE : 0.0010459759782592416\n",
            "Epoch 162 : Train loss 3.8983430727384984, validation loss 8.754447937011719\n",
            "Complete prediction MSE : 0.0010811817396747148\n",
            "Epoch 163 : Train loss 3.9238296165131032, validation loss 8.50766372680664\n",
            "Complete prediction MSE : 0.001191544173335693\n",
            "Epoch 164 : Train loss 3.863944375421852, validation loss 8.940362930297852\n",
            "Complete prediction MSE : 0.0012885746571374471\n",
            "Epoch 165 : Train loss 3.898265558294952, validation loss 8.58581829071045\n",
            "Complete prediction MSE : 0.0012558168309111729\n",
            "Epoch 166 : Train loss 3.836454900447279, validation loss 8.52694034576416\n",
            "Complete prediction MSE : 0.0010845854158486562\n",
            "Epoch 167 : Train loss 3.8309503900818527, validation loss 8.479522705078125\n",
            "Complete prediction MSE : 0.0010375151900710244\n",
            "Saving model\n",
            "Epoch 168 : Train loss 3.849167230539024, validation loss 8.08966064453125\n",
            "Complete prediction MSE : 0.0011869182784092268\n",
            "Epoch 169 : Train loss 3.859366834629327, validation loss 8.886200904846191\n",
            "Complete prediction MSE : 0.0011855313536692238\n",
            "Epoch 170 : Train loss 3.852667927276343, validation loss 9.24647331237793\n",
            "Complete prediction MSE : 0.0010666210535008928\n",
            "Epoch 171 : Train loss 3.820054307579994, validation loss 8.30147647857666\n",
            "Complete prediction MSE : 0.0017720439725890903\n",
            "Epoch 172 : Train loss 3.825506203342229, validation loss 8.335991859436035\n",
            "Complete prediction MSE : 0.0011478804643085668\n",
            "Epoch 173 : Train loss 3.829565288964659, validation loss 9.214314460754395\n",
            "Complete prediction MSE : 0.0010243870229040255\n",
            "Saving model\n",
            "Epoch 174 : Train loss 3.843510970007628, validation loss 8.485042572021484\n",
            "Complete prediction MSE : 0.0014232753484673113\n",
            "Epoch 175 : Train loss 3.864762796089053, validation loss 8.584818840026855\n",
            "Complete prediction MSE : 0.0011302147800512636\n",
            "Epoch 176 : Train loss 3.829716909211129, validation loss 8.074670791625977\n",
            "Complete prediction MSE : 0.00132013760715769\n",
            "Epoch 177 : Train loss 3.831028735730797, validation loss 8.752379417419434\n",
            "Complete prediction MSE : 0.001100275103332331\n",
            "Epoch 178 : Train loss 3.813840090762824, validation loss 9.020888328552246\n",
            "Complete prediction MSE : 0.001233351770678165\n",
            "Epoch 179 : Train loss 3.7966939355246723, validation loss 8.701608657836914\n",
            "Complete prediction MSE : 0.0011728165026854526\n",
            "Epoch 180 : Train loss 3.8722175853326917, validation loss 9.251755714416504\n",
            "Complete prediction MSE : 0.0010431067255091534\n",
            "Epoch 181 : Train loss 3.8192893331870437, validation loss 8.5940523147583\n",
            "Complete prediction MSE : 0.0011340450129144757\n",
            "Epoch 182 : Train loss 3.7866195384413004, validation loss 8.850125312805176\n",
            "Complete prediction MSE : 0.001098221342478238\n",
            "Epoch 183 : Train loss 3.815132069401443, validation loss 9.199874877929688\n",
            "Complete prediction MSE : 0.0011760497392187242\n",
            "Epoch 184 : Train loss 3.788714906666428, validation loss 8.334303855895996\n",
            "Complete prediction MSE : 0.001120524212125792\n",
            "Epoch 185 : Train loss 3.8001695377752185, validation loss 8.673758506774902\n",
            "Complete prediction MSE : 0.0013064099522531424\n",
            "Epoch 186 : Train loss 3.808404134120792, validation loss 9.37066650390625\n",
            "Complete prediction MSE : 0.0011779981472851368\n",
            "Epoch 187 : Train loss 3.8084560590796173, validation loss 8.512307167053223\n",
            "Complete prediction MSE : 0.0010410094939545555\n",
            "Epoch 188 : Train loss 3.761851687915623, validation loss 8.996800422668457\n",
            "Complete prediction MSE : 0.0009703086208365551\n",
            "Saving model\n",
            "Epoch 189 : Train loss 3.807814880274236, validation loss 8.871402740478516\n",
            "Complete prediction MSE : 0.0011722638811043373\n",
            "Epoch 190 : Train loss 3.7511665374040604, validation loss 8.01899242401123\n",
            "Complete prediction MSE : 0.0010892047966956594\n",
            "Epoch 191 : Train loss 3.834421049337834, validation loss 8.505146026611328\n",
            "Complete prediction MSE : 0.0010628652043856099\n",
            "Epoch 192 : Train loss 3.7739063599146903, validation loss 7.912380695343018\n",
            "Complete prediction MSE : 0.0011093477264007764\n",
            "Epoch 193 : Train loss 3.765090126078576, validation loss 9.028717041015625\n",
            "Complete prediction MSE : 0.0011035136700278043\n",
            "Epoch 194 : Train loss 3.795992624014616, validation loss 8.5858154296875\n",
            "Complete prediction MSE : 0.0011306387972205264\n",
            "Epoch 195 : Train loss 3.7490654387511313, validation loss 8.447098731994629\n",
            "Complete prediction MSE : 0.0012181050762498224\n",
            "Epoch 196 : Train loss 3.752719215117395, validation loss 9.144820213317871\n",
            "Complete prediction MSE : 0.0011064441173277114\n",
            "Epoch 197 : Train loss 3.750772968865931, validation loss 8.119778633117676\n",
            "Complete prediction MSE : 0.0014541072094600945\n",
            "Epoch 198 : Train loss 3.7826706059277058, validation loss 9.017251968383789\n",
            "Complete prediction MSE : 0.0010431759965247977\n",
            "Epoch 199 : Train loss 3.737888344563544, validation loss 8.111533164978027\n",
            "Complete prediction MSE : 0.0011559482933455089\n",
            "Epoch 200 : Train loss 3.752507511060685, validation loss 8.795801162719727\n",
            "Complete prediction MSE : 0.0010475527189747634\n",
            "Epoch 201 : Train loss 3.7919768574647605, validation loss 8.273493766784668\n",
            "Complete prediction MSE : 0.0012103603220450692\n",
            "Epoch 202 : Train loss 3.741456946823746, validation loss 7.851069450378418\n",
            "Complete prediction MSE : 0.0009647356073063821\n",
            "Saving model\n",
            "Epoch 203 : Train loss 3.7305555660277605, validation loss 8.025160789489746\n",
            "Complete prediction MSE : 0.0013056595259039192\n",
            "Epoch 204 : Train loss 3.742040609009564, validation loss 8.351150512695312\n",
            "Complete prediction MSE : 0.0010919472668960244\n",
            "Epoch 205 : Train loss 3.7475081654265523, validation loss 8.250530242919922\n",
            "Complete prediction MSE : 0.0010726996139713652\n",
            "Epoch 206 : Train loss 3.8185551813803613, validation loss 8.413525581359863\n",
            "Complete prediction MSE : 0.0012218903643723559\n",
            "Epoch 207 : Train loss 3.759971986990422, validation loss 8.689384460449219\n",
            "Complete prediction MSE : 0.0009214348460229261\n",
            "Saving model\n",
            "Epoch 208 : Train loss 3.6879257345572114, validation loss 9.030920028686523\n",
            "Complete prediction MSE : 0.0012051816840308463\n",
            "Epoch 209 : Train loss 3.749470562208444, validation loss 8.9837646484375\n",
            "Complete prediction MSE : 0.0011820405265512124\n",
            "Epoch 210 : Train loss 3.7197387400083244, validation loss 8.120251655578613\n",
            "Complete prediction MSE : 0.0012295845563169497\n",
            "Epoch 211 : Train loss 3.726930539123714, validation loss 8.797977447509766\n",
            "Complete prediction MSE : 0.0012393783633070717\n",
            "Epoch 212 : Train loss 3.7165270829573274, validation loss 8.325308799743652\n",
            "Complete prediction MSE : 0.0012139709680722688\n",
            "Epoch 213 : Train loss 3.7057045488618314, validation loss 8.208309173583984\n",
            "Complete prediction MSE : 0.0009873868917851779\n",
            "Epoch 214 : Train loss 3.731407289393246, validation loss 8.032867431640625\n",
            "Complete prediction MSE : 0.0010680678831070454\n",
            "Epoch 215 : Train loss 3.714234944432974, validation loss 8.910348892211914\n",
            "Complete prediction MSE : 0.0011151891312906205\n",
            "Epoch 216 : Train loss 3.7401503808796406, validation loss 7.965576171875\n",
            "Complete prediction MSE : 0.0010743212720414719\n",
            "Epoch 217 : Train loss 3.7221097266301513, validation loss 8.212111473083496\n",
            "Complete prediction MSE : 0.001130851732964137\n",
            "Epoch 218 : Train loss 3.6776472022756934, validation loss 7.989992618560791\n",
            "Complete prediction MSE : 0.0011971940535691551\n",
            "Epoch 219 : Train loss 3.701407164335251, validation loss 7.871681213378906\n",
            "Complete prediction MSE : 0.0011104069557591326\n",
            "Epoch 220 : Train loss 3.6853270139545202, validation loss 8.209173202514648\n",
            "Complete prediction MSE : 0.0010275815215914459\n",
            "Epoch 221 : Train loss 3.651796282734722, validation loss 8.810691833496094\n",
            "Complete prediction MSE : 0.0010276944227308837\n",
            "Epoch 222 : Train loss 3.7400155547074974, validation loss 8.184553146362305\n",
            "Complete prediction MSE : 0.001148168128992753\n",
            "Epoch 223 : Train loss 3.6986728510819376, validation loss 7.757440567016602\n",
            "Complete prediction MSE : 0.001311184348149233\n",
            "Epoch 224 : Train loss 3.723004927393049, validation loss 8.086214065551758\n",
            "Complete prediction MSE : 0.0010830454071384414\n",
            "Epoch 225 : Train loss 3.664319571107626, validation loss 8.50776481628418\n",
            "Complete prediction MSE : 0.0010520977268587137\n",
            "Epoch 226 : Train loss 3.6910507208667696, validation loss 8.12247085571289\n",
            "Complete prediction MSE : 0.0009919572037555822\n",
            "Epoch 227 : Train loss 3.6486923322081566, validation loss 7.926741600036621\n",
            "Complete prediction MSE : 0.0010715471553326078\n",
            "Epoch 228 : Train loss 3.693640553858131, validation loss 8.927526473999023\n",
            "Complete prediction MSE : 0.001065915133614262\n",
            "Epoch 229 : Train loss 3.680739798117429, validation loss 9.034350395202637\n",
            "Complete prediction MSE : 0.0009906876795307239\n",
            "Epoch 230 : Train loss 3.690461400896311, validation loss 8.516300201416016\n",
            "Complete prediction MSE : 0.0009935114782377037\n",
            "Epoch 231 : Train loss 3.660331917461008, validation loss 8.42696475982666\n",
            "Complete prediction MSE : 0.0011797485658833933\n",
            "Epoch 232 : Train loss 3.651253626216203, validation loss 8.040114402770996\n",
            "Complete prediction MSE : 0.0010846627738820504\n",
            "Epoch 233 : Train loss 3.6715820454992354, validation loss 8.0541353225708\n",
            "Complete prediction MSE : 0.001186265328522369\n",
            "Epoch 234 : Train loss 3.696059704758227, validation loss 8.321466445922852\n",
            "Complete prediction MSE : 0.0011101554310882927\n",
            "Epoch 235 : Train loss 3.667607153300196, validation loss 8.179421424865723\n",
            "Complete prediction MSE : 0.0011941100936302467\n",
            "Epoch 236 : Train loss 3.6540772980079055, validation loss 7.7002739906311035\n",
            "Complete prediction MSE : 0.001065675289758752\n",
            "Epoch 237 : Train loss 3.6447407719679177, validation loss 8.852189064025879\n",
            "Complete prediction MSE : 0.0011411547341526045\n",
            "Epoch 238 : Train loss 3.6939973635599017, validation loss 7.975559711456299\n",
            "Complete prediction MSE : 0.001055839496924478\n",
            "Epoch 239 : Train loss 3.640111355576664, validation loss 7.790196418762207\n",
            "Complete prediction MSE : 0.0009811914527655893\n",
            "Epoch 240 : Train loss 3.711352583952248, validation loss 8.495332717895508\n",
            "Complete prediction MSE : 0.0012102640197946997\n",
            "Epoch 241 : Train loss 3.6939254319295287, validation loss 7.637800216674805\n",
            "Complete prediction MSE : 0.0009954424093386244\n",
            "Epoch 242 : Train loss 3.691176968626678, validation loss 7.919220447540283\n",
            "Complete prediction MSE : 0.0011202831540855736\n",
            "Epoch 243 : Train loss 3.7063762648031116, validation loss 7.934847831726074\n",
            "Complete prediction MSE : 0.0009337811485172243\n",
            "Epoch 244 : Train loss 3.710737314540893, validation loss 8.312897682189941\n",
            "Complete prediction MSE : 0.0011599675313984927\n",
            "Epoch 245 : Train loss 3.6425249013118446, validation loss 8.386409759521484\n",
            "Complete prediction MSE : 0.001130950428598559\n",
            "Epoch 246 : Train loss 3.6662733061239123, validation loss 8.494635581970215\n",
            "Complete prediction MSE : 0.0010991919154772056\n",
            "Epoch 247 : Train loss 3.640764352399856, validation loss 8.075360298156738\n",
            "Complete prediction MSE : 0.0012887080477584762\n",
            "Epoch 248 : Train loss 3.6479539843276143, validation loss 8.224160194396973\n",
            "Complete prediction MSE : 0.0009691529895367231\n",
            "Epoch 249 : Train loss 3.652302043978125, validation loss 8.350090026855469\n",
            "Complete prediction MSE : 0.0010636558320420814\n",
            "Epoch 250 : Train loss 3.634893815033138, validation loss 8.423762321472168\n",
            "Complete prediction MSE : 0.0011539914851252824\n",
            "Epoch 251 : Train loss 3.6882714303210378, validation loss 8.181488990783691\n",
            "Complete prediction MSE : 0.001383931857203135\n",
            "Epoch 252 : Train loss 3.5948470612056553, validation loss 8.054119110107422\n",
            "Complete prediction MSE : 0.001160829794935751\n",
            "Epoch 253 : Train loss 3.676298729609698, validation loss 9.257628440856934\n",
            "Complete prediction MSE : 0.0010020389580046838\n",
            "Epoch 254 : Train loss 3.658814697060734, validation loss 8.688272476196289\n",
            "Complete prediction MSE : 0.0009594474594423547\n",
            "Epoch 255 : Train loss 3.7064479682594538, validation loss 8.118412017822266\n",
            "Complete prediction MSE : 0.0011346405408684717\n",
            "Epoch 256 : Train loss 3.626371496822685, validation loss 8.539528846740723\n",
            "Complete prediction MSE : 0.001081114880281351\n",
            "Epoch 257 : Train loss 3.659877866972238, validation loss 8.544726371765137\n",
            "Complete prediction MSE : 0.001161104883692486\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 3\n",
            "Epoch 1 : Train loss 36.8982021138072, validation loss 13.343579292297363\n",
            "Complete prediction MSE : 0.0029325077166853994\n",
            "Saving model\n",
            "Epoch 2 : Train loss 14.984140953049064, validation loss 11.310992240905762\n",
            "Complete prediction MSE : 0.0025783674939455397\n",
            "Saving model\n",
            "Epoch 3 : Train loss 13.08293279632926, validation loss 11.907293319702148\n",
            "Complete prediction MSE : 0.0031987472857195483\n",
            "Epoch 4 : Train loss 12.05321534536779, validation loss 11.907782554626465\n",
            "Complete prediction MSE : 0.002763117063531733\n",
            "Epoch 5 : Train loss 11.21426122263074, validation loss 10.207852363586426\n",
            "Complete prediction MSE : 0.003095459365719249\n",
            "Epoch 6 : Train loss 10.662487359717488, validation loss 11.158775329589844\n",
            "Complete prediction MSE : 0.0026437749983319447\n",
            "Epoch 7 : Train loss 168.26031757704914, validation loss 23.289714813232422\n",
            "Complete prediction MSE : 0.0033637851426342093\n",
            "Epoch 8 : Train loss 23.61843204125762, validation loss 19.759693145751953\n",
            "Complete prediction MSE : 0.00313658793948613\n",
            "Epoch 9 : Train loss 20.369267269968987, validation loss 19.640785217285156\n",
            "Complete prediction MSE : 0.003322472541381924\n",
            "Epoch 10 : Train loss 19.00198734551668, validation loss 18.568572998046875\n",
            "Complete prediction MSE : 0.00314096357509577\n",
            "Epoch 11 : Train loss 18.337343065068126, validation loss 15.317815780639648\n",
            "Complete prediction MSE : 0.002755733780068685\n",
            "Epoch 12 : Train loss 17.503847394138575, validation loss 14.506793975830078\n",
            "Complete prediction MSE : 0.0028318645280469767\n",
            "Epoch 13 : Train loss 16.958377229049802, validation loss 14.741941452026367\n",
            "Complete prediction MSE : 0.0028883774869769624\n",
            "Epoch 14 : Train loss 16.23633591271937, validation loss 16.457496643066406\n",
            "Complete prediction MSE : 0.003272540605604182\n",
            "Epoch 15 : Train loss 15.591906836256385, validation loss 15.138008117675781\n",
            "Complete prediction MSE : 0.0030546663493062464\n",
            "Epoch 16 : Train loss 15.069280099123716, validation loss 14.121971130371094\n",
            "Complete prediction MSE : 0.002925764640862437\n",
            "Epoch 17 : Train loss 14.255331730470061, validation loss 12.993839263916016\n",
            "Complete prediction MSE : 0.0031380307468896734\n",
            "Epoch 18 : Train loss 13.791715547442436, validation loss 13.701759338378906\n",
            "Complete prediction MSE : 0.0029434776431262765\n",
            "Epoch 19 : Train loss 13.153696686029434, validation loss 13.011571884155273\n",
            "Complete prediction MSE : 0.0027822087021922765\n",
            "Epoch 20 : Train loss 12.579568454995751, validation loss 13.117762565612793\n",
            "Complete prediction MSE : 0.0032113400649612625\n",
            "Epoch 21 : Train loss 11.950721168890595, validation loss 13.294456481933594\n",
            "Complete prediction MSE : 0.0026409737443731187\n",
            "Epoch 22 : Train loss 11.430826412513852, validation loss 10.938962936401367\n",
            "Complete prediction MSE : 0.002432272158469049\n",
            "Saving model\n",
            "Epoch 23 : Train loss 10.913395812734962, validation loss 10.281328201293945\n",
            "Complete prediction MSE : 0.0023246762197107374\n",
            "Saving model\n",
            "Epoch 24 : Train loss 10.341138018295169, validation loss 9.498347282409668\n",
            "Complete prediction MSE : 0.002301069378599696\n",
            "Saving model\n",
            "Epoch 25 : Train loss 9.82190383411944, validation loss 9.707124710083008\n",
            "Complete prediction MSE : 0.002371831058818182\n",
            "Epoch 26 : Train loss 9.33952032122761, validation loss 10.087700843811035\n",
            "Complete prediction MSE : 0.0023035564156115317\n",
            "Epoch 27 : Train loss 8.96296026930213, validation loss 8.938526153564453\n",
            "Complete prediction MSE : 0.00254495673653493\n",
            "Epoch 28 : Train loss 8.66340074595064, validation loss 9.33264446258545\n",
            "Complete prediction MSE : 0.002300520003193148\n",
            "Saving model\n",
            "Epoch 29 : Train loss 8.271454436704516, validation loss 10.040587425231934\n",
            "Complete prediction MSE : 0.002166838227247875\n",
            "Saving model\n",
            "Epoch 30 : Train loss 8.107211987487972, validation loss 10.552314758300781\n",
            "Complete prediction MSE : 0.002138502064038902\n",
            "Saving model\n",
            "Epoch 31 : Train loss 7.911772229708731, validation loss 9.409008026123047\n",
            "Complete prediction MSE : 0.0021930740713688047\n",
            "Epoch 32 : Train loss 7.726349911652505, validation loss 9.574037551879883\n",
            "Complete prediction MSE : 0.002065664702159317\n",
            "Saving model\n",
            "Epoch 33 : Train loss 7.550924754701555, validation loss 9.443693161010742\n",
            "Complete prediction MSE : 0.0022706172802795595\n",
            "Epoch 34 : Train loss 7.465068702585995, validation loss 7.917596817016602\n",
            "Complete prediction MSE : 0.0022732288185541346\n",
            "Epoch 35 : Train loss 7.3206702414900064, validation loss 8.579167366027832\n",
            "Complete prediction MSE : 0.0020914253078910343\n",
            "Epoch 36 : Train loss 7.153329575434327, validation loss 8.51136302947998\n",
            "Complete prediction MSE : 0.0020616112708638718\n",
            "Saving model\n",
            "Epoch 37 : Train loss 7.047758654691279, validation loss 9.04201602935791\n",
            "Complete prediction MSE : 0.0020204828901975768\n",
            "Saving model\n",
            "Epoch 38 : Train loss 6.933484332635999, validation loss 9.419389724731445\n",
            "Complete prediction MSE : 0.002082979906400243\n",
            "Epoch 39 : Train loss 6.781431019306183, validation loss 9.227840423583984\n",
            "Complete prediction MSE : 0.0017941597264211023\n",
            "Saving model\n",
            "Epoch 40 : Train loss 6.658517811447382, validation loss 9.115596771240234\n",
            "Complete prediction MSE : 0.0018515834268121526\n",
            "Epoch 41 : Train loss 6.593069341033697, validation loss 8.813718795776367\n",
            "Complete prediction MSE : 0.0017971971513405386\n",
            "Epoch 42 : Train loss 6.501112272962928, validation loss 9.073079109191895\n",
            "Complete prediction MSE : 0.0016843439042550435\n",
            "Saving model\n",
            "Epoch 43 : Train loss 6.436969263479114, validation loss 9.410882949829102\n",
            "Complete prediction MSE : 0.0018980772165307237\n",
            "Epoch 44 : Train loss 6.358247606083751, validation loss 8.573511123657227\n",
            "Complete prediction MSE : 0.001709767064648998\n",
            "Epoch 45 : Train loss 6.289521644823253, validation loss 8.160104751586914\n",
            "Complete prediction MSE : 0.0019440960636970708\n",
            "Epoch 46 : Train loss 6.174889384768903, validation loss 8.817315101623535\n",
            "Complete prediction MSE : 0.0018193970423103678\n",
            "Epoch 47 : Train loss 6.137307533994317, validation loss 9.233583450317383\n",
            "Complete prediction MSE : 0.002121976371190616\n",
            "Epoch 48 : Train loss 6.0581096122041345, validation loss 9.322571754455566\n",
            "Complete prediction MSE : 0.0019515017620329897\n",
            "Epoch 49 : Train loss 5.9783748257905245, validation loss 9.385236740112305\n",
            "Complete prediction MSE : 0.0017038807226391589\n",
            "Epoch 50 : Train loss 5.950761267915368, validation loss 9.17199993133545\n",
            "Complete prediction MSE : 0.0017834977761050177\n",
            "Epoch 51 : Train loss 5.908137531019747, validation loss 9.324068069458008\n",
            "Complete prediction MSE : 0.0015629180797473957\n",
            "Saving model\n",
            "Epoch 52 : Train loss 5.8420230355113745, validation loss 8.140113830566406\n",
            "Complete prediction MSE : 0.0014670967982515785\n",
            "Saving model\n",
            "Epoch 53 : Train loss 5.790438514202833, validation loss 8.312774658203125\n",
            "Complete prediction MSE : 0.0016664675517476352\n",
            "Epoch 54 : Train loss 5.728591561317444, validation loss 8.72725772857666\n",
            "Complete prediction MSE : 0.0016378699558948341\n",
            "Epoch 55 : Train loss 5.680298741906881, validation loss 8.765143394470215\n",
            "Complete prediction MSE : 0.0014750783942549114\n",
            "Epoch 56 : Train loss 5.657929818145931, validation loss 8.144430160522461\n",
            "Complete prediction MSE : 0.0015531609062908538\n",
            "Epoch 57 : Train loss 5.617018342018127, validation loss 8.1941499710083\n",
            "Complete prediction MSE : 0.0018274275301001254\n",
            "Epoch 58 : Train loss 5.554894307628274, validation loss 7.647823810577393\n",
            "Complete prediction MSE : 0.001587212890190126\n",
            "Epoch 59 : Train loss 5.494063628837466, validation loss 8.65972900390625\n",
            "Complete prediction MSE : 0.0021042244302587913\n",
            "Epoch 60 : Train loss 5.443018552847207, validation loss 8.636709213256836\n",
            "Complete prediction MSE : 0.0018716715134769711\n",
            "Epoch 61 : Train loss 5.417649446055293, validation loss 8.896178245544434\n",
            "Complete prediction MSE : 0.0024817725207969096\n",
            "Epoch 62 : Train loss 5.367112879641354, validation loss 8.604474067687988\n",
            "Complete prediction MSE : 0.001993190298444068\n",
            "Epoch 63 : Train loss 5.315157729201019, validation loss 7.9558868408203125\n",
            "Complete prediction MSE : 0.001645142394358203\n",
            "Epoch 64 : Train loss 5.3013824839144945, validation loss 8.805696487426758\n",
            "Complete prediction MSE : 0.0017922503402070223\n",
            "Epoch 65 : Train loss 5.235771542415023, validation loss 7.552158355712891\n",
            "Complete prediction MSE : 0.0017468334094331707\n",
            "Epoch 66 : Train loss 5.251643500290811, validation loss 7.424960613250732\n",
            "Complete prediction MSE : 0.0017247840971740078\n",
            "Epoch 67 : Train loss 5.181202640756965, validation loss 8.504216194152832\n",
            "Complete prediction MSE : 0.0017343525222772778\n",
            "Epoch 68 : Train loss 5.166407071053982, validation loss 7.619690418243408\n",
            "Complete prediction MSE : 0.0017080735005197242\n",
            "Epoch 69 : Train loss 5.136503072455525, validation loss 8.608448028564453\n",
            "Complete prediction MSE : 0.0021095284150707185\n",
            "Epoch 70 : Train loss 5.114168562926352, validation loss 7.233549118041992\n",
            "Complete prediction MSE : 0.0016436629366708359\n",
            "Epoch 71 : Train loss 5.053945656865835, validation loss 7.943296432495117\n",
            "Complete prediction MSE : 0.0015487223713565176\n",
            "Epoch 72 : Train loss 5.041143094189465, validation loss 7.368618965148926\n",
            "Complete prediction MSE : 0.0015332138611282016\n",
            "Epoch 73 : Train loss 5.034494776278734, validation loss 7.616325855255127\n",
            "Complete prediction MSE : 0.0014490086588141693\n",
            "Saving model\n",
            "Epoch 74 : Train loss 4.980339726433158, validation loss 7.728931427001953\n",
            "Complete prediction MSE : 0.0017653183552871097\n",
            "Epoch 75 : Train loss 4.939682886004448, validation loss 7.853717803955078\n",
            "Complete prediction MSE : 0.0014517665993143889\n",
            "Epoch 76 : Train loss 4.938745422288775, validation loss 7.742887020111084\n",
            "Complete prediction MSE : 0.0013663389639441167\n",
            "Saving model\n",
            "Epoch 77 : Train loss 4.942619684152305, validation loss 7.559221267700195\n",
            "Complete prediction MSE : 0.0014572234485447934\n",
            "Epoch 78 : Train loss 4.879057350568473, validation loss 7.104711532592773\n",
            "Complete prediction MSE : 0.0013866615222863335\n",
            "Epoch 79 : Train loss 4.868706029839814, validation loss 7.832970142364502\n",
            "Complete prediction MSE : 0.0014846880980684354\n",
            "Epoch 80 : Train loss 4.852329509332776, validation loss 7.971456527709961\n",
            "Complete prediction MSE : 0.001342364113100906\n",
            "Saving model\n",
            "Epoch 81 : Train loss 4.821153758093715, validation loss 8.006732940673828\n",
            "Complete prediction MSE : 0.0013880741342656247\n",
            "Epoch 82 : Train loss 4.793831653892994, validation loss 7.901096343994141\n",
            "Complete prediction MSE : 0.001530147476816365\n",
            "Epoch 83 : Train loss 4.799226642586291, validation loss 8.152228355407715\n",
            "Complete prediction MSE : 0.0013396105377891602\n",
            "Saving model\n",
            "Epoch 84 : Train loss 4.752928178757429, validation loss 7.561309814453125\n",
            "Complete prediction MSE : 0.0013051394679440703\n",
            "Saving model\n",
            "Epoch 85 : Train loss 4.736421393230557, validation loss 8.060494422912598\n",
            "Complete prediction MSE : 0.0012951198660284473\n",
            "Saving model\n",
            "Epoch 86 : Train loss 4.720281582325697, validation loss 7.887993335723877\n",
            "Complete prediction MSE : 0.0011684266848980746\n",
            "Saving model\n",
            "Epoch 87 : Train loss 4.7148459469899535, validation loss 7.890411376953125\n",
            "Complete prediction MSE : 0.0011922372399542974\n",
            "Epoch 88 : Train loss 4.700237368233502, validation loss 7.465731620788574\n",
            "Complete prediction MSE : 0.0013010419820136713\n",
            "Epoch 89 : Train loss 4.641946414485574, validation loss 7.89575719833374\n",
            "Complete prediction MSE : 0.0013722902960078105\n",
            "Epoch 90 : Train loss 4.672947263345122, validation loss 7.911892890930176\n",
            "Complete prediction MSE : 0.0012647133617131093\n",
            "Epoch 91 : Train loss 4.626111211720854, validation loss 8.672590255737305\n",
            "Complete prediction MSE : 0.0013458493457809324\n",
            "Epoch 92 : Train loss 4.609131360426545, validation loss 8.219512939453125\n",
            "Complete prediction MSE : 0.0012740610497354627\n",
            "Epoch 93 : Train loss 4.600931776687503, validation loss 7.754772186279297\n",
            "Complete prediction MSE : 0.0012719883902945033\n",
            "Epoch 94 : Train loss 4.599924664013088, validation loss 7.813159465789795\n",
            "Complete prediction MSE : 0.0012962042829308895\n",
            "Epoch 95 : Train loss 4.587516344152391, validation loss 7.741605281829834\n",
            "Complete prediction MSE : 0.0013547074667813839\n",
            "Epoch 96 : Train loss 4.564680367242545, validation loss 7.901494979858398\n",
            "Complete prediction MSE : 0.0014264659394730647\n",
            "Epoch 97 : Train loss 4.580747578758746, validation loss 7.458913803100586\n",
            "Complete prediction MSE : 0.00129518045129734\n",
            "Epoch 98 : Train loss 4.51923838397488, validation loss 8.08566951751709\n",
            "Complete prediction MSE : 0.0011978857224301059\n",
            "Epoch 99 : Train loss 4.5371829671785235, validation loss 7.900332450866699\n",
            "Complete prediction MSE : 0.0012714467133329984\n",
            "Epoch 100 : Train loss 4.532353792339563, validation loss 7.941763877868652\n",
            "Complete prediction MSE : 0.0012218084718484035\n",
            "Epoch 101 : Train loss 4.546314776409417, validation loss 7.547124862670898\n",
            "Complete prediction MSE : 0.001330577881607073\n",
            "Epoch 102 : Train loss 4.4556837640702724, validation loss 7.564210414886475\n",
            "Complete prediction MSE : 0.001358050018298778\n",
            "Epoch 103 : Train loss 4.50791872292757, validation loss 8.471720695495605\n",
            "Complete prediction MSE : 0.0012323413826326407\n",
            "Epoch 104 : Train loss 4.464769579935819, validation loss 7.520171165466309\n",
            "Complete prediction MSE : 0.0014223121508824602\n",
            "Epoch 105 : Train loss 4.477882018778473, validation loss 8.335135459899902\n",
            "Complete prediction MSE : 0.0012491270664842478\n",
            "Epoch 106 : Train loss 4.450656692497432, validation loss 7.931302070617676\n",
            "Complete prediction MSE : 0.0011869531463977185\n",
            "Epoch 107 : Train loss 4.4087656061165035, validation loss 7.678661823272705\n",
            "Complete prediction MSE : 0.0011988115300491735\n",
            "Epoch 108 : Train loss 4.442442068364471, validation loss 7.712917327880859\n",
            "Complete prediction MSE : 0.0011310312261083825\n",
            "Saving model\n",
            "Epoch 109 : Train loss 4.401890866924077, validation loss 7.534026622772217\n",
            "Complete prediction MSE : 0.001038085139312168\n",
            "Saving model\n",
            "Epoch 110 : Train loss 4.378687889315188, validation loss 7.540946006774902\n",
            "Complete prediction MSE : 0.0011094008362743984\n",
            "Epoch 111 : Train loss 4.390139102004468, validation loss 8.030346870422363\n",
            "Complete prediction MSE : 0.0012026262010973007\n",
            "Epoch 112 : Train loss 4.382901754695922, validation loss 8.07651138305664\n",
            "Complete prediction MSE : 0.0011775513800664796\n",
            "Epoch 113 : Train loss 4.36428657034412, validation loss 7.670004844665527\n",
            "Complete prediction MSE : 0.001366382616391452\n",
            "Epoch 114 : Train loss 4.326213104650378, validation loss 7.621664524078369\n",
            "Complete prediction MSE : 0.0011113383972671032\n",
            "Epoch 115 : Train loss 4.340084463357925, validation loss 7.7076334953308105\n",
            "Complete prediction MSE : 0.0011998248952487208\n",
            "Epoch 116 : Train loss 4.315271470230073, validation loss 7.266903877258301\n",
            "Complete prediction MSE : 0.0012889376362879845\n",
            "Epoch 117 : Train loss 4.315165818203241, validation loss 8.00409984588623\n",
            "Complete prediction MSE : 0.0012316399356143103\n",
            "Epoch 118 : Train loss 4.35578337777406, validation loss 7.7558393478393555\n",
            "Complete prediction MSE : 0.00147285301420665\n",
            "Epoch 119 : Train loss 4.331159865483642, validation loss 7.455027103424072\n",
            "Complete prediction MSE : 0.0012895872051916074\n",
            "Epoch 120 : Train loss 4.275510026142001, validation loss 8.068399429321289\n",
            "Complete prediction MSE : 0.0011911490258336803\n",
            "Epoch 121 : Train loss 4.301250101067126, validation loss 7.92226505279541\n",
            "Complete prediction MSE : 0.0011519234365224566\n",
            "Epoch 122 : Train loss 4.25328285805881, validation loss 7.368904113769531\n",
            "Complete prediction MSE : 0.001281825123971716\n",
            "Epoch 123 : Train loss 4.271950694732368, validation loss 7.37434196472168\n",
            "Complete prediction MSE : 0.001148698759347968\n",
            "Epoch 124 : Train loss 4.274222900625318, validation loss 8.168153762817383\n",
            "Complete prediction MSE : 0.0011163456899390659\n",
            "Epoch 125 : Train loss 4.223561943974346, validation loss 8.0330810546875\n",
            "Complete prediction MSE : 0.0010356445068499698\n",
            "Saving model\n",
            "Epoch 126 : Train loss 4.23544636182487, validation loss 7.661696434020996\n",
            "Complete prediction MSE : 0.0010285660378389632\n",
            "Saving model\n",
            "Epoch 127 : Train loss 4.237529107835144, validation loss 7.462573051452637\n",
            "Complete prediction MSE : 0.001132504132139921\n",
            "Epoch 128 : Train loss 4.2654310264624655, validation loss 7.588213920593262\n",
            "Complete prediction MSE : 0.0010142986850726764\n",
            "Saving model\n",
            "Epoch 129 : Train loss 4.227647823281586, validation loss 7.7697906494140625\n",
            "Complete prediction MSE : 0.0010718430641486214\n",
            "Epoch 130 : Train loss 4.219552656169981, validation loss 7.782290458679199\n",
            "Complete prediction MSE : 0.0011432653127728873\n",
            "Epoch 131 : Train loss 4.197519740555435, validation loss 7.203193664550781\n",
            "Complete prediction MSE : 0.0011655562508404288\n",
            "Epoch 132 : Train loss 4.187004534993321, validation loss 7.383424758911133\n",
            "Complete prediction MSE : 0.001106990511427275\n",
            "Epoch 133 : Train loss 4.191708583384752, validation loss 7.299785137176514\n",
            "Complete prediction MSE : 0.001124448576402503\n",
            "Epoch 134 : Train loss 4.172737903892994, validation loss 7.51065731048584\n",
            "Complete prediction MSE : 0.001052320769232247\n",
            "Epoch 135 : Train loss 4.214405187871307, validation loss 7.352471828460693\n",
            "Complete prediction MSE : 0.0010242649772249201\n",
            "Epoch 136 : Train loss 4.1809675437398255, validation loss 7.958697319030762\n",
            "Complete prediction MSE : 0.001074638805013597\n",
            "Epoch 137 : Train loss 4.113280479796231, validation loss 7.252669334411621\n",
            "Complete prediction MSE : 0.0011484391806335006\n",
            "Epoch 138 : Train loss 4.134515950921923, validation loss 7.87476110458374\n",
            "Complete prediction MSE : 0.001159371995335077\n",
            "Epoch 139 : Train loss 4.163287878967822, validation loss 7.231684684753418\n",
            "Complete prediction MSE : 0.0010997531784002913\n",
            "Epoch 140 : Train loss 4.138587836641818, validation loss 7.2898173332214355\n",
            "Complete prediction MSE : 0.00119613405956543\n",
            "Epoch 141 : Train loss 4.135593946557492, validation loss 8.000965118408203\n",
            "Complete prediction MSE : 0.0013731977824239887\n",
            "Epoch 142 : Train loss 4.124428350478411, validation loss 8.423199653625488\n",
            "Complete prediction MSE : 0.00102945025791203\n",
            "Epoch 143 : Train loss 4.11802081624046, validation loss 7.823338508605957\n",
            "Complete prediction MSE : 0.001121856868562088\n",
            "Epoch 144 : Train loss 4.1393500519916415, validation loss 7.961212158203125\n",
            "Complete prediction MSE : 0.001043473672334639\n",
            "Epoch 145 : Train loss 4.120301867835224, validation loss 8.386069297790527\n",
            "Complete prediction MSE : 0.0011819701407251523\n",
            "Epoch 146 : Train loss 4.106736470479518, validation loss 7.901477813720703\n",
            "Complete prediction MSE : 0.0010925973682994466\n",
            "Epoch 147 : Train loss 4.086460538208485, validation loss 7.633792877197266\n",
            "Complete prediction MSE : 0.0010561125337938673\n",
            "Epoch 148 : Train loss 4.0941165327094495, validation loss 8.691679954528809\n",
            "Complete prediction MSE : 0.001177169777690149\n",
            "Epoch 149 : Train loss 4.070780191104859, validation loss 8.385287284851074\n",
            "Complete prediction MSE : 0.0010662522948734412\n",
            "Epoch 150 : Train loss 4.070826863404363, validation loss 7.972165584564209\n",
            "Complete prediction MSE : 0.0012295958204632603\n",
            "Epoch 151 : Train loss 4.104197365697473, validation loss 8.00644302368164\n",
            "Complete prediction MSE : 0.001094682972997359\n",
            "Epoch 152 : Train loss 4.109406948555261, validation loss 8.776322364807129\n",
            "Complete prediction MSE : 0.0012776688277535107\n",
            "Epoch 153 : Train loss 4.09218717738986, validation loss 8.28194808959961\n",
            "Complete prediction MSE : 0.0010329125639916153\n",
            "Epoch 154 : Train loss 4.015979908872396, validation loss 7.932324409484863\n",
            "Complete prediction MSE : 0.0010265678742137094\n",
            "Epoch 155 : Train loss 4.103580029215664, validation loss 8.344057083129883\n",
            "Complete prediction MSE : 0.0011702338894963302\n",
            "Epoch 156 : Train loss 4.0325731337070465, validation loss 8.99532699584961\n",
            "Complete prediction MSE : 0.001168049286195042\n",
            "Epoch 157 : Train loss 4.072221321053803, validation loss 8.624994277954102\n",
            "Complete prediction MSE : 0.0013189627117019427\n",
            "Epoch 158 : Train loss 4.054339028894901, validation loss 8.757055282592773\n",
            "Complete prediction MSE : 0.0011551576247120787\n",
            "Epoch 159 : Train loss 4.002891319338232, validation loss 8.419333457946777\n",
            "Complete prediction MSE : 0.0012199228430749694\n",
            "Epoch 160 : Train loss 4.003087916877121, validation loss 8.455860137939453\n",
            "Complete prediction MSE : 0.0010707038826807738\n",
            "Epoch 161 : Train loss 4.026989696547389, validation loss 8.293681144714355\n",
            "Complete prediction MSE : 0.0011417008579887539\n",
            "Epoch 162 : Train loss 4.012339898850769, validation loss 8.253565788269043\n",
            "Complete prediction MSE : 0.0010754847839356664\n",
            "Epoch 163 : Train loss 3.988068140577525, validation loss 8.469578742980957\n",
            "Complete prediction MSE : 0.0011499235036916257\n",
            "Epoch 164 : Train loss 4.001564675476402, validation loss 8.585336685180664\n",
            "Complete prediction MSE : 0.0012388810341692825\n",
            "Epoch 165 : Train loss 4.0147282048128545, validation loss 8.986536979675293\n",
            "Complete prediction MSE : 0.0010561572130693947\n",
            "Epoch 166 : Train loss 3.9967198353260756, validation loss 8.493749618530273\n",
            "Complete prediction MSE : 0.0011463092955423205\n",
            "Epoch 167 : Train loss 3.9942280794493854, validation loss 8.578337669372559\n",
            "Complete prediction MSE : 0.0011686307884823234\n",
            "Epoch 168 : Train loss 3.9864220479503274, validation loss 8.752720832824707\n",
            "Complete prediction MSE : 0.0011506471951037017\n",
            "Epoch 169 : Train loss 3.9889416061341763, validation loss 8.021017074584961\n",
            "Complete prediction MSE : 0.0012777603754494328\n",
            "Epoch 170 : Train loss 3.959656129591167, validation loss 8.205021858215332\n",
            "Complete prediction MSE : 0.0010737022859785858\n",
            "Epoch 171 : Train loss 3.965215798933059, validation loss 8.306288719177246\n",
            "Complete prediction MSE : 0.0011988203282091772\n",
            "Epoch 172 : Train loss 4.012487757951021, validation loss 7.896237373352051\n",
            "Complete prediction MSE : 0.0011902250091955521\n",
            "Epoch 173 : Train loss 3.956967077217996, validation loss 8.935132026672363\n",
            "Complete prediction MSE : 0.001079840992428817\n",
            "Epoch 174 : Train loss 3.9950419859960675, validation loss 8.063270568847656\n",
            "Complete prediction MSE : 0.0011711639248260474\n",
            "Epoch 175 : Train loss 3.954326172824949, validation loss 8.603938102722168\n",
            "Complete prediction MSE : 0.0011691274622164017\n",
            "Epoch 176 : Train loss 3.978051786776632, validation loss 8.646008491516113\n",
            "Complete prediction MSE : 0.0010888836698827442\n",
            "Epoch 177 : Train loss 3.98367111524567, validation loss 8.37250804901123\n",
            "Complete prediction MSE : 0.0012680344029766639\n",
            "Epoch 178 : Train loss 3.9188573686406016, validation loss 8.775995254516602\n",
            "Complete prediction MSE : 0.0011951177580368417\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 4\n",
            "Epoch 1 : Train loss 34.18063764460385, validation loss 15.28143310546875\n",
            "Complete prediction MSE : 0.003321195984372061\n",
            "Saving model\n",
            "Epoch 2 : Train loss 14.706361444666982, validation loss 11.669182777404785\n",
            "Complete prediction MSE : 0.0029132585847704774\n",
            "Saving model\n",
            "Epoch 3 : Train loss 18.202995819970965, validation loss 12.770374298095703\n",
            "Complete prediction MSE : 0.002955587801821744\n",
            "Epoch 4 : Train loss 13.00351481884718, validation loss 11.390881538391113\n",
            "Complete prediction MSE : 0.0028527622205513164\n",
            "Saving model\n",
            "Epoch 5 : Train loss 11.980191443115473, validation loss 9.615732192993164\n",
            "Complete prediction MSE : 0.002531572772594722\n",
            "Saving model\n",
            "Epoch 6 : Train loss 10.890300557017326, validation loss 8.997694969177246\n",
            "Complete prediction MSE : 0.0025889815127232087\n",
            "Epoch 7 : Train loss 18.044237229973078, validation loss 48.426971435546875\n",
            "Complete prediction MSE : 0.004986060756360265\n",
            "Epoch 8 : Train loss 17.64470672234893, validation loss 13.093362808227539\n",
            "Complete prediction MSE : 0.0030054989654422284\n",
            "Epoch 9 : Train loss 13.543677389621735, validation loss 11.521469116210938\n",
            "Complete prediction MSE : 0.002668824346651865\n",
            "Epoch 10 : Train loss 11.889932518824935, validation loss 11.720539093017578\n",
            "Complete prediction MSE : 0.0029302924513939267\n",
            "Epoch 11 : Train loss 10.814920991659164, validation loss 9.80044174194336\n",
            "Complete prediction MSE : 0.003114414192924258\n",
            "Epoch 12 : Train loss 9.965346455574036, validation loss 10.052188873291016\n",
            "Complete prediction MSE : 0.00287978333787442\n",
            "Epoch 13 : Train loss 9.373238118365407, validation loss 9.186502456665039\n",
            "Complete prediction MSE : 0.0028023769818936346\n",
            "Epoch 14 : Train loss 8.963484370149672, validation loss 8.790970802307129\n",
            "Complete prediction MSE : 0.00250429861011955\n",
            "Saving model\n",
            "Epoch 15 : Train loss 8.72919254284352, validation loss 8.735373497009277\n",
            "Complete prediction MSE : 0.0024830120952837056\n",
            "Saving model\n",
            "Epoch 16 : Train loss 8.481723200529814, validation loss 8.941028594970703\n",
            "Complete prediction MSE : 0.0024498442555991465\n",
            "Saving model\n",
            "Epoch 17 : Train loss 8.236533115617931, validation loss 9.004425048828125\n",
            "Complete prediction MSE : 0.0022618610158753457\n",
            "Saving model\n",
            "Epoch 18 : Train loss 8.037274054251611, validation loss 8.561007499694824\n",
            "Complete prediction MSE : 0.0024250256888659247\n",
            "Epoch 19 : Train loss 7.845330640673637, validation loss 9.866308212280273\n",
            "Complete prediction MSE : 0.002750382589095256\n",
            "Epoch 20 : Train loss 7.674550499767065, validation loss 9.169154167175293\n",
            "Complete prediction MSE : 0.0022440155962321377\n",
            "Saving model\n",
            "Epoch 21 : Train loss 17.112440077587962, validation loss 14.320073127746582\n",
            "Complete prediction MSE : 0.0029819636745029\n",
            "Epoch 22 : Train loss 11.904755463823676, validation loss 10.917673110961914\n",
            "Complete prediction MSE : 0.0023879419118791718\n",
            "Epoch 23 : Train loss 9.063350076787174, validation loss 9.653838157653809\n",
            "Complete prediction MSE : 0.0022829863904199293\n",
            "Epoch 24 : Train loss 8.02925675548613, validation loss 8.717344284057617\n",
            "Complete prediction MSE : 0.0022433811688265205\n",
            "Saving model\n",
            "Epoch 25 : Train loss 7.616203668527305, validation loss 8.170045852661133\n",
            "Complete prediction MSE : 0.002326663656024475\n",
            "Epoch 26 : Train loss 7.382319268770516, validation loss 8.049720764160156\n",
            "Complete prediction MSE : 0.002251473241254469\n",
            "Epoch 27 : Train loss 7.192256431095302, validation loss 8.769647598266602\n",
            "Complete prediction MSE : 0.002277314980680447\n",
            "Epoch 28 : Train loss 7.043497525155544, validation loss 8.671975135803223\n",
            "Complete prediction MSE : 0.002200217179191999\n",
            "Saving model\n",
            "Epoch 29 : Train loss 6.922850274480879, validation loss 8.793741226196289\n",
            "Complete prediction MSE : 0.0022322129600197836\n",
            "Epoch 30 : Train loss 6.782133196480572, validation loss 8.632225036621094\n",
            "Complete prediction MSE : 0.0021989544514494624\n",
            "Saving model\n",
            "Epoch 31 : Train loss 6.658794105984271, validation loss 8.3274564743042\n",
            "Complete prediction MSE : 0.0023848474812908785\n",
            "Epoch 32 : Train loss 6.5573558155447245, validation loss 8.28492546081543\n",
            "Complete prediction MSE : 0.0021868651133055846\n",
            "Saving model\n",
            "Epoch 33 : Train loss 6.450707593001425, validation loss 8.045026779174805\n",
            "Complete prediction MSE : 0.002306011281902107\n",
            "Epoch 34 : Train loss 6.349827476777136, validation loss 7.868260383605957\n",
            "Complete prediction MSE : 0.0021453054879929565\n",
            "Saving model\n",
            "Epoch 35 : Train loss 6.275389789603651, validation loss 7.583041191101074\n",
            "Complete prediction MSE : 0.0019830050502601905\n",
            "Saving model\n",
            "Epoch 36 : Train loss 6.168766271322966, validation loss 7.875826358795166\n",
            "Complete prediction MSE : 0.002100425205469969\n",
            "Epoch 37 : Train loss 6.101809841580689, validation loss 8.069863319396973\n",
            "Complete prediction MSE : 0.001875720841594812\n",
            "Saving model\n",
            "Epoch 38 : Train loss 6.026812905445695, validation loss 8.264512062072754\n",
            "Complete prediction MSE : 0.002077204160075886\n",
            "Epoch 39 : Train loss 5.925572458654642, validation loss 7.399051189422607\n",
            "Complete prediction MSE : 0.002094399763078483\n",
            "Epoch 40 : Train loss 5.88039218634367, validation loss 8.43315315246582\n",
            "Complete prediction MSE : 0.001990810116865058\n",
            "Epoch 41 : Train loss 5.782421348616481, validation loss 8.239215850830078\n",
            "Complete prediction MSE : 0.0019060412539289068\n",
            "Epoch 42 : Train loss 5.710967774502933, validation loss 8.235968589782715\n",
            "Complete prediction MSE : 0.0018423631969491068\n",
            "Saving model\n",
            "Epoch 43 : Train loss 5.658484137617052, validation loss 8.34627914428711\n",
            "Complete prediction MSE : 0.001956099544833466\n",
            "Epoch 44 : Train loss 5.6197868240997195, validation loss 7.594969272613525\n",
            "Complete prediction MSE : 0.0019430706505609186\n",
            "Epoch 45 : Train loss 5.527528923936188, validation loss 8.443220138549805\n",
            "Complete prediction MSE : 0.0018490581507780257\n",
            "Epoch 46 : Train loss 5.505988289602101, validation loss 8.218815803527832\n",
            "Complete prediction MSE : 0.0018246220878715225\n",
            "Saving model\n",
            "Epoch 47 : Train loss 5.4387440783903, validation loss 7.832415580749512\n",
            "Complete prediction MSE : 0.0019127744970528927\n",
            "Epoch 48 : Train loss 5.424066664651036, validation loss 7.7664079666137695\n",
            "Complete prediction MSE : 0.0018320554229287744\n",
            "Epoch 49 : Train loss 5.367105606943369, validation loss 7.604111194610596\n",
            "Complete prediction MSE : 0.001809724817529652\n",
            "Saving model\n",
            "Epoch 50 : Train loss 5.319378280080855, validation loss 7.664828300476074\n",
            "Complete prediction MSE : 0.0016658974616157378\n",
            "Saving model\n",
            "Epoch 51 : Train loss 5.305904978886247, validation loss 8.818082809448242\n",
            "Complete prediction MSE : 0.0016780657296194897\n",
            "Epoch 52 : Train loss 5.241854346357286, validation loss 8.244565963745117\n",
            "Complete prediction MSE : 0.0015191894670928887\n",
            "Saving model\n",
            "Epoch 53 : Train loss 5.1803908152505755, validation loss 7.81355619430542\n",
            "Complete prediction MSE : 0.001688646059844764\n",
            "Epoch 54 : Train loss 5.168989415280521, validation loss 7.719178199768066\n",
            "Complete prediction MSE : 0.001563277718468313\n",
            "Epoch 55 : Train loss 5.128015131689608, validation loss 7.78309440612793\n",
            "Complete prediction MSE : 0.0016509670085714256\n",
            "Epoch 56 : Train loss 5.127329899929464, validation loss 7.848391056060791\n",
            "Complete prediction MSE : 0.0016285633581590026\n",
            "Epoch 57 : Train loss 5.093804117292166, validation loss 8.103474617004395\n",
            "Complete prediction MSE : 0.0014925626530738862\n",
            "Saving model\n",
            "Epoch 58 : Train loss 5.071570793166757, validation loss 8.0618896484375\n",
            "Complete prediction MSE : 0.0014840558778695142\n",
            "Saving model\n",
            "Epoch 59 : Train loss 5.033058498054743, validation loss 8.249634742736816\n",
            "Complete prediction MSE : 0.0014804464294585885\n",
            "Saving model\n",
            "Epoch 60 : Train loss 4.986571371555328, validation loss 7.868721008300781\n",
            "Complete prediction MSE : 0.0014665381469602568\n",
            "Saving model\n",
            "Epoch 61 : Train loss 4.952160282060504, validation loss 7.999876022338867\n",
            "Complete prediction MSE : 0.0015389795779220477\n",
            "Epoch 62 : Train loss 4.934313672594726, validation loss 8.08132553100586\n",
            "Complete prediction MSE : 0.001376911574241435\n",
            "Saving model\n",
            "Epoch 63 : Train loss 4.879097766242921, validation loss 7.905926704406738\n",
            "Complete prediction MSE : 0.0013404783201650043\n",
            "Saving model\n",
            "Epoch 64 : Train loss 4.890431602485478, validation loss 8.273600578308105\n",
            "Complete prediction MSE : 0.001320229377110267\n",
            "Saving model\n",
            "Epoch 65 : Train loss 4.85037849470973, validation loss 8.503854751586914\n",
            "Complete prediction MSE : 0.0015584023424180576\n",
            "Epoch 66 : Train loss 4.838808380998671, validation loss 8.079224586486816\n",
            "Complete prediction MSE : 0.0014116247478794355\n",
            "Epoch 67 : Train loss 4.804190807044506, validation loss 7.944748878479004\n",
            "Complete prediction MSE : 0.0012625431340560235\n",
            "Saving model\n",
            "Epoch 68 : Train loss 4.756235278211534, validation loss 8.15224838256836\n",
            "Complete prediction MSE : 0.0013077544895782772\n",
            "Epoch 69 : Train loss 4.758882286958396, validation loss 8.054738998413086\n",
            "Complete prediction MSE : 0.001319550142992847\n",
            "Epoch 70 : Train loss 4.750902349129319, validation loss 8.070828437805176\n",
            "Complete prediction MSE : 0.0013659384778921617\n",
            "Epoch 71 : Train loss 4.686661531217396, validation loss 7.687232494354248\n",
            "Complete prediction MSE : 0.0012733462161625933\n",
            "Epoch 72 : Train loss 4.671308563090861, validation loss 7.843986511230469\n",
            "Complete prediction MSE : 0.0013551450350453948\n",
            "Epoch 73 : Train loss 4.660593601409346, validation loss 7.458428859710693\n",
            "Complete prediction MSE : 0.0013875191956390102\n",
            "Epoch 74 : Train loss 4.629575042519718, validation loss 8.27920150756836\n",
            "Complete prediction MSE : 0.0012395648224210057\n",
            "Saving model\n",
            "Epoch 75 : Train loss 4.640432256739587, validation loss 7.718412399291992\n",
            "Complete prediction MSE : 0.0012784132536568032\n",
            "Epoch 76 : Train loss 4.62675501126796, validation loss 8.25062084197998\n",
            "Complete prediction MSE : 0.0011897760413255589\n",
            "Saving model\n",
            "Epoch 77 : Train loss 4.600147717166692, validation loss 8.067729949951172\n",
            "Complete prediction MSE : 0.0014573292846662813\n",
            "Epoch 78 : Train loss 4.583817363716662, validation loss 8.326881408691406\n",
            "Complete prediction MSE : 0.0012540642795251503\n",
            "Epoch 79 : Train loss 4.573401976842433, validation loss 8.59264850616455\n",
            "Complete prediction MSE : 0.0015330058340832177\n",
            "Epoch 80 : Train loss 4.581677027512342, validation loss 7.647991180419922\n",
            "Complete prediction MSE : 0.001313022618336234\n",
            "Epoch 81 : Train loss 4.551261123269796, validation loss 7.966461181640625\n",
            "Complete prediction MSE : 0.0012920258975738902\n",
            "Epoch 82 : Train loss 4.505945147946477, validation loss 7.944949150085449\n",
            "Complete prediction MSE : 0.0012082837130917906\n",
            "Epoch 83 : Train loss 4.543273468501866, validation loss 7.42326021194458\n",
            "Complete prediction MSE : 0.001256720604410405\n",
            "Epoch 84 : Train loss 4.516146419104189, validation loss 7.979483604431152\n",
            "Complete prediction MSE : 0.0013342052599179964\n",
            "Epoch 85 : Train loss 4.48161741392687, validation loss 7.811361312866211\n",
            "Complete prediction MSE : 0.0014801188687383192\n",
            "Epoch 86 : Train loss 4.459593435749412, validation loss 7.6571526527404785\n",
            "Complete prediction MSE : 0.0012394066554727023\n",
            "Epoch 87 : Train loss 4.474212644156069, validation loss 7.412403583526611\n",
            "Complete prediction MSE : 0.0013163643961910279\n",
            "Epoch 88 : Train loss 4.424104552716017, validation loss 8.088385581970215\n",
            "Complete prediction MSE : 0.00122281917315445\n",
            "Epoch 89 : Train loss 4.454579163342714, validation loss 7.525801181793213\n",
            "Complete prediction MSE : 0.0013475896211915914\n",
            "Epoch 90 : Train loss 4.423868981190026, validation loss 7.757009506225586\n",
            "Complete prediction MSE : 0.0012974248930500672\n",
            "Epoch 91 : Train loss 4.398509253747761, validation loss 7.842009544372559\n",
            "Complete prediction MSE : 0.0011967959188287911\n",
            "Epoch 92 : Train loss 4.397295701317489, validation loss 7.818488597869873\n",
            "Complete prediction MSE : 0.0011182775465011763\n",
            "Saving model\n",
            "Epoch 93 : Train loss 4.387278987560421, validation loss 7.681267738342285\n",
            "Complete prediction MSE : 0.0012056532861183468\n",
            "Epoch 94 : Train loss 4.350018280092627, validation loss 7.78652286529541\n",
            "Complete prediction MSE : 0.0012458045353537733\n",
            "Epoch 95 : Train loss 4.347466972656548, validation loss 8.005317687988281\n",
            "Complete prediction MSE : 0.001206393449994853\n",
            "Epoch 96 : Train loss 4.343725178390741, validation loss 8.031415939331055\n",
            "Complete prediction MSE : 0.0011031407483889579\n",
            "Saving model\n",
            "Epoch 97 : Train loss 4.359706755261868, validation loss 8.049386978149414\n",
            "Complete prediction MSE : 0.0011257001454248133\n",
            "Epoch 98 : Train loss 4.345840234309435, validation loss 8.15771770477295\n",
            "Complete prediction MSE : 0.0012550117018149819\n",
            "Epoch 99 : Train loss 4.33945020288229, validation loss 7.704324722290039\n",
            "Complete prediction MSE : 0.001066024992716585\n",
            "Saving model\n",
            "Epoch 100 : Train loss 4.294459551107138, validation loss 8.089103698730469\n",
            "Complete prediction MSE : 0.0012291119794611053\n",
            "Epoch 101 : Train loss 4.303224268369377, validation loss 8.46246337890625\n",
            "Complete prediction MSE : 0.0011203033969222394\n",
            "Epoch 102 : Train loss 4.27682879101485, validation loss 8.508002281188965\n",
            "Complete prediction MSE : 0.0011738166923773606\n",
            "Epoch 103 : Train loss 4.278837359510362, validation loss 8.069016456604004\n",
            "Complete prediction MSE : 0.001195412270863532\n",
            "Epoch 104 : Train loss 4.250417606439441, validation loss 8.913663864135742\n",
            "Complete prediction MSE : 0.0011724424798905243\n",
            "Epoch 105 : Train loss 4.2888670321553946, validation loss 8.510334014892578\n",
            "Complete prediction MSE : 0.0013383300800939152\n",
            "Epoch 106 : Train loss 4.235367267392576, validation loss 8.40347671508789\n",
            "Complete prediction MSE : 0.0011885135621098977\n",
            "Epoch 107 : Train loss 4.246090088039637, validation loss 8.38211727142334\n",
            "Complete prediction MSE : 0.001069662253559076\n",
            "Epoch 108 : Train loss 4.2547364216297865, validation loss 7.87871789932251\n",
            "Complete prediction MSE : 0.0011252270542931617\n",
            "Epoch 109 : Train loss 4.191158663947135, validation loss 7.896056175231934\n",
            "Complete prediction MSE : 0.0010723729881592754\n",
            "Epoch 110 : Train loss 4.162818908225745, validation loss 8.244943618774414\n",
            "Complete prediction MSE : 0.001160333386098303\n",
            "Epoch 111 : Train loss 4.185996443964541, validation loss 8.275039672851562\n",
            "Complete prediction MSE : 0.0010721465078323013\n",
            "Epoch 112 : Train loss 4.184892256744206, validation loss 8.248257637023926\n",
            "Complete prediction MSE : 0.001071392892574506\n",
            "Epoch 113 : Train loss 4.191767069045454, validation loss 8.749839782714844\n",
            "Complete prediction MSE : 0.0010773152037525725\n",
            "Epoch 114 : Train loss 4.152243261225522, validation loss 8.116670608520508\n",
            "Complete prediction MSE : 0.0010846986184575168\n",
            "Epoch 115 : Train loss 4.199423756450415, validation loss 7.536689758300781\n",
            "Complete prediction MSE : 0.0010844231785567006\n",
            "Epoch 116 : Train loss 4.1719922800548375, validation loss 7.616950988769531\n",
            "Complete prediction MSE : 0.0011192785130065335\n",
            "Epoch 117 : Train loss 4.174800405744463, validation loss 7.984206676483154\n",
            "Complete prediction MSE : 0.001142405278660175\n",
            "Epoch 118 : Train loss 4.157417653594166, validation loss 7.649656295776367\n",
            "Complete prediction MSE : 0.0011495916441629404\n",
            "Epoch 119 : Train loss 4.146761830430478, validation loss 8.407576560974121\n",
            "Complete prediction MSE : 0.001050987572949552\n",
            "Saving model\n",
            "Epoch 120 : Train loss 4.1292148642241955, validation loss 7.40681266784668\n",
            "Complete prediction MSE : 0.0010834017259750408\n",
            "Epoch 121 : Train loss 4.122666882351041, validation loss 8.239978790283203\n",
            "Complete prediction MSE : 0.0010536093660068445\n",
            "Epoch 122 : Train loss 4.117540307808667, validation loss 7.916449069976807\n",
            "Complete prediction MSE : 0.0011018661758728462\n",
            "Epoch 123 : Train loss 4.13117282371968, validation loss 8.52338695526123\n",
            "Complete prediction MSE : 0.0011519294222347453\n",
            "Epoch 124 : Train loss 4.08911622967571, validation loss 8.735085487365723\n",
            "Complete prediction MSE : 0.0011421786970078642\n",
            "Epoch 125 : Train loss 4.152016306761652, validation loss 8.07569408416748\n",
            "Complete prediction MSE : 0.001288044837406131\n",
            "Epoch 126 : Train loss 4.120862413197756, validation loss 8.249606132507324\n",
            "Complete prediction MSE : 0.0012125655183906044\n",
            "Epoch 127 : Train loss 4.088742314372212, validation loss 9.070934295654297\n",
            "Complete prediction MSE : 0.0012410828809455445\n",
            "Epoch 128 : Train loss 4.102676880080253, validation loss 8.398677825927734\n",
            "Complete prediction MSE : 0.0010959966933510388\n",
            "Epoch 129 : Train loss 4.084753010887653, validation loss 8.246177673339844\n",
            "Complete prediction MSE : 0.00111913962850425\n",
            "Epoch 130 : Train loss 4.1347819291986525, validation loss 8.380404472351074\n",
            "Complete prediction MSE : 0.0009683707951530521\n",
            "Saving model\n",
            "Epoch 131 : Train loss 4.0894382651895285, validation loss 7.783847332000732\n",
            "Complete prediction MSE : 0.0012181939846387393\n",
            "Epoch 132 : Train loss 4.067415248602629, validation loss 8.746831893920898\n",
            "Complete prediction MSE : 0.0010871376859267268\n",
            "Epoch 133 : Train loss 4.039769852999598, validation loss 8.19309139251709\n",
            "Complete prediction MSE : 0.0010869037061358856\n",
            "Epoch 134 : Train loss 4.051806506700814, validation loss 7.7132887840271\n",
            "Complete prediction MSE : 0.001216109005324062\n",
            "Epoch 135 : Train loss 4.074696839787066, validation loss 8.563288688659668\n",
            "Complete prediction MSE : 0.0015136295304162594\n",
            "Epoch 136 : Train loss 4.05851151002571, validation loss 8.575377464294434\n",
            "Complete prediction MSE : 0.001275692358600449\n",
            "Epoch 137 : Train loss 4.0553897260688245, validation loss 7.568914413452148\n",
            "Complete prediction MSE : 0.0012154224713882287\n",
            "Epoch 138 : Train loss 4.015816811937839, validation loss 8.360169410705566\n",
            "Complete prediction MSE : 0.0012352286345556722\n",
            "Epoch 139 : Train loss 4.010570479091257, validation loss 8.68551254272461\n",
            "Complete prediction MSE : 0.0010444669323243757\n",
            "Epoch 140 : Train loss 4.007735972758383, validation loss 7.606559753417969\n",
            "Complete prediction MSE : 0.0011192018931405466\n",
            "Epoch 141 : Train loss 4.025710024405271, validation loss 8.184884071350098\n",
            "Complete prediction MSE : 0.001280564839077337\n",
            "Epoch 142 : Train loss 4.035071752499789, validation loss 8.226893424987793\n",
            "Complete prediction MSE : 0.0010414238495566619\n",
            "Epoch 143 : Train loss 4.0496186022646725, validation loss 8.674328804016113\n",
            "Complete prediction MSE : 0.001429285524671326\n",
            "Epoch 144 : Train loss 4.001966446172446, validation loss 8.325807571411133\n",
            "Complete prediction MSE : 0.0012854608315077854\n",
            "Epoch 145 : Train loss 3.960991901345551, validation loss 8.326276779174805\n",
            "Complete prediction MSE : 0.0012884152623642588\n",
            "Epoch 146 : Train loss 4.033799701370299, validation loss 8.53117847442627\n",
            "Complete prediction MSE : 0.001051678642215986\n",
            "Epoch 147 : Train loss 4.018788226414472, validation loss 7.915720462799072\n",
            "Complete prediction MSE : 0.00112141803743988\n",
            "Epoch 148 : Train loss 3.9845384364016354, validation loss 7.8841328620910645\n",
            "Complete prediction MSE : 0.0012776360859052289\n",
            "Epoch 149 : Train loss 3.947357607539743, validation loss 7.756683826446533\n",
            "Complete prediction MSE : 0.0011299962266965648\n",
            "Epoch 150 : Train loss 3.957445311360061, validation loss 8.132302284240723\n",
            "Complete prediction MSE : 0.001374768059768492\n",
            "Epoch 151 : Train loss 3.9834282570518553, validation loss 8.203834533691406\n",
            "Complete prediction MSE : 0.0010762843208713974\n",
            "Epoch 152 : Train loss 3.935287061613053, validation loss 8.508084297180176\n",
            "Complete prediction MSE : 0.0012598938432237332\n",
            "Epoch 153 : Train loss 3.961762640159577, validation loss 8.110024452209473\n",
            "Complete prediction MSE : 0.0009454651765613989\n",
            "Saving model\n",
            "Epoch 154 : Train loss 3.9690148779191077, validation loss 7.3206634521484375\n",
            "Complete prediction MSE : 0.0009930981565268219\n",
            "Epoch 155 : Train loss 3.9359778575599194, validation loss 8.332794189453125\n",
            "Complete prediction MSE : 0.001434798406721477\n",
            "Epoch 156 : Train loss 3.905852834228426, validation loss 8.320438385009766\n",
            "Complete prediction MSE : 0.00132410271025336\n",
            "Epoch 157 : Train loss 3.9822920532897115, validation loss 8.39968490600586\n",
            "Complete prediction MSE : 0.0014670772987656424\n",
            "Epoch 158 : Train loss 3.9182645711116493, validation loss 8.389178276062012\n",
            "Complete prediction MSE : 0.00112539673531122\n",
            "Epoch 159 : Train loss 3.9534209216944873, validation loss 7.808298110961914\n",
            "Complete prediction MSE : 0.0011407427818573756\n",
            "Epoch 160 : Train loss 3.9408879657275975, validation loss 8.017436981201172\n",
            "Complete prediction MSE : 0.0014806140776611938\n",
            "Epoch 161 : Train loss 3.907196265179664, validation loss 8.380989074707031\n",
            "Complete prediction MSE : 0.0015127563352407367\n",
            "Epoch 162 : Train loss 3.8954273741692305, validation loss 7.747323513031006\n",
            "Complete prediction MSE : 0.0012332244818550947\n",
            "Epoch 163 : Train loss 3.9597544660791755, validation loss 8.13446044921875\n",
            "Complete prediction MSE : 0.0015926477143928138\n",
            "Epoch 164 : Train loss 3.9615522199310362, validation loss 8.29677963256836\n",
            "Complete prediction MSE : 0.001225049377763317\n",
            "Epoch 165 : Train loss 3.9219028968364, validation loss 7.667605400085449\n",
            "Complete prediction MSE : 0.0013062425876189368\n",
            "Epoch 166 : Train loss 3.90781042445451, validation loss 7.928027153015137\n",
            "Complete prediction MSE : 0.0014037646074448326\n",
            "Epoch 167 : Train loss 3.897782632149756, validation loss 8.008137702941895\n",
            "Complete prediction MSE : 0.0010605102934664616\n",
            "Epoch 168 : Train loss 3.8738081962801516, validation loss 8.17735767364502\n",
            "Complete prediction MSE : 0.0011946025459414486\n",
            "Epoch 169 : Train loss 3.885323002934456, validation loss 8.352476119995117\n",
            "Complete prediction MSE : 0.001039523052878233\n",
            "Epoch 170 : Train loss 3.8833276657387614, validation loss 8.188002586364746\n",
            "Complete prediction MSE : 0.0011010756823861473\n",
            "Epoch 171 : Train loss 3.930800258181989, validation loss 8.587425231933594\n",
            "Complete prediction MSE : 0.0012234899127823366\n",
            "Epoch 172 : Train loss 3.8577778851613402, validation loss 7.756641387939453\n",
            "Complete prediction MSE : 0.0010467098545614672\n",
            "Epoch 173 : Train loss 3.903119557071477, validation loss 8.304136276245117\n",
            "Complete prediction MSE : 0.001304808421820726\n",
            "Epoch 174 : Train loss 3.8873969251289964, validation loss 8.298338890075684\n",
            "Complete prediction MSE : 0.0012048806879189295\n",
            "Epoch 175 : Train loss 3.8773696809075773, validation loss 8.956009864807129\n",
            "Complete prediction MSE : 0.001285511231226627\n",
            "Epoch 176 : Train loss 3.8310211109928787, validation loss 8.016387939453125\n",
            "Complete prediction MSE : 0.0013592653485180303\n",
            "Epoch 177 : Train loss 3.881649089977145, validation loss 7.724542140960693\n",
            "Complete prediction MSE : 0.0013692057500086867\n",
            "Epoch 178 : Train loss 3.880387293174863, validation loss 8.954765319824219\n",
            "Complete prediction MSE : 0.0016253518033609539\n",
            "Epoch 179 : Train loss 3.8645037445239723, validation loss 8.507695198059082\n",
            "Complete prediction MSE : 0.001405110296140619\n",
            "Epoch 180 : Train loss 3.8262702305801213, validation loss 9.01598072052002\n",
            "Complete prediction MSE : 0.0013069255490997485\n",
            "Epoch 181 : Train loss 3.8667001044377685, validation loss 8.216601371765137\n",
            "Complete prediction MSE : 0.0011269884780442023\n",
            "Epoch 182 : Train loss 3.858269310556352, validation loss 8.723764419555664\n",
            "Complete prediction MSE : 0.001251292341942974\n",
            "Epoch 183 : Train loss 3.8642323040403426, validation loss 8.488964080810547\n",
            "Complete prediction MSE : 0.0011182549692701025\n",
            "Epoch 184 : Train loss 3.859221055638045, validation loss 8.006937026977539\n",
            "Complete prediction MSE : 0.0013408943803211075\n",
            "Epoch 185 : Train loss 3.860955160111189, validation loss 7.901907444000244\n",
            "Complete prediction MSE : 0.0018503698311047698\n",
            "Epoch 186 : Train loss 3.810414200183004, validation loss 8.028116226196289\n",
            "Complete prediction MSE : 0.0013452521726749415\n",
            "Epoch 187 : Train loss 3.857187708374113, validation loss 8.67741870880127\n",
            "Complete prediction MSE : 0.0014157863683987972\n",
            "Epoch 188 : Train loss 3.88232170837, validation loss 9.0782470703125\n",
            "Complete prediction MSE : 0.0012095059505674802\n",
            "Epoch 189 : Train loss 3.830146328546107, validation loss 8.532575607299805\n",
            "Complete prediction MSE : 0.0011213223705917124\n",
            "Epoch 190 : Train loss 3.8026875676587224, validation loss 8.641385078430176\n",
            "Complete prediction MSE : 0.0015247681813877739\n",
            "Epoch 191 : Train loss 3.8691574223339558, validation loss 8.360849380493164\n",
            "Complete prediction MSE : 0.0011052154892550114\n",
            "Epoch 192 : Train loss 3.8174776481464505, validation loss 8.808063507080078\n",
            "Complete prediction MSE : 0.0012277863379007393\n",
            "Epoch 193 : Train loss 3.7750975200906396, validation loss 8.494124412536621\n",
            "Complete prediction MSE : 0.0010713403501586634\n",
            "Epoch 194 : Train loss 3.794793989509344, validation loss 8.206305503845215\n",
            "Complete prediction MSE : 0.0011403777810795493\n",
            "Epoch 195 : Train loss 3.82237965753302, validation loss 8.44063663482666\n",
            "Complete prediction MSE : 0.0014010521017106328\n",
            "Epoch 196 : Train loss 3.809967862442136, validation loss 8.081887245178223\n",
            "Complete prediction MSE : 0.0011939640753979724\n",
            "Epoch 197 : Train loss 3.7869575396180153, validation loss 8.127830505371094\n",
            "Complete prediction MSE : 0.0011540377389054654\n",
            "Epoch 198 : Train loss 3.8062939667142928, validation loss 8.368471145629883\n",
            "Complete prediction MSE : 0.001406760508899447\n",
            "Epoch 199 : Train loss 3.781831200234592, validation loss 9.158565521240234\n",
            "Complete prediction MSE : 0.0011530624496563357\n",
            "Epoch 200 : Train loss 3.828752744011581, validation loss 8.698261260986328\n",
            "Complete prediction MSE : 0.0011346234972019389\n",
            "Epoch 201 : Train loss 3.8023757389746606, validation loss 8.788959503173828\n",
            "Complete prediction MSE : 0.0012833319699586232\n",
            "Epoch 202 : Train loss 3.7972146342508495, validation loss 8.620609283447266\n",
            "Complete prediction MSE : 0.0010398839278088863\n",
            "Epoch 203 : Train loss 3.790196475572884, validation loss 9.12739372253418\n",
            "Complete prediction MSE : 0.0014608862652342508\n",
            "Early stopping due to no more improvement and/or unstable training\n"
          ]
        }
      ],
      "source": [
        "nb_seeds = 5\n",
        "for seed in range(nb_seeds):\n",
        "  torch.manual_seed(seed)\n",
        "  model = IKAE_zp(input_dim=20, hidden_dim=256, n_layers_encoder=6, zero_padding=16,\n",
        "                     positive_nonlin=nn.Softplus(), flow='NICE', device=device).to(device)\n",
        "  print(f'Training model with seed {seed}')\n",
        "  epochs = 500\n",
        "  #opt = model.configure_optimizers(lr=1e-3)\n",
        "  opt = model.configure_optimizers(lr=1e-3, weight_decay=1e-6) # with weight decay\n",
        "  max_patience = 50\n",
        "  patience = 0\n",
        "  time_span = 100\n",
        "  alpha = 0\n",
        "  lamda = 100.\n",
        "  model.best_epoch, model.best_val = 0, 1e15\n",
        "  last_train_index = 53\n",
        "  model.train_losses = []\n",
        "  model.val_losses = []\n",
        "  model.val_losses2 = []\n",
        "  model.val_losses3 = []\n",
        "  starting_point = 0\n",
        "  loss_every = 1\n",
        "\n",
        "  for epoch in range(epochs+1) :\n",
        "    if patience >= max_patience:\n",
        "      print('Early stopping due to no more improvement and/or unstable training')\n",
        "      break\n",
        "    epoch_loss = 0\n",
        "    epoch_val_loss = 0\n",
        "    model.train()\n",
        "    for batch in range(nb_batches) :\n",
        "      opt.zero_grad()\n",
        "      x0 = state_batches[0,batch].to(device)\n",
        "      gt = state_batches[:,batch].to(device)\n",
        "      latent_states = model.encode(gt.flatten(0,1))\n",
        "      #print(gt.shape, latent_states.shape, x0.shape)\n",
        "      xt, phis = model.forward_n_remember(x0, time_span)\n",
        "      phi_0 = phis[0]\n",
        "      loss = 0\n",
        "      # Prediction loss\n",
        "      #print(phis.shape, latent_states.shape, gt.shape)\n",
        "      pred_loss = mse_loss(model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], model.input_dim)), gt)\n",
        "      loss += pred_loss\n",
        "      # Reconstruction loss\n",
        "      #ae_loss = mse_loss(model.decode(latent_states).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "      #loss += ae_loss\n",
        "      # Linearity loss\n",
        "      lin_loss = mse_loss(phis, latent_states.reshape((phis.shape[0], phis.shape[1], phis.shape[2])))\n",
        "      loss += lin_loss\n",
        "      # Orthogonality loss\n",
        "      orth_loss = lamda * mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "      loss += orth_loss\n",
        "      #if batch % 100 == 0:\n",
        "        #print(f\"Batch {batch}: loss = {loss}\")\n",
        "        #print(f\"pred loss = {pred_loss}, ae loss = {ae_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\n",
        "        #print(f\"pred loss = {pred_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      epoch_loss += loss.detach().item()\n",
        "\n",
        "    #scheduler.step()\n",
        "    epoch_loss /= nb_batches\n",
        "    model.train_losses.append(epoch_loss)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    x0 = states_val[0].to(device)\n",
        "    gt = states_val.to(device)\n",
        "    latent_states = model.encode(states_val.to(device).flatten(0,1))\n",
        "    xt, phis = model.forward_n_remember(x0, time_span)\n",
        "    phi_0 = phis[0]\n",
        "    # Prediction loss\n",
        "    val_loss += mse_loss(model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], model.input_dim)), gt)\n",
        "    # Reconstruction loss\n",
        "    #val_loss += mse_loss(model.decode(latent_states).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "    # Linearity loss\n",
        "    val_loss += mse_loss(phis, latent_states.reshape((phis.shape[0], phis.shape[1], phis.shape[2])))\n",
        "    # Orthogonality loss\n",
        "    val_loss += lamda * mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "    model.val_losses2.append(val_loss.item())\n",
        "    #epoch_val_loss = val_loss.item()\n",
        "    whole_predictions = np.zeros((data_small.shape[0]-101, data_small.shape[1]//10, data_small.shape[2], data_small.shape[3]))\n",
        "    for column in range(data_small.shape[1] // 10) :\n",
        "      states = torch.Tensor(data_small[1:,10*column]).to(device)\n",
        "      states = torch.cat([states, states - torch.Tensor(data_small[:-1,10*column]).to(device)], dim=2) # Add derivatives\n",
        "      predictions, phis = model.forward_n_remember(states[starting_point],241)\n",
        "      #whole_predictions[starting_point:, column] = predictions[:342-starting_point,:10].cpu().detach()\n",
        "      decoded = model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], model.input_dim))\n",
        "      whole_predictions[starting_point:, column] = decoded[:whole_predictions.shape[0]-starting_point,:,:10].cpu().detach()\n",
        "\n",
        "    val_loss3 = np.mean((data_small[starting_point+1:starting_point+243,::10] - whole_predictions)[starting_point:] **2)\n",
        "    model.val_losses3.append(val_loss3.item())\n",
        "    epoch_val_loss = val_loss3.item()\n",
        "    if epoch % loss_every == 0 :\n",
        "      print(f\"Epoch {epoch+1} : Train loss {model.train_losses[-1]}, validation loss {model.val_losses2[-1]}\")\n",
        "      print(f\"Complete prediction MSE : {model.val_losses3[-1]}\")\n",
        "    if epoch_val_loss < model.best_val : # Save the model parameters\n",
        "      model.best_val = epoch_val_loss\n",
        "      model.best_epoch = epoch\n",
        "      torch.save(model.state_dict(), models_path+f'/best_model_{seed}.pt')\n",
        "      torch.save(model.K, models_path+f'/best_K_{seed}.pt')\n",
        "      patience = 0\n",
        "      print('Saving model')\n",
        "    else:\n",
        "      patience += 1\n",
        "      if math.isnan(epoch_val_loss) or model.train_losses[-1] > 1000:\n",
        "        patience += 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2ox8UefdWDK"
      },
      "source": [
        "# AIKAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X9otqpTdXeE",
        "outputId": "87432b39-42f1-4d45-ed56-9cf4e387fc03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 313932\n",
            "AIKAE(\n",
            "  (positive_nonlin): Softplus(beta=1.0, threshold=20.0)\n",
            "  (invertible_encoder): stacked_NICE(\n",
            "    (bijectors): ModuleList(\n",
            "      (0-5): 6 x NICE(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=10, out_features=256, bias=True)\n",
            "          (1): LeakyReLU(negative_slope=0.01)\n",
            "          (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (augmentation_encoder): ModuleList(\n",
            "    (0): Linear(in_features=20, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (2): Linear(in_features=512, out_features=16, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "model = AIKAE.AIKAE(input_dim=20, hidden_dim=256, n_layers_encoder=6, augmentation_dims=[512,512,16],\n",
        "                    positive_nonlin=nn.Softplus(), flow='NICE', device=device).to(device)\n",
        "print(f\"Number of parameters: {count_parameters(model)}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGW0wIc2dkxz",
        "outputId": "71e49b97-1053-43ae-e7bd-6a08d82d3e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with seed 0\n",
            "Epoch 1 : Train loss 36.87611767090857, validation loss 25.111949920654297\n",
            "Complete prediction MSE : 0.003936433346558266\n",
            "Saving model\n",
            "Epoch 2 : Train loss 15.018192157149315, validation loss 10.20786190032959\n",
            "Complete prediction MSE : 0.0028764619538148547\n",
            "Saving model\n",
            "Epoch 3 : Train loss 28.60874625481665, validation loss 15.317610740661621\n",
            "Complete prediction MSE : 0.0027090137547301006\n",
            "Saving model\n",
            "Epoch 4 : Train loss 13.81826752051711, validation loss 12.338517189025879\n",
            "Complete prediction MSE : 0.0028295211987149544\n",
            "Epoch 5 : Train loss 12.042797798290849, validation loss 10.628305435180664\n",
            "Complete prediction MSE : 0.0027449839010663113\n",
            "Epoch 6 : Train loss 10.907390741631389, validation loss 10.139772415161133\n",
            "Complete prediction MSE : 0.0026205659019569996\n",
            "Saving model\n",
            "Epoch 7 : Train loss 24.967963559553027, validation loss 14.899036407470703\n",
            "Complete prediction MSE : 0.0028323561367534916\n",
            "Epoch 8 : Train loss 13.26255633495748, validation loss 12.181191444396973\n",
            "Complete prediction MSE : 0.00276246023995394\n",
            "Epoch 9 : Train loss 11.15787915699184, validation loss 10.74687671661377\n",
            "Complete prediction MSE : 0.002613163955307704\n",
            "Saving model\n",
            "Epoch 10 : Train loss 9.85509267821908, validation loss 9.670364379882812\n",
            "Complete prediction MSE : 0.0026084511679390246\n",
            "Saving model\n",
            "Epoch 11 : Train loss 31.73630370758474, validation loss 16.503204345703125\n",
            "Complete prediction MSE : 0.0027739260916239115\n",
            "Epoch 12 : Train loss 14.481919694691896, validation loss 13.813885688781738\n",
            "Complete prediction MSE : 0.002618033932029139\n",
            "Epoch 13 : Train loss 12.185468759387732, validation loss 12.923542022705078\n",
            "Complete prediction MSE : 0.0024342597419072993\n",
            "Saving model\n",
            "Epoch 14 : Train loss 10.596765473484993, validation loss 11.497306823730469\n",
            "Complete prediction MSE : 0.002513492170152966\n",
            "Epoch 15 : Train loss 9.375765578821301, validation loss 11.166837692260742\n",
            "Complete prediction MSE : 0.0025968574496247625\n",
            "Epoch 16 : Train loss 15.648240987211466, validation loss 11.224804878234863\n",
            "Complete prediction MSE : 0.0026832045111463312\n",
            "Epoch 17 : Train loss 9.287124466150999, validation loss 9.706220626831055\n",
            "Complete prediction MSE : 0.002495851290147087\n",
            "Epoch 18 : Train loss 7.9774057902395725, validation loss 8.862743377685547\n",
            "Complete prediction MSE : 0.0024518208022093623\n",
            "Epoch 19 : Train loss 7.319555121473968, validation loss 8.495220184326172\n",
            "Complete prediction MSE : 0.0023905928693309358\n",
            "Saving model\n",
            "Epoch 20 : Train loss 16.2154985871166, validation loss 12.172057151794434\n",
            "Complete prediction MSE : 0.002566667091239895\n",
            "Epoch 21 : Train loss 9.651204919442534, validation loss 9.562756538391113\n",
            "Complete prediction MSE : 0.0023560398850353257\n",
            "Saving model\n",
            "Epoch 22 : Train loss 7.81924326531589, validation loss 9.214010238647461\n",
            "Complete prediction MSE : 0.0021875280082775486\n",
            "Saving model\n",
            "Epoch 23 : Train loss 6.99081090465188, validation loss 9.097445487976074\n",
            "Complete prediction MSE : 0.002144668297923678\n",
            "Saving model\n",
            "Epoch 24 : Train loss 7.552659864537418, validation loss 8.349285125732422\n",
            "Complete prediction MSE : 0.0020597845435446752\n",
            "Saving model\n",
            "Epoch 25 : Train loss 6.309416174888611, validation loss 7.896534442901611\n",
            "Complete prediction MSE : 0.0020183255238715486\n",
            "Saving model\n",
            "Epoch 26 : Train loss 7.545933301560581, validation loss 8.512009620666504\n",
            "Complete prediction MSE : 0.002054058026716722\n",
            "Epoch 27 : Train loss 6.037717252038419, validation loss 8.83175277709961\n",
            "Complete prediction MSE : 0.001934850899475804\n",
            "Saving model\n",
            "Epoch 28 : Train loss 5.930419499985874, validation loss 13.66905403137207\n",
            "Complete prediction MSE : 0.003731000968104675\n",
            "Epoch 29 : Train loss 10.006573003716767, validation loss 8.721308708190918\n",
            "Complete prediction MSE : 0.0018614224631654135\n",
            "Saving model\n",
            "Epoch 30 : Train loss 6.048107291571796, validation loss 8.294960021972656\n",
            "Complete prediction MSE : 0.0018561898875848824\n",
            "Saving model\n",
            "Epoch 31 : Train loss 5.7748027285560966, validation loss 8.29302978515625\n",
            "Complete prediction MSE : 0.0018505334951624784\n",
            "Saving model\n",
            "Epoch 32 : Train loss 5.682282128371298, validation loss 8.431724548339844\n",
            "Complete prediction MSE : 0.001974359462450776\n",
            "Epoch 33 : Train loss 5.748376101255417, validation loss 8.526002883911133\n",
            "Complete prediction MSE : 0.0018273689393276408\n",
            "Saving model\n",
            "Epoch 34 : Train loss 5.478819826617837, validation loss 8.33094596862793\n",
            "Complete prediction MSE : 0.0016615796791032474\n",
            "Saving model\n",
            "Epoch 35 : Train loss 5.50117889046669, validation loss 8.170456886291504\n",
            "Complete prediction MSE : 0.001642629772639134\n",
            "Saving model\n",
            "Epoch 36 : Train loss 5.338885091245174, validation loss 7.986881732940674\n",
            "Complete prediction MSE : 0.0015668567376730081\n",
            "Saving model\n",
            "Epoch 37 : Train loss 9.409805336035788, validation loss 14.751340866088867\n",
            "Complete prediction MSE : 0.002590955390323898\n",
            "Epoch 38 : Train loss 7.701400516554713, validation loss 8.897137641906738\n",
            "Complete prediction MSE : 0.0017000159626437083\n",
            "Epoch 39 : Train loss 5.637384847737849, validation loss 8.803557395935059\n",
            "Complete prediction MSE : 0.0016467370568337071\n",
            "Epoch 40 : Train loss 5.319366097450256, validation loss 8.187029838562012\n",
            "Complete prediction MSE : 0.0016323608466155262\n",
            "Epoch 41 : Train loss 5.236774225719273, validation loss 8.07592487335205\n",
            "Complete prediction MSE : 0.0016469959194174942\n",
            "Epoch 42 : Train loss 5.175465782172978, validation loss 8.515481948852539\n",
            "Complete prediction MSE : 0.0016797975318640962\n",
            "Epoch 43 : Train loss 5.127972640097141, validation loss 8.007129669189453\n",
            "Complete prediction MSE : 0.0016195971469173548\n",
            "Epoch 44 : Train loss 5.07137271668762, validation loss 8.130043029785156\n",
            "Complete prediction MSE : 0.00160606087629187\n",
            "Epoch 45 : Train loss 5.051884124986827, validation loss 8.276251792907715\n",
            "Complete prediction MSE : 0.00159013169267967\n",
            "Epoch 46 : Train loss 4.983827333897352, validation loss 8.443258285522461\n",
            "Complete prediction MSE : 0.0015283741675610034\n",
            "Saving model\n",
            "Epoch 47 : Train loss 6.549971231259406, validation loss 50.46416091918945\n",
            "Complete prediction MSE : 0.007442297674375585\n",
            "Epoch 48 : Train loss 10.116822235286236, validation loss 9.391073226928711\n",
            "Complete prediction MSE : 0.0017259379731016863\n",
            "Epoch 49 : Train loss 5.642826426774263, validation loss 9.735716819763184\n",
            "Complete prediction MSE : 0.0016215549917101009\n",
            "Epoch 50 : Train loss 5.1517751244828105, validation loss 9.927214622497559\n",
            "Complete prediction MSE : 0.001561585236724033\n",
            "Epoch 51 : Train loss 5.010829059407115, validation loss 10.358022689819336\n",
            "Complete prediction MSE : 0.0015570813305921432\n",
            "Epoch 52 : Train loss 4.944202581420541, validation loss 9.998340606689453\n",
            "Complete prediction MSE : 0.0015025228224234538\n",
            "Saving model\n",
            "Epoch 53 : Train loss 4.887818301096559, validation loss 9.69249153137207\n",
            "Complete prediction MSE : 0.0014770580062152335\n",
            "Saving model\n",
            "Epoch 54 : Train loss 4.845211553387344, validation loss 9.429222106933594\n",
            "Complete prediction MSE : 0.0014451482146079456\n",
            "Saving model\n",
            "Epoch 55 : Train loss 4.794936364516616, validation loss 9.567704200744629\n",
            "Complete prediction MSE : 0.0015236950329012748\n",
            "Epoch 56 : Train loss 4.769172944128513, validation loss 9.158000946044922\n",
            "Complete prediction MSE : 0.0014768990023297326\n",
            "Epoch 57 : Train loss 4.735358336009085, validation loss 9.7178373336792\n",
            "Complete prediction MSE : 0.0014580783278055518\n",
            "Epoch 58 : Train loss 4.692886281758547, validation loss 9.404199600219727\n",
            "Complete prediction MSE : 0.001426811222117918\n",
            "Saving model\n",
            "Epoch 59 : Train loss 4.677436780184507, validation loss 9.015689849853516\n",
            "Complete prediction MSE : 0.0014027367522141685\n",
            "Saving model\n",
            "Epoch 60 : Train loss 4.6500973124057055, validation loss 9.02631950378418\n",
            "Complete prediction MSE : 0.0013939209559300826\n",
            "Saving model\n",
            "Epoch 61 : Train loss 4.624831129796803, validation loss 8.902657508850098\n",
            "Complete prediction MSE : 0.0013968961307512452\n",
            "Epoch 62 : Train loss 4.59559868555516, validation loss 8.846346855163574\n",
            "Complete prediction MSE : 0.0013568801184421207\n",
            "Saving model\n",
            "Epoch 63 : Train loss 4.571137589402497, validation loss 9.198022842407227\n",
            "Complete prediction MSE : 0.001339292596236346\n",
            "Saving model\n",
            "Epoch 64 : Train loss 4.539887041319162, validation loss 9.033761024475098\n",
            "Complete prediction MSE : 0.0013570071189228721\n",
            "Epoch 65 : Train loss 4.537234162446111, validation loss 9.76268482208252\n",
            "Complete prediction MSE : 0.0014002196056174187\n",
            "Epoch 66 : Train loss 4.497466339729726, validation loss 9.096657752990723\n",
            "Complete prediction MSE : 0.0013757531278740848\n",
            "Epoch 67 : Train loss 4.477563855238259, validation loss 9.587827682495117\n",
            "Complete prediction MSE : 0.0013721650826993695\n",
            "Epoch 68 : Train loss 4.448658905457705, validation loss 9.372599601745605\n",
            "Complete prediction MSE : 0.0013857510887836833\n",
            "Epoch 69 : Train loss 4.433624906465411, validation loss 9.577418327331543\n",
            "Complete prediction MSE : 0.0013871269768247498\n",
            "Epoch 70 : Train loss 4.421263745054603, validation loss 9.414762496948242\n",
            "Complete prediction MSE : 0.0013570950062924637\n",
            "Epoch 71 : Train loss 4.395081014372408, validation loss 9.587188720703125\n",
            "Complete prediction MSE : 0.0013687138164438027\n",
            "Epoch 72 : Train loss 4.379357592668384, validation loss 9.047179222106934\n",
            "Complete prediction MSE : 0.0013539731941437465\n",
            "Epoch 73 : Train loss 4.364668616093695, validation loss 9.163806915283203\n",
            "Complete prediction MSE : 0.0013721013087690057\n",
            "Epoch 74 : Train loss 4.3527755732648075, validation loss 8.610793113708496\n",
            "Complete prediction MSE : 0.0014108717574204679\n",
            "Epoch 75 : Train loss 4.332100563682616, validation loss 8.94001579284668\n",
            "Complete prediction MSE : 0.0014900499387536835\n",
            "Epoch 76 : Train loss 4.322485210373998, validation loss 8.739241600036621\n",
            "Complete prediction MSE : 0.0015985962432532896\n",
            "Epoch 77 : Train loss 4.300135951954871, validation loss 8.971010208129883\n",
            "Complete prediction MSE : 0.00148213750809569\n",
            "Epoch 78 : Train loss 4.276579873170704, validation loss 8.656968116760254\n",
            "Complete prediction MSE : 0.0014241817113075726\n",
            "Epoch 79 : Train loss 4.268852629233152, validation loss 8.489564895629883\n",
            "Complete prediction MSE : 0.001494227468266233\n",
            "Epoch 80 : Train loss 4.25553293665871, validation loss 8.178427696228027\n",
            "Complete prediction MSE : 0.0014807804306159929\n",
            "Epoch 81 : Train loss 4.241916043218225, validation loss 8.766895294189453\n",
            "Complete prediction MSE : 0.0015099731558105608\n",
            "Epoch 82 : Train loss 4.227254827041179, validation loss 8.551915168762207\n",
            "Complete prediction MSE : 0.0013789584460939996\n",
            "Epoch 83 : Train loss 4.216067858040333, validation loss 8.611440658569336\n",
            "Complete prediction MSE : 0.0013842104349164385\n",
            "Epoch 84 : Train loss 4.200858890078962, validation loss 8.585196495056152\n",
            "Complete prediction MSE : 0.0014764740953032945\n",
            "Epoch 85 : Train loss 4.194310256745666, validation loss 8.517641067504883\n",
            "Complete prediction MSE : 0.001365979931838249\n",
            "Epoch 86 : Train loss 4.17340919515118, validation loss 8.375833511352539\n",
            "Complete prediction MSE : 0.0013504984906826008\n",
            "Epoch 87 : Train loss 4.1599097601138055, validation loss 8.206055641174316\n",
            "Complete prediction MSE : 0.0013926451709387186\n",
            "Epoch 88 : Train loss 4.148148194886744, validation loss 8.508564949035645\n",
            "Complete prediction MSE : 0.0014131494669823712\n",
            "Epoch 89 : Train loss 4.1408631964586675, validation loss 8.368976593017578\n",
            "Complete prediction MSE : 0.0013764688805409388\n",
            "Epoch 90 : Train loss 4.127515060827136, validation loss 8.781290054321289\n",
            "Complete prediction MSE : 0.001381972876780746\n",
            "Epoch 91 : Train loss 4.119629655499011, validation loss 8.554630279541016\n",
            "Complete prediction MSE : 0.0013574122773699787\n",
            "Epoch 92 : Train loss 4.1143190446309745, validation loss 8.107421875\n",
            "Complete prediction MSE : 0.0013303121136977107\n",
            "Saving model\n",
            "Epoch 93 : Train loss 4.094665947370231, validation loss 8.214282035827637\n",
            "Complete prediction MSE : 0.0013307427907741014\n",
            "Epoch 94 : Train loss 4.093820494133979, validation loss 8.613615036010742\n",
            "Complete prediction MSE : 0.0012793087504507287\n",
            "Saving model\n",
            "Epoch 95 : Train loss 4.090572468936443, validation loss 8.584230422973633\n",
            "Complete prediction MSE : 0.0013151317478803954\n",
            "Epoch 96 : Train loss 4.0746689713560045, validation loss 8.537568092346191\n",
            "Complete prediction MSE : 0.0012778204852117185\n",
            "Saving model\n",
            "Epoch 97 : Train loss 4.067191138397902, validation loss 8.535538673400879\n",
            "Complete prediction MSE : 0.0012692391709131874\n",
            "Saving model\n",
            "Epoch 98 : Train loss 4.05415330035612, validation loss 8.335290908813477\n",
            "Complete prediction MSE : 0.0012614338646481174\n",
            "Saving model\n",
            "Epoch 99 : Train loss 4.046118639409542, validation loss 8.45764446258545\n",
            "Complete prediction MSE : 0.001270665533085322\n",
            "Epoch 100 : Train loss 4.038777167443186, validation loss 8.411270141601562\n",
            "Complete prediction MSE : 0.0012306890986627315\n",
            "Saving model\n",
            "Epoch 101 : Train loss 4.029211633838713, validation loss 8.578864097595215\n",
            "Complete prediction MSE : 0.0012218468759657346\n",
            "Saving model\n",
            "Epoch 102 : Train loss 4.021240693517029, validation loss 8.53661060333252\n",
            "Complete prediction MSE : 0.0012102466123215683\n",
            "Saving model\n",
            "Epoch 103 : Train loss 4.011614991351962, validation loss 8.317680358886719\n",
            "Complete prediction MSE : 0.0012107104615205536\n",
            "Epoch 104 : Train loss 4.011013732757419, validation loss 8.362814903259277\n",
            "Complete prediction MSE : 0.0012443124731927292\n",
            "Epoch 105 : Train loss 4.00329302251339, validation loss 8.235053062438965\n",
            "Complete prediction MSE : 0.0012301155699784166\n",
            "Epoch 106 : Train loss 3.9885634486563504, validation loss 8.315949440002441\n",
            "Complete prediction MSE : 0.0012235876749019548\n",
            "Epoch 107 : Train loss 3.9838676345534623, validation loss 8.441360473632812\n",
            "Complete prediction MSE : 0.00118383720683059\n",
            "Saving model\n",
            "Epoch 108 : Train loss 3.9753901744261384, validation loss 8.209880828857422\n",
            "Complete prediction MSE : 0.0012660641999889574\n",
            "Epoch 109 : Train loss 3.968857935629785, validation loss 8.552589416503906\n",
            "Complete prediction MSE : 0.00123485262194906\n",
            "Epoch 110 : Train loss 3.96055406704545, validation loss 8.139876365661621\n",
            "Complete prediction MSE : 0.0012369860191833873\n",
            "Epoch 111 : Train loss 3.952911417465657, validation loss 8.265217781066895\n",
            "Complete prediction MSE : 0.0012322408267756552\n",
            "Epoch 112 : Train loss 3.947439775336534, validation loss 8.772586822509766\n",
            "Complete prediction MSE : 0.0012070360364314046\n",
            "Epoch 113 : Train loss 3.9361244654282928, validation loss 8.249958992004395\n",
            "Complete prediction MSE : 0.0012086892908885585\n",
            "Epoch 114 : Train loss 3.9278507851995528, validation loss 8.39955997467041\n",
            "Complete prediction MSE : 0.0012063623805966344\n",
            "Epoch 115 : Train loss 3.9258505408652127, validation loss 8.881336212158203\n",
            "Complete prediction MSE : 0.0012441886304841018\n",
            "Epoch 116 : Train loss 3.9209117027930915, validation loss 8.684924125671387\n",
            "Complete prediction MSE : 0.0012097275070327746\n",
            "Epoch 117 : Train loss 3.9065857557579875, validation loss 8.814983367919922\n",
            "Complete prediction MSE : 0.0011722039970418056\n",
            "Saving model\n",
            "Epoch 118 : Train loss 3.9125999975949526, validation loss 8.81814956665039\n",
            "Complete prediction MSE : 0.0012311800268865788\n",
            "Epoch 119 : Train loss 3.8984198113903403, validation loss 8.822128295898438\n",
            "Complete prediction MSE : 0.00120279913460195\n",
            "Epoch 120 : Train loss 3.8958774427883327, validation loss 8.887487411499023\n",
            "Complete prediction MSE : 0.0011964890150550874\n",
            "Epoch 121 : Train loss 3.8863616255111992, validation loss 8.725049018859863\n",
            "Complete prediction MSE : 0.001234913506082482\n",
            "Epoch 122 : Train loss 3.8858456988818944, validation loss 8.565641403198242\n",
            "Complete prediction MSE : 0.0012481353061507942\n",
            "Epoch 123 : Train loss 3.876713605131954, validation loss 8.555680274963379\n",
            "Complete prediction MSE : 0.0012508967005212663\n",
            "Epoch 124 : Train loss 3.879024608526379, validation loss 8.39649486541748\n",
            "Complete prediction MSE : 0.0012362931328838787\n",
            "Epoch 125 : Train loss 3.874447440262884, validation loss 8.840066909790039\n",
            "Complete prediction MSE : 0.0012992723718250154\n",
            "Epoch 126 : Train loss 3.874149148352444, validation loss 8.807455062866211\n",
            "Complete prediction MSE : 0.0014088122121874117\n",
            "Epoch 127 : Train loss 3.860718083102256, validation loss 8.870902061462402\n",
            "Complete prediction MSE : 0.0012993996153659753\n",
            "Epoch 128 : Train loss 3.8502325154840946, validation loss 8.607895851135254\n",
            "Complete prediction MSE : 0.0013015260139854876\n",
            "Epoch 129 : Train loss 3.842689460143447, validation loss 8.60484504699707\n",
            "Complete prediction MSE : 0.0013057801970507825\n",
            "Epoch 130 : Train loss 3.8364565949887037, validation loss 8.7633056640625\n",
            "Complete prediction MSE : 0.0012978650954121446\n",
            "Epoch 131 : Train loss 3.835669188760221, validation loss 8.64645767211914\n",
            "Complete prediction MSE : 0.0013124210641557994\n",
            "Epoch 132 : Train loss 3.8353980178944767, validation loss 8.578119277954102\n",
            "Complete prediction MSE : 0.0013775142874502364\n",
            "Epoch 133 : Train loss 3.8275965871289372, validation loss 8.564759254455566\n",
            "Complete prediction MSE : 0.0013712112586515318\n",
            "Epoch 134 : Train loss 3.8323660758323967, validation loss 8.564594268798828\n",
            "Complete prediction MSE : 0.0013327176414844918\n",
            "Epoch 135 : Train loss 3.809678304474801, validation loss 8.789399147033691\n",
            "Complete prediction MSE : 0.0013788329555220152\n",
            "Epoch 136 : Train loss 3.807428329717368, validation loss 8.208531379699707\n",
            "Complete prediction MSE : 0.001370662401951432\n",
            "Epoch 137 : Train loss 3.8094986234791577, validation loss 8.796247482299805\n",
            "Complete prediction MSE : 0.0014181955823521677\n",
            "Epoch 138 : Train loss 3.806464282795787, validation loss 8.732115745544434\n",
            "Complete prediction MSE : 0.0013711828999753693\n",
            "Epoch 139 : Train loss 3.794974461197853, validation loss 8.511066436767578\n",
            "Complete prediction MSE : 0.0013197598589940803\n",
            "Epoch 140 : Train loss 3.790574945975095, validation loss 8.98561954498291\n",
            "Complete prediction MSE : 0.0013173252656961667\n",
            "Epoch 141 : Train loss 3.7889139060862362, validation loss 8.83852767944336\n",
            "Complete prediction MSE : 0.0014129773790317976\n",
            "Epoch 142 : Train loss 3.789141355548054, validation loss 8.741923332214355\n",
            "Complete prediction MSE : 0.001336873477626728\n",
            "Epoch 143 : Train loss 3.7761710570193827, validation loss 8.483768463134766\n",
            "Complete prediction MSE : 0.0013400284150497206\n",
            "Epoch 144 : Train loss 3.778902038000524, validation loss 8.600401878356934\n",
            "Complete prediction MSE : 0.0013483273224437066\n",
            "Epoch 145 : Train loss 3.77461590571329, validation loss 9.020445823669434\n",
            "Complete prediction MSE : 0.0013786736985694967\n",
            "Epoch 146 : Train loss 3.7708998192101717, validation loss 8.658439636230469\n",
            "Complete prediction MSE : 0.0013396264156104653\n",
            "Epoch 147 : Train loss 3.7671390073373914, validation loss 8.40564250946045\n",
            "Complete prediction MSE : 0.0012963967225628572\n",
            "Epoch 148 : Train loss 3.763579782564193, validation loss 8.602806091308594\n",
            "Complete prediction MSE : 0.0014334191634415236\n",
            "Epoch 149 : Train loss 3.7568106702528894, validation loss 8.82430362701416\n",
            "Complete prediction MSE : 0.001320057885570605\n",
            "Epoch 150 : Train loss 3.7490606349892914, validation loss 8.561047554016113\n",
            "Complete prediction MSE : 0.0013384973067885433\n",
            "Epoch 151 : Train loss 3.7532179076224566, validation loss 8.66681957244873\n",
            "Complete prediction MSE : 0.0013385853765712614\n",
            "Epoch 152 : Train loss 3.753022964578122, validation loss 8.936509132385254\n",
            "Complete prediction MSE : 0.001353428816307412\n",
            "Epoch 153 : Train loss 3.744289734400809, validation loss 8.637548446655273\n",
            "Complete prediction MSE : 0.0014232839778171825\n",
            "Epoch 154 : Train loss 3.7413302711211145, validation loss 7.9718337059021\n",
            "Complete prediction MSE : 0.0014280462708853995\n",
            "Epoch 155 : Train loss 3.732639951631427, validation loss 8.121240615844727\n",
            "Complete prediction MSE : 0.0014915534337219588\n",
            "Epoch 156 : Train loss 3.725199314765632, validation loss 8.106637954711914\n",
            "Complete prediction MSE : 0.00155194160447152\n",
            "Epoch 157 : Train loss 3.732226516585797, validation loss 8.142803192138672\n",
            "Complete prediction MSE : 0.0014297136775428614\n",
            "Epoch 158 : Train loss 3.723693440668285, validation loss 8.707695960998535\n",
            "Complete prediction MSE : 0.0013909094875177452\n",
            "Epoch 159 : Train loss 3.7306008520536125, validation loss 8.635998725891113\n",
            "Complete prediction MSE : 0.001512949446041141\n",
            "Epoch 160 : Train loss 3.706814759876579, validation loss 8.445173263549805\n",
            "Complete prediction MSE : 0.001432442464519486\n",
            "Epoch 161 : Train loss 3.709971775766462, validation loss 8.69095230102539\n",
            "Complete prediction MSE : 0.0013775615936545238\n",
            "Epoch 162 : Train loss 3.711449450813234, validation loss 8.985445022583008\n",
            "Complete prediction MSE : 0.0013948478662743128\n",
            "Epoch 163 : Train loss 3.7179146544076502, validation loss 8.464009284973145\n",
            "Complete prediction MSE : 0.001439793700281079\n",
            "Epoch 164 : Train loss 3.7134016323834658, validation loss 8.962381362915039\n",
            "Complete prediction MSE : 0.0013045988581886732\n",
            "Epoch 165 : Train loss 3.702657023910433, validation loss 8.327269554138184\n",
            "Complete prediction MSE : 0.0014971988029311048\n",
            "Epoch 166 : Train loss 3.7088250000961125, validation loss 8.971416473388672\n",
            "Complete prediction MSE : 0.0014667570487827606\n",
            "Epoch 167 : Train loss 3.7006432353518903, validation loss 9.101052284240723\n",
            "Complete prediction MSE : 0.0014310732849848067\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 2\n",
            "Epoch 1 : Train loss 33.28848492912948, validation loss 13.545738220214844\n",
            "Complete prediction MSE : 0.0030721980144892405\n",
            "Saving model\n",
            "Epoch 2 : Train loss 24.482759607955813, validation loss 13.522970199584961\n",
            "Complete prediction MSE : 0.002801700999197916\n",
            "Saving model\n",
            "Epoch 3 : Train loss 13.176254553720355, validation loss 11.508047103881836\n",
            "Complete prediction MSE : 0.00275783284532622\n",
            "Saving model\n",
            "Epoch 4 : Train loss 11.315262820571661, validation loss 9.413383483886719\n",
            "Complete prediction MSE : 0.002613228437839008\n",
            "Saving model\n",
            "Epoch 5 : Train loss 10.004212094470859, validation loss 9.005668640136719\n",
            "Complete prediction MSE : 0.002675747200705445\n",
            "Epoch 6 : Train loss 95.24366973154247, validation loss 22.06142807006836\n",
            "Complete prediction MSE : 0.0029375024344036917\n",
            "Epoch 7 : Train loss 19.76755439117551, validation loss 19.688148498535156\n",
            "Complete prediction MSE : 0.0026883064361385538\n",
            "Epoch 8 : Train loss 17.560479190200567, validation loss 17.627553939819336\n",
            "Complete prediction MSE : 0.002671344056467564\n",
            "Epoch 9 : Train loss 16.25694701448083, validation loss 16.390716552734375\n",
            "Complete prediction MSE : 0.0027223363708378896\n",
            "Epoch 10 : Train loss 15.175242096185684, validation loss 15.363795280456543\n",
            "Complete prediction MSE : 0.0027383461112406807\n",
            "Epoch 11 : Train loss 14.175858909264207, validation loss 14.72773265838623\n",
            "Complete prediction MSE : 0.0026485747825976073\n",
            "Epoch 12 : Train loss 13.212871102616191, validation loss 13.536979675292969\n",
            "Complete prediction MSE : 0.0027157342635167367\n",
            "Epoch 13 : Train loss 12.262970494106412, validation loss 12.907894134521484\n",
            "Complete prediction MSE : 0.0025778235022049564\n",
            "Saving model\n",
            "Epoch 14 : Train loss 11.334801761433482, validation loss 11.741334915161133\n",
            "Complete prediction MSE : 0.002626294123454472\n",
            "Epoch 15 : Train loss 10.388367597013712, validation loss 11.240817070007324\n",
            "Complete prediction MSE : 0.0024869054795870127\n",
            "Saving model\n",
            "Epoch 16 : Train loss 9.490292465314269, validation loss 10.31970500946045\n",
            "Complete prediction MSE : 0.00236794637990792\n",
            "Saving model\n",
            "Epoch 17 : Train loss 8.678973581641912, validation loss 9.82581901550293\n",
            "Complete prediction MSE : 0.002390564615350269\n",
            "Epoch 18 : Train loss 8.013892556540668, validation loss 9.289155006408691\n",
            "Complete prediction MSE : 0.0024413326540701167\n",
            "Epoch 19 : Train loss 17.540140245109797, validation loss 11.728915214538574\n",
            "Complete prediction MSE : 0.00273896184365819\n",
            "Epoch 20 : Train loss 9.252876239828765, validation loss 10.775643348693848\n",
            "Complete prediction MSE : 0.002337490629203625\n",
            "Saving model\n",
            "Epoch 21 : Train loss 8.051089095883071, validation loss 10.23230266571045\n",
            "Complete prediction MSE : 0.00237996996652251\n",
            "Epoch 22 : Train loss 7.380665707401931, validation loss 9.18806266784668\n",
            "Complete prediction MSE : 0.0023031727021358777\n",
            "Saving model\n",
            "Epoch 23 : Train loss 6.943049653433263, validation loss 8.96325969696045\n",
            "Complete prediction MSE : 0.002535745721700802\n",
            "Epoch 24 : Train loss 9.312287963926792, validation loss 9.162918090820312\n",
            "Complete prediction MSE : 0.0024319623278175177\n",
            "Epoch 25 : Train loss 6.924947667866945, validation loss 8.658012390136719\n",
            "Complete prediction MSE : 0.002273173840108026\n",
            "Saving model\n",
            "Epoch 26 : Train loss 6.392494414001703, validation loss 8.661462783813477\n",
            "Complete prediction MSE : 0.0023523176787296554\n",
            "Epoch 27 : Train loss 6.262630396522582, validation loss 8.822894096374512\n",
            "Complete prediction MSE : 0.002348207198206795\n",
            "Epoch 28 : Train loss 10.976776922121644, validation loss 9.992941856384277\n",
            "Complete prediction MSE : 0.0024688463230271977\n",
            "Epoch 29 : Train loss 7.20589386112988, validation loss 8.63115406036377\n",
            "Complete prediction MSE : 0.00214040667573053\n",
            "Saving model\n",
            "Epoch 30 : Train loss 6.3071521036326885, validation loss 8.051377296447754\n",
            "Complete prediction MSE : 0.002147463566713838\n",
            "Epoch 31 : Train loss 6.090389456599951, validation loss 8.096043586730957\n",
            "Complete prediction MSE : 0.002087838268951661\n",
            "Saving model\n",
            "Epoch 32 : Train loss 5.958675874397159, validation loss 7.7736711502075195\n",
            "Complete prediction MSE : 0.0020247205522542326\n",
            "Saving model\n",
            "Epoch 33 : Train loss 5.8687480660155416, validation loss 7.802131652832031\n",
            "Complete prediction MSE : 0.001940411823906948\n",
            "Saving model\n",
            "Epoch 34 : Train loss 5.771769331768155, validation loss 8.114347457885742\n",
            "Complete prediction MSE : 0.0019144169169278541\n",
            "Saving model\n",
            "Epoch 35 : Train loss 10.263619883917272, validation loss 8.933497428894043\n",
            "Complete prediction MSE : 0.0018151461966939531\n",
            "Saving model\n",
            "Epoch 36 : Train loss 5.957339795306325, validation loss 8.26887035369873\n",
            "Complete prediction MSE : 0.0018371808843246082\n",
            "Epoch 37 : Train loss 5.669860539026558, validation loss 8.419035911560059\n",
            "Complete prediction MSE : 0.0017448471712978482\n",
            "Saving model\n",
            "Epoch 38 : Train loss 5.5724898194894195, validation loss 13.136896133422852\n",
            "Complete prediction MSE : 0.0023864414671935885\n",
            "Epoch 39 : Train loss 8.239392171613872, validation loss 8.29423713684082\n",
            "Complete prediction MSE : 0.001759342394506685\n",
            "Epoch 40 : Train loss 5.609226111322641, validation loss 8.19438648223877\n",
            "Complete prediction MSE : 0.0016704964862494997\n",
            "Saving model\n",
            "Epoch 41 : Train loss 5.46186400577426, validation loss 8.150412559509277\n",
            "Complete prediction MSE : 0.0016560875918101548\n",
            "Saving model\n",
            "Epoch 42 : Train loss 5.376751039177179, validation loss 7.784785270690918\n",
            "Complete prediction MSE : 0.0016316996796938803\n",
            "Saving model\n",
            "Epoch 43 : Train loss 5.315571843646467, validation loss 7.894531726837158\n",
            "Complete prediction MSE : 0.001632808797711487\n",
            "Epoch 44 : Train loss 5.262026660144329, validation loss 7.662498950958252\n",
            "Complete prediction MSE : 0.0015798587888333476\n",
            "Saving model\n",
            "Epoch 45 : Train loss 5.201003344729543, validation loss 7.787134170532227\n",
            "Complete prediction MSE : 0.0016431729170049583\n",
            "Epoch 46 : Train loss 5.150812083855271, validation loss 7.739840984344482\n",
            "Complete prediction MSE : 0.001593011029268002\n",
            "Epoch 47 : Train loss 5.098897719755769, validation loss 7.713446140289307\n",
            "Complete prediction MSE : 0.001606199381744037\n",
            "Epoch 48 : Train loss 5.0539313005283475, validation loss 7.768911838531494\n",
            "Complete prediction MSE : 0.0016005770593027374\n",
            "Epoch 49 : Train loss 5.019368845038116, validation loss 7.7989583015441895\n",
            "Complete prediction MSE : 0.0014965370745105278\n",
            "Saving model\n",
            "Epoch 50 : Train loss 4.979907549917698, validation loss 7.958248615264893\n",
            "Complete prediction MSE : 0.001505539392024371\n",
            "Epoch 51 : Train loss 4.952097721397877, validation loss 8.334985733032227\n",
            "Complete prediction MSE : 0.0014506797892880293\n",
            "Saving model\n",
            "Epoch 52 : Train loss 4.913833518512547, validation loss 7.944570541381836\n",
            "Complete prediction MSE : 0.0014123843834357903\n",
            "Saving model\n",
            "Epoch 53 : Train loss 4.876806608401239, validation loss 7.664244651794434\n",
            "Complete prediction MSE : 0.0013987585631730142\n",
            "Saving model\n",
            "Epoch 54 : Train loss 4.851365958340466, validation loss 7.83899450302124\n",
            "Complete prediction MSE : 0.001447556962649451\n",
            "Epoch 55 : Train loss 4.821393170394003, validation loss 7.762001037597656\n",
            "Complete prediction MSE : 0.0014217341537100126\n",
            "Epoch 56 : Train loss 4.788059155456722, validation loss 7.463521957397461\n",
            "Complete prediction MSE : 0.0013881463708064641\n",
            "Saving model\n",
            "Epoch 57 : Train loss 4.765885258093476, validation loss 8.145467758178711\n",
            "Complete prediction MSE : 0.0013642993630201626\n",
            "Saving model\n",
            "Epoch 58 : Train loss 4.731082131154835, validation loss 7.829065799713135\n",
            "Complete prediction MSE : 0.0014289688777748904\n",
            "Epoch 59 : Train loss 4.715412102639675, validation loss 8.467777252197266\n",
            "Complete prediction MSE : 0.0013217634923520596\n",
            "Saving model\n",
            "Epoch 60 : Train loss 4.688506858423352, validation loss 7.854263782501221\n",
            "Complete prediction MSE : 0.0013862152079709973\n",
            "Epoch 61 : Train loss 4.663662097416818, validation loss 8.04234504699707\n",
            "Complete prediction MSE : 0.0013827656905516326\n",
            "Epoch 62 : Train loss 4.643552173860371, validation loss 7.563067436218262\n",
            "Complete prediction MSE : 0.0014494105928755934\n",
            "Epoch 63 : Train loss 4.628721763379872, validation loss 7.806085586547852\n",
            "Complete prediction MSE : 0.00129791591592684\n",
            "Saving model\n",
            "Epoch 64 : Train loss 4.599724107421935, validation loss 7.438215732574463\n",
            "Complete prediction MSE : 0.001351142511587954\n",
            "Epoch 65 : Train loss 4.586117434315383, validation loss 7.758344650268555\n",
            "Complete prediction MSE : 0.0013643969575088209\n",
            "Epoch 66 : Train loss 4.567893612198532, validation loss 7.72968053817749\n",
            "Complete prediction MSE : 0.0013832965904148982\n",
            "Epoch 67 : Train loss 4.551599170081317, validation loss 7.932772636413574\n",
            "Complete prediction MSE : 0.0013782620530162829\n",
            "Epoch 68 : Train loss 4.5278457421809435, validation loss 7.823415756225586\n",
            "Complete prediction MSE : 0.0014077936797631094\n",
            "Epoch 69 : Train loss 4.513275171164423, validation loss 7.670011520385742\n",
            "Complete prediction MSE : 0.0014054453724994275\n",
            "Epoch 70 : Train loss 4.49120577564463, validation loss 7.831871509552002\n",
            "Complete prediction MSE : 0.0013786534881635047\n",
            "Epoch 71 : Train loss 4.478630408179015, validation loss 7.9119415283203125\n",
            "Complete prediction MSE : 0.0013989308846939234\n",
            "Epoch 72 : Train loss 4.457064776215702, validation loss 7.885702610015869\n",
            "Complete prediction MSE : 0.001484172416181389\n",
            "Epoch 73 : Train loss 4.451058339793235, validation loss 7.668380260467529\n",
            "Complete prediction MSE : 0.0014080050590461494\n",
            "Epoch 74 : Train loss 4.442962717264891, validation loss 7.621406555175781\n",
            "Complete prediction MSE : 0.0015249718242641148\n",
            "Epoch 75 : Train loss 4.421665095724165, validation loss 7.589234828948975\n",
            "Complete prediction MSE : 0.0015777115082642908\n",
            "Epoch 76 : Train loss 4.409099497832358, validation loss 7.60225248336792\n",
            "Complete prediction MSE : 0.0014859702717145214\n",
            "Epoch 77 : Train loss 4.39453205652535, validation loss 7.6018385887146\n",
            "Complete prediction MSE : 0.0016607762632067475\n",
            "Epoch 78 : Train loss 4.384570012334734, validation loss 7.371781826019287\n",
            "Complete prediction MSE : 0.001580826643100571\n",
            "Epoch 79 : Train loss 4.377337913494557, validation loss 7.732539653778076\n",
            "Complete prediction MSE : 0.0016370844773448453\n",
            "Epoch 80 : Train loss 4.356813367921859, validation loss 7.678697109222412\n",
            "Complete prediction MSE : 0.001898299879788249\n",
            "Epoch 81 : Train loss 4.346437843050808, validation loss 7.592504024505615\n",
            "Complete prediction MSE : 0.001565807621344752\n",
            "Epoch 82 : Train loss 4.331985562108457, validation loss 7.898814678192139\n",
            "Complete prediction MSE : 0.0018266863613993344\n",
            "Epoch 83 : Train loss 4.3240900645032525, validation loss 7.419415473937988\n",
            "Complete prediction MSE : 0.001635067361790323\n",
            "Epoch 84 : Train loss 4.31073203496635, validation loss 7.620526313781738\n",
            "Complete prediction MSE : 0.0017337570053871946\n",
            "Epoch 85 : Train loss 4.296139947604388, validation loss 7.625265121459961\n",
            "Complete prediction MSE : 0.0017020109536632466\n",
            "Epoch 86 : Train loss 4.294770854990929, validation loss 7.576839923858643\n",
            "Complete prediction MSE : 0.0018411718739005172\n",
            "Epoch 87 : Train loss 4.280914204195142, validation loss 7.3773393630981445\n",
            "Complete prediction MSE : 0.0017986568168607557\n",
            "Epoch 88 : Train loss 4.26326311705634, validation loss 7.548061847686768\n",
            "Complete prediction MSE : 0.0015415363132168993\n",
            "Epoch 89 : Train loss 4.268613859079778, validation loss 7.576001167297363\n",
            "Complete prediction MSE : 0.0016348017640270282\n",
            "Epoch 90 : Train loss 4.250083161983639, validation loss 7.352689743041992\n",
            "Complete prediction MSE : 0.0018527025621489243\n",
            "Epoch 91 : Train loss 4.249013879802078, validation loss 7.433955192565918\n",
            "Complete prediction MSE : 0.0018413742490312995\n",
            "Epoch 92 : Train loss 4.224295534193516, validation loss 7.343631744384766\n",
            "Complete prediction MSE : 0.001614739040379727\n",
            "Epoch 93 : Train loss 4.228091148193926, validation loss 7.620436191558838\n",
            "Complete prediction MSE : 0.0018613341228831243\n",
            "Epoch 94 : Train loss 4.213151878677309, validation loss 7.25836181640625\n",
            "Complete prediction MSE : 0.0016332661875634634\n",
            "Epoch 95 : Train loss 4.21110761910677, validation loss 7.386909008026123\n",
            "Complete prediction MSE : 0.001655992127939079\n",
            "Epoch 96 : Train loss 4.191814843099564, validation loss 7.347680568695068\n",
            "Complete prediction MSE : 0.0017601759571509844\n",
            "Epoch 97 : Train loss 4.184136169496924, validation loss 7.397569179534912\n",
            "Complete prediction MSE : 0.00166211039076864\n",
            "Epoch 98 : Train loss 4.170827542897314, validation loss 7.128831386566162\n",
            "Complete prediction MSE : 0.001726359118161843\n",
            "Epoch 99 : Train loss 4.162943436298519, validation loss 7.271399021148682\n",
            "Complete prediction MSE : 0.001638111466570284\n",
            "Epoch 100 : Train loss 4.152135848999023, validation loss 7.101744651794434\n",
            "Complete prediction MSE : 0.0015817534261135383\n",
            "Epoch 101 : Train loss 4.155092716217041, validation loss 7.405434608459473\n",
            "Complete prediction MSE : 0.0016770593922210769\n",
            "Epoch 102 : Train loss 4.138721587602049, validation loss 7.082155704498291\n",
            "Complete prediction MSE : 0.001631534684824901\n",
            "Epoch 103 : Train loss 4.134637286886573, validation loss 7.267184734344482\n",
            "Complete prediction MSE : 0.0016133639713454783\n",
            "Epoch 104 : Train loss 4.126139590982348, validation loss 7.192417621612549\n",
            "Complete prediction MSE : 0.001564282857915948\n",
            "Epoch 105 : Train loss 4.1170234605669975, validation loss 7.0705742835998535\n",
            "Complete prediction MSE : 0.0016148475361443164\n",
            "Epoch 106 : Train loss 4.11157588288188, validation loss 7.073936939239502\n",
            "Complete prediction MSE : 0.0016797587491441156\n",
            "Epoch 107 : Train loss 4.099561933428049, validation loss 7.199100494384766\n",
            "Complete prediction MSE : 0.0017095269524146288\n",
            "Epoch 108 : Train loss 4.090037894435227, validation loss 7.088749408721924\n",
            "Complete prediction MSE : 0.0016864463166560279\n",
            "Epoch 109 : Train loss 4.084544430952519, validation loss 7.175607204437256\n",
            "Complete prediction MSE : 0.0016743131253434999\n",
            "Epoch 110 : Train loss 4.077071729116142, validation loss 7.208571434020996\n",
            "Complete prediction MSE : 0.0016416797793559782\n",
            "Epoch 111 : Train loss 4.071049913764, validation loss 6.937510967254639\n",
            "Complete prediction MSE : 0.0016468078320728116\n",
            "Epoch 112 : Train loss 4.070276308339089, validation loss 7.139115810394287\n",
            "Complete prediction MSE : 0.001616921910849904\n",
            "Epoch 113 : Train loss 4.056769830174744, validation loss 7.13315486907959\n",
            "Complete prediction MSE : 0.0015722737273698335\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 3\n",
            "Epoch 1 : Train loss 36.02375230751932, validation loss 13.252654075622559\n",
            "Complete prediction MSE : 0.002940318303816293\n",
            "Saving model\n",
            "Epoch 2 : Train loss 22.7013633903116, validation loss 13.343805313110352\n",
            "Complete prediction MSE : 0.0030576482478880487\n",
            "Epoch 3 : Train loss 12.2604412548244, validation loss 10.706064224243164\n",
            "Complete prediction MSE : 0.002894429068790835\n",
            "Saving model\n",
            "Epoch 4 : Train loss 16.121454525738955, validation loss 11.11109733581543\n",
            "Complete prediction MSE : 0.0029748833042568877\n",
            "Epoch 5 : Train loss 10.968710623681545, validation loss 10.128052711486816\n",
            "Complete prediction MSE : 0.002950730761169724\n",
            "Epoch 6 : Train loss 9.686057146638632, validation loss 9.041677474975586\n",
            "Complete prediction MSE : 0.0028106081638749206\n",
            "Saving model\n",
            "Epoch 7 : Train loss 39.2975105419755, validation loss 15.90626049041748\n",
            "Complete prediction MSE : 0.0027519775334218515\n",
            "Saving model\n",
            "Epoch 8 : Train loss 14.434932483360171, validation loss 13.548381805419922\n",
            "Complete prediction MSE : 0.002885708762749474\n",
            "Epoch 9 : Train loss 12.60533950664103, validation loss 12.332088470458984\n",
            "Complete prediction MSE : 0.0026541311614908833\n",
            "Saving model\n",
            "Epoch 10 : Train loss 11.27970282919705, validation loss 11.255576133728027\n",
            "Complete prediction MSE : 0.0024984438321464064\n",
            "Saving model\n",
            "Epoch 11 : Train loss 10.15635197609663, validation loss 10.727621078491211\n",
            "Complete prediction MSE : 0.002430367159718277\n",
            "Saving model\n",
            "Epoch 12 : Train loss 10.783989802002907, validation loss 10.601712226867676\n",
            "Complete prediction MSE : 0.002474221233828638\n",
            "Epoch 13 : Train loss 9.436440882273018, validation loss 9.309236526489258\n",
            "Complete prediction MSE : 0.002265801631791094\n",
            "Saving model\n",
            "Epoch 14 : Train loss 7.874186956323683, validation loss 9.400634765625\n",
            "Complete prediction MSE : 0.002229565072347693\n",
            "Saving model\n",
            "Epoch 15 : Train loss 22.36683728545904, validation loss 14.373309135437012\n",
            "Complete prediction MSE : 0.0027108858348999375\n",
            "Epoch 16 : Train loss 12.751468973234296, validation loss 11.529277801513672\n",
            "Complete prediction MSE : 0.0026312523781834136\n",
            "Epoch 17 : Train loss 10.066177168861032, validation loss 9.815929412841797\n",
            "Complete prediction MSE : 0.002376702382637124\n",
            "Epoch 18 : Train loss 8.583340865559876, validation loss 8.567269325256348\n",
            "Complete prediction MSE : 0.0022324931994879495\n",
            "Epoch 19 : Train loss 7.6801377376541495, validation loss 8.50662899017334\n",
            "Complete prediction MSE : 0.0021614061282317462\n",
            "Saving model\n",
            "Epoch 20 : Train loss 8.818296086974442, validation loss 8.424657821655273\n",
            "Complete prediction MSE : 0.002151373976967734\n",
            "Saving model\n",
            "Epoch 21 : Train loss 6.824531015008688, validation loss 8.268635749816895\n",
            "Complete prediction MSE : 0.0021718132616291076\n",
            "Epoch 22 : Train loss 7.3359973430633545, validation loss 8.383487701416016\n",
            "Complete prediction MSE : 0.0021736762395903396\n",
            "Epoch 23 : Train loss 7.770116983912885, validation loss 8.628954887390137\n",
            "Complete prediction MSE : 0.0022307406655093604\n",
            "Epoch 24 : Train loss 6.329536105506122, validation loss 7.8738555908203125\n",
            "Complete prediction MSE : 0.00227298659395087\n",
            "Epoch 25 : Train loss 6.136850482784212, validation loss 7.733556270599365\n",
            "Complete prediction MSE : 0.0021504108404583034\n",
            "Saving model\n",
            "Epoch 26 : Train loss 6.088060377165675, validation loss 7.39242696762085\n",
            "Complete prediction MSE : 0.0021003259031096085\n",
            "Saving model\n",
            "Epoch 27 : Train loss 15.264991249889135, validation loss 13.103254318237305\n",
            "Complete prediction MSE : 0.002695618129694603\n",
            "Epoch 28 : Train loss 10.203542238101363, validation loss 11.094268798828125\n",
            "Complete prediction MSE : 0.00206438166281439\n",
            "Saving model\n",
            "Epoch 29 : Train loss 7.955717035569251, validation loss 9.343743324279785\n",
            "Complete prediction MSE : 0.0020164934183774536\n",
            "Saving model\n",
            "Epoch 30 : Train loss 6.836868302896619, validation loss 8.528696060180664\n",
            "Complete prediction MSE : 0.0019751984291447714\n",
            "Saving model\n",
            "Epoch 31 : Train loss 6.261203559115529, validation loss 8.42480754852295\n",
            "Complete prediction MSE : 0.001764116776298331\n",
            "Saving model\n",
            "Epoch 32 : Train loss 5.966906878165901, validation loss 7.980417728424072\n",
            "Complete prediction MSE : 0.0019925110621052578\n",
            "Epoch 33 : Train loss 6.282476890832186, validation loss 7.823859214782715\n",
            "Complete prediction MSE : 0.0018128590586806818\n",
            "Epoch 34 : Train loss 5.719303632155061, validation loss 8.017134666442871\n",
            "Complete prediction MSE : 0.0018987804323091794\n",
            "Epoch 35 : Train loss 5.581027788110077, validation loss 7.887732982635498\n",
            "Complete prediction MSE : 0.0018665611375335187\n",
            "Epoch 36 : Train loss 5.536154817789793, validation loss 7.863020896911621\n",
            "Complete prediction MSE : 0.001945683768226629\n",
            "Epoch 37 : Train loss 9.37582029029727, validation loss 13.970742225646973\n",
            "Complete prediction MSE : 0.002203076233994329\n",
            "Epoch 38 : Train loss 8.120465069077909, validation loss 8.45096492767334\n",
            "Complete prediction MSE : 0.0018084467278518886\n",
            "Epoch 39 : Train loss 5.839102065190673, validation loss 7.967960834503174\n",
            "Complete prediction MSE : 0.0018822398606828624\n",
            "Epoch 40 : Train loss 5.499100444838405, validation loss 7.841890811920166\n",
            "Complete prediction MSE : 0.001956760659662064\n",
            "Epoch 41 : Train loss 5.3901246739551425, validation loss 7.909407138824463\n",
            "Complete prediction MSE : 0.0019213569710270133\n",
            "Epoch 42 : Train loss 5.300099105574191, validation loss 7.821558475494385\n",
            "Complete prediction MSE : 0.0020217055119081447\n",
            "Epoch 43 : Train loss 5.981791668571532, validation loss 8.516484260559082\n",
            "Complete prediction MSE : 0.0018522836287900891\n",
            "Epoch 44 : Train loss 5.26187726482749, validation loss 7.805444717407227\n",
            "Complete prediction MSE : 0.0018178537155482196\n",
            "Epoch 45 : Train loss 5.151634353213012, validation loss 7.778997421264648\n",
            "Complete prediction MSE : 0.00174030322053174\n",
            "Saving model\n",
            "Epoch 46 : Train loss 5.086276385933161, validation loss 7.684935092926025\n",
            "Complete prediction MSE : 0.0018513533583632501\n",
            "Epoch 47 : Train loss 5.036580822430551, validation loss 7.772555351257324\n",
            "Complete prediction MSE : 0.001751274334532186\n",
            "Epoch 48 : Train loss 4.987551991827786, validation loss 7.902878284454346\n",
            "Complete prediction MSE : 0.0017358926670279703\n",
            "Saving model\n",
            "Epoch 49 : Train loss 4.967145918868482, validation loss 8.007709503173828\n",
            "Complete prediction MSE : 0.0017619536397393307\n",
            "Epoch 50 : Train loss 4.917433918453753, validation loss 8.459063529968262\n",
            "Complete prediction MSE : 0.001671716613204058\n",
            "Saving model\n",
            "Epoch 51 : Train loss 4.867063422687352, validation loss 8.131260871887207\n",
            "Complete prediction MSE : 0.0016744273366242678\n",
            "Epoch 52 : Train loss 4.834404441528022, validation loss 8.275969505310059\n",
            "Complete prediction MSE : 0.0016082771314478968\n",
            "Saving model\n",
            "Epoch 53 : Train loss 4.802180751226842, validation loss 8.537388801574707\n",
            "Complete prediction MSE : 0.0017273235272969858\n",
            "Epoch 54 : Train loss 4.787463309243321, validation loss 8.515987396240234\n",
            "Complete prediction MSE : 0.001635734485421107\n",
            "Epoch 55 : Train loss 4.73868687544018, validation loss 8.69291877746582\n",
            "Complete prediction MSE : 0.0015213988371182295\n",
            "Saving model\n",
            "Epoch 56 : Train loss 4.704356295987964, validation loss 8.644739151000977\n",
            "Complete prediction MSE : 0.0015702696430604807\n",
            "Epoch 57 : Train loss 4.6814977787435055, validation loss 8.780771255493164\n",
            "Complete prediction MSE : 0.0015469955903838724\n",
            "Epoch 58 : Train loss 4.660423435270786, validation loss 8.601221084594727\n",
            "Complete prediction MSE : 0.00161910659976899\n",
            "Epoch 59 : Train loss 4.640303997322917, validation loss 8.740038871765137\n",
            "Complete prediction MSE : 0.0015911061667056804\n",
            "Epoch 60 : Train loss 4.605571947991848, validation loss 8.81693172454834\n",
            "Complete prediction MSE : 0.001547116274399858\n",
            "Epoch 61 : Train loss 4.585478793364018, validation loss 8.62033748626709\n",
            "Complete prediction MSE : 0.0015747635696890167\n",
            "Epoch 62 : Train loss 4.555105071514845, validation loss 8.727441787719727\n",
            "Complete prediction MSE : 0.001538442799954061\n",
            "Epoch 63 : Train loss 4.544017589185387, validation loss 8.433181762695312\n",
            "Complete prediction MSE : 0.0015014253937655681\n",
            "Saving model\n",
            "Epoch 64 : Train loss 4.527410126291215, validation loss 8.717870712280273\n",
            "Complete prediction MSE : 0.0014959587153037148\n",
            "Saving model\n",
            "Epoch 65 : Train loss 4.513390726875514, validation loss 8.711614608764648\n",
            "Complete prediction MSE : 0.0015728960583931571\n",
            "Epoch 66 : Train loss 4.488760031294078, validation loss 8.706677436828613\n",
            "Complete prediction MSE : 0.0015105438920413156\n",
            "Epoch 67 : Train loss 4.472711306530982, validation loss 8.858381271362305\n",
            "Complete prediction MSE : 0.0016270723842877698\n",
            "Epoch 68 : Train loss 4.4543523457832634, validation loss 8.750370025634766\n",
            "Complete prediction MSE : 0.001591380346080244\n",
            "Epoch 69 : Train loss 4.4525957982987165, validation loss 8.917595863342285\n",
            "Complete prediction MSE : 0.0014835122245762397\n",
            "Saving model\n",
            "Epoch 70 : Train loss 4.439303322229534, validation loss 9.14521312713623\n",
            "Complete prediction MSE : 0.0015757811859643406\n",
            "Epoch 71 : Train loss 4.41727905953303, validation loss 8.592361450195312\n",
            "Complete prediction MSE : 0.0015110581655977985\n",
            "Epoch 72 : Train loss 4.386816272512078, validation loss 8.68971061706543\n",
            "Complete prediction MSE : 0.0015414780351647645\n",
            "Epoch 73 : Train loss 4.383351797703654, validation loss 8.79633617401123\n",
            "Complete prediction MSE : 0.0015307947005599966\n",
            "Epoch 74 : Train loss 4.362208046019077, validation loss 8.79002571105957\n",
            "Complete prediction MSE : 0.001465202200284787\n",
            "Saving model\n",
            "Epoch 75 : Train loss 4.346421002410352, validation loss 8.427576065063477\n",
            "Complete prediction MSE : 0.0014527773277815824\n",
            "Saving model\n",
            "Epoch 76 : Train loss 4.336168939247727, validation loss 8.78019905090332\n",
            "Complete prediction MSE : 0.001511222511849809\n",
            "Epoch 77 : Train loss 4.324538659770042, validation loss 8.653342247009277\n",
            "Complete prediction MSE : 0.001473602015089593\n",
            "Epoch 78 : Train loss 4.300842416938394, validation loss 8.647549629211426\n",
            "Complete prediction MSE : 0.0015053627643563231\n",
            "Epoch 79 : Train loss 4.300918342079967, validation loss 8.703059196472168\n",
            "Complete prediction MSE : 0.0015387616217909228\n",
            "Epoch 80 : Train loss 4.277665168978274, validation loss 8.69991397857666\n",
            "Complete prediction MSE : 0.0013594099278792316\n",
            "Saving model\n",
            "Epoch 81 : Train loss 4.279070478398353, validation loss 8.804780006408691\n",
            "Complete prediction MSE : 0.0014156133965773188\n",
            "Epoch 82 : Train loss 4.262137939222157, validation loss 8.660932540893555\n",
            "Complete prediction MSE : 0.0013738593085151872\n",
            "Epoch 83 : Train loss 4.2448226721026, validation loss 8.848482131958008\n",
            "Complete prediction MSE : 0.0013548706250097469\n",
            "Saving model\n",
            "Epoch 84 : Train loss 4.235584720503539, validation loss 9.073447227478027\n",
            "Complete prediction MSE : 0.0014726807494728506\n",
            "Epoch 85 : Train loss 4.221451137214899, validation loss 8.883867263793945\n",
            "Complete prediction MSE : 0.00146702617960588\n",
            "Epoch 86 : Train loss 4.215732948388904, validation loss 8.7880277633667\n",
            "Complete prediction MSE : 0.0014383011281290043\n",
            "Epoch 87 : Train loss 4.213311171159148, validation loss 8.830976486206055\n",
            "Complete prediction MSE : 0.0014639929455779177\n",
            "Epoch 88 : Train loss 4.196490950882435, validation loss 8.775215148925781\n",
            "Complete prediction MSE : 0.0014429562162706659\n",
            "Epoch 89 : Train loss 4.193335961550474, validation loss 8.8773193359375\n",
            "Complete prediction MSE : 0.0013834441658634054\n",
            "Epoch 90 : Train loss 4.185267524793744, validation loss 8.9876708984375\n",
            "Complete prediction MSE : 0.0014353563156237444\n",
            "Epoch 91 : Train loss 4.176629940979183, validation loss 8.59758186340332\n",
            "Complete prediction MSE : 0.0013587092087349812\n",
            "Epoch 92 : Train loss 4.163101968355477, validation loss 8.81990909576416\n",
            "Complete prediction MSE : 0.001408468536780071\n",
            "Epoch 93 : Train loss 4.154944283422083, validation loss 8.687949180603027\n",
            "Complete prediction MSE : 0.0013880671589567139\n",
            "Epoch 94 : Train loss 4.1637155073694885, validation loss 9.03068733215332\n",
            "Complete prediction MSE : 0.0014793747807685484\n",
            "Epoch 95 : Train loss 4.148523161653429, validation loss 8.343918800354004\n",
            "Complete prediction MSE : 0.0013149037454056906\n",
            "Saving model\n",
            "Epoch 96 : Train loss 4.13237392809242, validation loss 8.45543098449707\n",
            "Complete prediction MSE : 0.0013062716915014489\n",
            "Saving model\n",
            "Epoch 97 : Train loss 4.1322701489552855, validation loss 8.762704849243164\n",
            "Complete prediction MSE : 0.0013414945832873216\n",
            "Epoch 98 : Train loss 4.120784185826778, validation loss 8.470544815063477\n",
            "Complete prediction MSE : 0.001355784500295171\n",
            "Epoch 99 : Train loss 4.107758550904691, validation loss 8.891990661621094\n",
            "Complete prediction MSE : 0.0013859961561887841\n",
            "Epoch 100 : Train loss 4.100408531725407, validation loss 8.748006820678711\n",
            "Complete prediction MSE : 0.0013203672247316075\n",
            "Epoch 101 : Train loss 4.086212961003184, validation loss 8.576475143432617\n",
            "Complete prediction MSE : 0.001255711685821848\n",
            "Saving model\n",
            "Epoch 102 : Train loss 4.0799954305402935, validation loss 8.903236389160156\n",
            "Complete prediction MSE : 0.0013232570548180598\n",
            "Epoch 103 : Train loss 4.077984839212149, validation loss 8.82322883605957\n",
            "Complete prediction MSE : 0.001269980010860405\n",
            "Epoch 104 : Train loss 4.065851312596351, validation loss 8.545284271240234\n",
            "Complete prediction MSE : 0.0011735022608405181\n",
            "Saving model\n",
            "Epoch 105 : Train loss 4.0661706808023155, validation loss 8.696850776672363\n",
            "Complete prediction MSE : 0.0012466672332764777\n",
            "Epoch 106 : Train loss 4.061631835531443, validation loss 8.330080032348633\n",
            "Complete prediction MSE : 0.001223834920382678\n",
            "Epoch 107 : Train loss 4.058078253176063, validation loss 8.328631401062012\n",
            "Complete prediction MSE : 0.0012600651279878446\n",
            "Epoch 108 : Train loss 4.037016808986664, validation loss 8.6141939163208\n",
            "Complete prediction MSE : 0.0012415216582538718\n",
            "Epoch 109 : Train loss 4.040893590543419, validation loss 8.558582305908203\n",
            "Complete prediction MSE : 0.0012535152181781654\n",
            "Epoch 110 : Train loss 4.026923265773803, validation loss 8.550162315368652\n",
            "Complete prediction MSE : 0.0012294907870445595\n",
            "Epoch 111 : Train loss 4.014382336288691, validation loss 8.09453296661377\n",
            "Complete prediction MSE : 0.0012440465723186013\n",
            "Epoch 112 : Train loss 4.0056631355546415, validation loss 8.231527328491211\n",
            "Complete prediction MSE : 0.0012078835057295451\n",
            "Epoch 113 : Train loss 4.01291422965005, validation loss 8.329090118408203\n",
            "Complete prediction MSE : 0.0012371633804180574\n",
            "Epoch 114 : Train loss 3.9896758743561804, validation loss 8.410179138183594\n",
            "Complete prediction MSE : 0.0011911138691755412\n",
            "Epoch 115 : Train loss 3.9906860780902207, validation loss 8.215518951416016\n",
            "Complete prediction MSE : 0.0012718769581553631\n",
            "Epoch 116 : Train loss 3.9848103770054877, validation loss 8.288683891296387\n",
            "Complete prediction MSE : 0.0012153054551612018\n",
            "Epoch 117 : Train loss 3.9810114302672446, validation loss 8.03344440460205\n",
            "Complete prediction MSE : 0.0011900613920090028\n",
            "Epoch 118 : Train loss 3.9701682599261403, validation loss 8.247076988220215\n",
            "Complete prediction MSE : 0.001214643204273579\n",
            "Epoch 119 : Train loss 3.9644434531219304, validation loss 8.204914093017578\n",
            "Complete prediction MSE : 0.0012416970973569907\n",
            "Epoch 120 : Train loss 3.965033170301467, validation loss 8.5437650680542\n",
            "Complete prediction MSE : 0.0012362008893699826\n",
            "Epoch 121 : Train loss 3.957429654430598, validation loss 8.287989616394043\n",
            "Complete prediction MSE : 0.0011942260469477801\n",
            "Epoch 122 : Train loss 3.9354387088678777, validation loss 8.299646377563477\n",
            "Complete prediction MSE : 0.001285687139090294\n",
            "Epoch 123 : Train loss 3.945311767514795, validation loss 8.347888946533203\n",
            "Complete prediction MSE : 0.001267934856469877\n",
            "Epoch 124 : Train loss 3.945836153347045, validation loss 8.543196678161621\n",
            "Complete prediction MSE : 0.0012436630976006343\n",
            "Epoch 125 : Train loss 3.9284459580667317, validation loss 8.411574363708496\n",
            "Complete prediction MSE : 0.001248322045423368\n",
            "Epoch 126 : Train loss 3.9232518863864243, validation loss 8.17540168762207\n",
            "Complete prediction MSE : 0.0012504634675687438\n",
            "Epoch 127 : Train loss 3.91924719652161, validation loss 8.295334815979004\n",
            "Complete prediction MSE : 0.0012884361351992758\n",
            "Epoch 128 : Train loss 3.92251746263355, validation loss 8.285929679870605\n",
            "Complete prediction MSE : 0.0012522846399073665\n",
            "Epoch 129 : Train loss 3.902230889070779, validation loss 8.234312057495117\n",
            "Complete prediction MSE : 0.0012720082400046334\n",
            "Epoch 130 : Train loss 3.8977977251634, validation loss 8.497454643249512\n",
            "Complete prediction MSE : 0.0012672983425523498\n",
            "Epoch 131 : Train loss 3.900169880129397, validation loss 8.336064338684082\n",
            "Complete prediction MSE : 0.001191882771561534\n",
            "Epoch 132 : Train loss 3.8914325633086264, validation loss 8.315711975097656\n",
            "Complete prediction MSE : 0.0012066973040149554\n",
            "Epoch 133 : Train loss 3.8944150442257524, validation loss 8.608423233032227\n",
            "Complete prediction MSE : 0.0013432892213702935\n",
            "Epoch 134 : Train loss 3.881548603065312, validation loss 8.614572525024414\n",
            "Complete prediction MSE : 0.0012107800357076262\n",
            "Epoch 135 : Train loss 3.8746937550604343, validation loss 8.39870548248291\n",
            "Complete prediction MSE : 0.0011863872661565526\n",
            "Epoch 136 : Train loss 3.867048959713429, validation loss 8.191242218017578\n",
            "Complete prediction MSE : 0.0013168686812054281\n",
            "Epoch 137 : Train loss 3.862908928655088, validation loss 8.449533462524414\n",
            "Complete prediction MSE : 0.001242291121079253\n",
            "Epoch 138 : Train loss 3.860292810946703, validation loss 8.435742378234863\n",
            "Complete prediction MSE : 0.0012417283161583281\n",
            "Epoch 139 : Train loss 3.857073781080544, validation loss 8.25717830657959\n",
            "Complete prediction MSE : 0.0013588611951000046\n",
            "Epoch 140 : Train loss 3.8546092035248876, validation loss 8.534899711608887\n",
            "Complete prediction MSE : 0.0012489150121160416\n",
            "Epoch 141 : Train loss 3.8553787018172443, validation loss 8.438226699829102\n",
            "Complete prediction MSE : 0.001345026929623862\n",
            "Epoch 142 : Train loss 3.853782422374934, validation loss 8.125473976135254\n",
            "Complete prediction MSE : 0.0012969388053019667\n",
            "Epoch 143 : Train loss 3.8406484532169998, validation loss 8.665903091430664\n",
            "Complete prediction MSE : 0.001324948801220305\n",
            "Epoch 144 : Train loss 3.8434127317741513, validation loss 8.4506254196167\n",
            "Complete prediction MSE : 0.0012218612400625908\n",
            "Epoch 145 : Train loss 3.8326845108531415, validation loss 8.570289611816406\n",
            "Complete prediction MSE : 0.0013372169582094593\n",
            "Epoch 146 : Train loss 3.830918066203594, validation loss 8.590204238891602\n",
            "Complete prediction MSE : 0.0012754959042549042\n",
            "Epoch 147 : Train loss 3.82531301304698, validation loss 8.75899887084961\n",
            "Complete prediction MSE : 0.001277111551164585\n",
            "Epoch 148 : Train loss 3.8220460154116154, validation loss 8.770467758178711\n",
            "Complete prediction MSE : 0.0013696997380986606\n",
            "Epoch 149 : Train loss 3.807245329488069, validation loss 8.698334693908691\n",
            "Complete prediction MSE : 0.0011780245227930768\n",
            "Epoch 150 : Train loss 3.818615099415183, validation loss 8.278327941894531\n",
            "Complete prediction MSE : 0.0014039162555949112\n",
            "Epoch 151 : Train loss 3.804761055391282, validation loss 8.438886642456055\n",
            "Complete prediction MSE : 0.001369063933094817\n",
            "Epoch 152 : Train loss 3.805234800092876, validation loss 8.750469207763672\n",
            "Complete prediction MSE : 0.0013224203628733491\n",
            "Epoch 153 : Train loss 3.811617999803275, validation loss 8.59697151184082\n",
            "Complete prediction MSE : 0.0013573584275261253\n",
            "Epoch 154 : Train loss 3.8136671064421535, validation loss 8.500227928161621\n",
            "Complete prediction MSE : 0.0012831168038422134\n",
            "Early stopping due to no more improvement and/or unstable training\n",
            "Training model with seed 4\n",
            "Epoch 1 : Train loss 35.81890603154898, validation loss 15.352950096130371\n",
            "Complete prediction MSE : 0.0034674668377078985\n",
            "Saving model\n",
            "Epoch 2 : Train loss 14.259154118597507, validation loss 10.377278327941895\n",
            "Complete prediction MSE : 0.002692552965713875\n",
            "Saving model\n",
            "Epoch 3 : Train loss 13.287979628890753, validation loss 11.476629257202148\n",
            "Complete prediction MSE : 0.002760397830850478\n",
            "Epoch 4 : Train loss 16.577123330906034, validation loss 15.273843765258789\n",
            "Complete prediction MSE : 0.0027775475141819197\n",
            "Epoch 5 : Train loss 12.140698429197073, validation loss 11.397887229919434\n",
            "Complete prediction MSE : 0.002534592198035879\n",
            "Saving model\n",
            "Epoch 6 : Train loss 13.889195466414094, validation loss 12.20529842376709\n",
            "Complete prediction MSE : 0.0027624304889049003\n",
            "Epoch 7 : Train loss 10.302075956016779, validation loss 9.05270004272461\n",
            "Complete prediction MSE : 0.0027430853280030697\n",
            "Epoch 8 : Train loss 27.734051366336644, validation loss 70.91297912597656\n",
            "Complete prediction MSE : 0.009997771375308693\n",
            "Epoch 9 : Train loss 19.79262576624751, validation loss 13.875308990478516\n",
            "Complete prediction MSE : 0.0028733488402539367\n",
            "Epoch 10 : Train loss 13.723770232871175, validation loss 12.087273597717285\n",
            "Complete prediction MSE : 0.00266567401828381\n",
            "Epoch 11 : Train loss 11.981897240504622, validation loss 11.027058601379395\n",
            "Complete prediction MSE : 0.0024216670994552767\n",
            "Saving model\n",
            "Epoch 12 : Train loss 10.80325104855001, validation loss 10.614164352416992\n",
            "Complete prediction MSE : 0.0023841458599230935\n",
            "Saving model\n",
            "Epoch 13 : Train loss 9.866477631032467, validation loss 9.755942344665527\n",
            "Complete prediction MSE : 0.00218570811328364\n",
            "Saving model\n",
            "Epoch 14 : Train loss 9.183281029574573, validation loss 9.666505813598633\n",
            "Complete prediction MSE : 0.0021265554477606966\n",
            "Saving model\n",
            "Epoch 15 : Train loss 8.47637408785522, validation loss 9.29759693145752\n",
            "Complete prediction MSE : 0.0021655927869988997\n",
            "Epoch 16 : Train loss 9.415663596242666, validation loss 8.568108558654785\n",
            "Complete prediction MSE : 0.002136422593559283\n",
            "Epoch 17 : Train loss 7.473934844136238, validation loss 8.878725051879883\n",
            "Complete prediction MSE : 0.0020207425612776453\n",
            "Saving model\n",
            "Epoch 18 : Train loss 16.124058236368, validation loss 10.607301712036133\n",
            "Complete prediction MSE : 0.002385714904256785\n",
            "Epoch 19 : Train loss 8.75822572503239, validation loss 9.013540267944336\n",
            "Complete prediction MSE : 0.002062158596476227\n",
            "Epoch 20 : Train loss 7.486691831611097, validation loss 8.875696182250977\n",
            "Complete prediction MSE : 0.0020864094912350145\n",
            "Epoch 21 : Train loss 9.92908126488328, validation loss 9.131688117980957\n",
            "Complete prediction MSE : 0.00196682089322956\n",
            "Saving model\n",
            "Epoch 22 : Train loss 7.254745191894472, validation loss 8.61098575592041\n",
            "Complete prediction MSE : 0.0019922437197934244\n",
            "Epoch 23 : Train loss 6.656684006564319, validation loss 8.610480308532715\n",
            "Complete prediction MSE : 0.002071195466515344\n",
            "Epoch 24 : Train loss 9.022046452388167, validation loss 11.214838027954102\n",
            "Complete prediction MSE : 0.0025681079786112394\n",
            "Epoch 25 : Train loss 7.7573104640468955, validation loss 8.802306175231934\n",
            "Complete prediction MSE : 0.0019011596718344229\n",
            "Saving model\n",
            "Epoch 26 : Train loss 6.537137215025723, validation loss 8.66728687286377\n",
            "Complete prediction MSE : 0.0018043366700571549\n",
            "Saving model\n",
            "Epoch 27 : Train loss 6.221860860474408, validation loss 8.15992259979248\n",
            "Complete prediction MSE : 0.0020020812299655954\n",
            "Epoch 28 : Train loss 6.087742797099054, validation loss 7.933171272277832\n",
            "Complete prediction MSE : 0.002072128664196792\n",
            "Epoch 29 : Train loss 10.555063380859792, validation loss 13.751465797424316\n",
            "Complete prediction MSE : 0.0033393604841646662\n",
            "Epoch 30 : Train loss 8.881299840286374, validation loss 8.737800598144531\n",
            "Complete prediction MSE : 0.0019997776295763714\n",
            "Epoch 31 : Train loss 6.35711953882128, validation loss 8.128890991210938\n",
            "Complete prediction MSE : 0.0018001487142462974\n",
            "Saving model\n",
            "Epoch 32 : Train loss 5.992462394759059, validation loss 8.223316192626953\n",
            "Complete prediction MSE : 0.0017302026369587485\n",
            "Saving model\n",
            "Epoch 33 : Train loss 5.864519528113306, validation loss 8.280497550964355\n",
            "Complete prediction MSE : 0.0017099873571573205\n",
            "Saving model\n",
            "Epoch 34 : Train loss 5.741529252380133, validation loss 8.702207565307617\n",
            "Complete prediction MSE : 0.001750911323247462\n",
            "Epoch 35 : Train loss 6.977573191747069, validation loss 9.745530128479004\n",
            "Complete prediction MSE : 0.0018274258731540596\n",
            "Epoch 36 : Train loss 5.926310584880412, validation loss 8.222334861755371\n",
            "Complete prediction MSE : 0.0017348859044317843\n",
            "Epoch 37 : Train loss 5.521035665646195, validation loss 8.526246070861816\n",
            "Complete prediction MSE : 0.001770083257102317\n",
            "Epoch 38 : Train loss 5.473661472089589, validation loss 8.421700477600098\n",
            "Complete prediction MSE : 0.0017332522185672951\n",
            "Epoch 39 : Train loss 5.4052127143368125, validation loss 8.742888450622559\n",
            "Complete prediction MSE : 0.0017411716990494062\n",
            "Epoch 40 : Train loss 5.3565032333135605, validation loss 8.770096778869629\n",
            "Complete prediction MSE : 0.0016565041700069938\n",
            "Saving model\n",
            "Epoch 41 : Train loss 5.284302796237171, validation loss 8.497536659240723\n",
            "Complete prediction MSE : 0.0016973650490084329\n",
            "Epoch 42 : Train loss 5.248866483569145, validation loss 8.375216484069824\n",
            "Complete prediction MSE : 0.0016443158677076613\n",
            "Saving model\n",
            "Epoch 43 : Train loss 5.17984436172992, validation loss 8.556047439575195\n",
            "Complete prediction MSE : 0.001614759806072853\n",
            "Saving model\n",
            "Epoch 44 : Train loss 5.147333892062306, validation loss 8.223679542541504\n",
            "Complete prediction MSE : 0.001638468121015736\n",
            "Epoch 45 : Train loss 5.092425526119769, validation loss 8.241482734680176\n",
            "Complete prediction MSE : 0.0015598783466936365\n",
            "Saving model\n",
            "Epoch 46 : Train loss 5.056063867174089, validation loss 8.128175735473633\n",
            "Complete prediction MSE : 0.0018271261985746674\n",
            "Epoch 47 : Train loss 5.029880343005061, validation loss 8.229569435119629\n",
            "Complete prediction MSE : 0.001646122160300404\n",
            "Epoch 48 : Train loss 4.992587984539568, validation loss 8.085091590881348\n",
            "Complete prediction MSE : 0.00163915742355097\n",
            "Epoch 49 : Train loss 4.951620627194643, validation loss 7.8711371421813965\n",
            "Complete prediction MSE : 0.0016212496475485033\n",
            "Epoch 50 : Train loss 4.913932530209422, validation loss 7.7443318367004395\n",
            "Complete prediction MSE : 0.0015045939414613893\n",
            "Saving model\n",
            "Epoch 51 : Train loss 4.886046586558223, validation loss 8.06479263305664\n",
            "Complete prediction MSE : 0.001604347783256158\n",
            "Epoch 52 : Train loss 4.861841126345098, validation loss 7.860396862030029\n",
            "Complete prediction MSE : 0.0015775880652283884\n",
            "Epoch 53 : Train loss 4.821845433674753, validation loss 7.967749118804932\n",
            "Complete prediction MSE : 0.0015356419473974918\n",
            "Epoch 54 : Train loss 4.802535128779709, validation loss 8.110304832458496\n",
            "Complete prediction MSE : 0.0014401754668000163\n",
            "Saving model\n",
            "Epoch 55 : Train loss 4.776321802288294, validation loss 8.157266616821289\n",
            "Complete prediction MSE : 0.0015193148019823062\n",
            "Epoch 56 : Train loss 4.744441272690892, validation loss 8.179433822631836\n",
            "Complete prediction MSE : 0.0014604000082057238\n",
            "Epoch 57 : Train loss 4.7281663697212934, validation loss 8.377449035644531\n",
            "Complete prediction MSE : 0.0014361280995376935\n",
            "Saving model\n",
            "Epoch 58 : Train loss 4.688719509169459, validation loss 8.215073585510254\n",
            "Complete prediction MSE : 0.0015590004197560676\n",
            "Epoch 59 : Train loss 4.669244522228837, validation loss 8.43033504486084\n",
            "Complete prediction MSE : 0.0014387671652613858\n",
            "Epoch 60 : Train loss 4.654736328404397, validation loss 8.331893920898438\n",
            "Complete prediction MSE : 0.0014894883699377627\n",
            "Epoch 61 : Train loss 4.639716116711497, validation loss 8.138060569763184\n",
            "Complete prediction MSE : 0.0014859732526681959\n",
            "Epoch 62 : Train loss 4.610583890229464, validation loss 8.37432861328125\n",
            "Complete prediction MSE : 0.001424492514631288\n",
            "Saving model\n",
            "Epoch 63 : Train loss 4.604533609934151, validation loss 8.592964172363281\n",
            "Complete prediction MSE : 0.0014623970467234238\n",
            "Epoch 64 : Train loss 4.587939421646297, validation loss 8.123733520507812\n",
            "Complete prediction MSE : 0.0014182159251755278\n",
            "Saving model\n",
            "Epoch 65 : Train loss 4.563198545947671, validation loss 8.20944595336914\n",
            "Complete prediction MSE : 0.001509015247656064\n",
            "Epoch 66 : Train loss 4.549674634821713, validation loss 8.758102416992188\n",
            "Complete prediction MSE : 0.0014508738888809097\n",
            "Epoch 67 : Train loss 4.523635047953576, validation loss 8.201767921447754\n",
            "Complete prediction MSE : 0.0014434149617468793\n",
            "Epoch 68 : Train loss 4.522008960135281, validation loss 8.272228240966797\n",
            "Complete prediction MSE : 0.0014362392274212953\n",
            "Epoch 69 : Train loss 4.50229668058455, validation loss 8.532883644104004\n",
            "Complete prediction MSE : 0.001607674978031338\n",
            "Epoch 70 : Train loss 4.496420665178448, validation loss 8.758657455444336\n",
            "Complete prediction MSE : 0.001464715602998661\n",
            "Epoch 71 : Train loss 4.480148442089558, validation loss 8.745373725891113\n",
            "Complete prediction MSE : 0.0016005804446040104\n",
            "Epoch 72 : Train loss 4.459694281220436, validation loss 8.523002624511719\n",
            "Complete prediction MSE : 0.0016404869233473405\n",
            "Epoch 73 : Train loss 4.451631112024188, validation loss 9.081440925598145\n",
            "Complete prediction MSE : 0.0014820813777983977\n",
            "Epoch 74 : Train loss 4.428768530022353, validation loss 8.900978088378906\n",
            "Complete prediction MSE : 0.0016023731182629986\n",
            "Epoch 75 : Train loss 4.406852629967034, validation loss 8.896933555603027\n",
            "Complete prediction MSE : 0.0014243704875625375\n",
            "Epoch 76 : Train loss 4.403729513287544, validation loss 8.566527366638184\n",
            "Complete prediction MSE : 0.0014237152132436438\n",
            "Epoch 77 : Train loss 4.386069575324655, validation loss 9.019770622253418\n",
            "Complete prediction MSE : 0.0014782980352849588\n",
            "Epoch 78 : Train loss 4.370415166951716, validation loss 8.398087501525879\n",
            "Complete prediction MSE : 0.0014637061146084553\n",
            "Epoch 79 : Train loss 4.355644766706973, validation loss 8.805335998535156\n",
            "Complete prediction MSE : 0.001443759142655611\n",
            "Epoch 80 : Train loss 4.353616241365671, validation loss 8.858588218688965\n",
            "Complete prediction MSE : 0.0014459766880499548\n",
            "Epoch 81 : Train loss 4.346366764046252, validation loss 9.281521797180176\n",
            "Complete prediction MSE : 0.0014350145496592776\n",
            "Epoch 82 : Train loss 4.329566431231797, validation loss 8.816758155822754\n",
            "Complete prediction MSE : 0.0013407483560747596\n",
            "Saving model\n",
            "Epoch 83 : Train loss 4.320049862843007, validation loss 8.612424850463867\n",
            "Complete prediction MSE : 0.001331343384061074\n",
            "Saving model\n",
            "Epoch 84 : Train loss 4.302806606050581, validation loss 9.028149604797363\n",
            "Complete prediction MSE : 0.001367068268449553\n",
            "Epoch 85 : Train loss 4.286483030766249, validation loss 8.637794494628906\n",
            "Complete prediction MSE : 0.0013166985190436672\n",
            "Saving model\n",
            "Epoch 86 : Train loss 4.280918814241886, validation loss 8.895391464233398\n",
            "Complete prediction MSE : 0.0012925291079527188\n",
            "Saving model\n",
            "Epoch 87 : Train loss 4.267577200196683, validation loss 8.971109390258789\n",
            "Complete prediction MSE : 0.001331976485552675\n",
            "Epoch 88 : Train loss 4.2594116809777915, validation loss 8.51693344116211\n",
            "Complete prediction MSE : 0.0012613284989897553\n",
            "Saving model\n",
            "Epoch 89 : Train loss 4.252662978600711, validation loss 8.277993202209473\n",
            "Complete prediction MSE : 0.0013122575844538296\n",
            "Epoch 90 : Train loss 4.2419475563801825, validation loss 7.9845123291015625\n",
            "Complete prediction MSE : 0.0013195301707772179\n",
            "Epoch 91 : Train loss 4.233658326789737, validation loss 8.11897087097168\n",
            "Complete prediction MSE : 0.0012358997505696634\n",
            "Saving model\n",
            "Epoch 92 : Train loss 4.217248465400189, validation loss 8.258688926696777\n",
            "Complete prediction MSE : 0.0012284509527253793\n",
            "Saving model\n",
            "Epoch 93 : Train loss 4.210298148915172, validation loss 8.127747535705566\n",
            "Complete prediction MSE : 0.0013253524052936263\n",
            "Epoch 94 : Train loss 4.203588297124952, validation loss 8.138350486755371\n",
            "Complete prediction MSE : 0.0011839918925720938\n",
            "Saving model\n",
            "Epoch 95 : Train loss 4.206457763444632, validation loss 7.802774429321289\n",
            "Complete prediction MSE : 0.0012993866044732885\n",
            "Epoch 96 : Train loss 4.187087294179946, validation loss 8.020931243896484\n",
            "Complete prediction MSE : 0.0014076975271868476\n",
            "Epoch 97 : Train loss 4.182089930400252, validation loss 8.532496452331543\n",
            "Complete prediction MSE : 0.001344891810782181\n",
            "Epoch 98 : Train loss 4.1740962392650545, validation loss 8.295838356018066\n",
            "Complete prediction MSE : 0.0013138298277061335\n",
            "Epoch 99 : Train loss 4.162941006012261, validation loss 8.037701606750488\n",
            "Complete prediction MSE : 0.0013706077877466652\n",
            "Epoch 100 : Train loss 4.162039942573756, validation loss 8.052546501159668\n",
            "Complete prediction MSE : 0.0012847475679623915\n",
            "Epoch 101 : Train loss 4.15250633796677, validation loss 8.008520126342773\n",
            "Complete prediction MSE : 0.0013061668594022606\n",
            "Epoch 102 : Train loss 4.140380980446935, validation loss 8.110618591308594\n",
            "Complete prediction MSE : 0.0012910779922631899\n",
            "Epoch 103 : Train loss 4.138608772773296, validation loss 8.026862144470215\n",
            "Complete prediction MSE : 0.0012344013749985053\n",
            "Epoch 104 : Train loss 4.1297712326049805, validation loss 8.052599906921387\n",
            "Complete prediction MSE : 0.0013412708742640367\n",
            "Epoch 105 : Train loss 4.1234406172297895, validation loss 7.768178462982178\n",
            "Complete prediction MSE : 0.0012251438827375713\n",
            "Epoch 106 : Train loss 4.110788378864527, validation loss 7.727405071258545\n",
            "Complete prediction MSE : 0.0012088055674667\n",
            "Epoch 107 : Train loss 4.113467317540199, validation loss 7.677894115447998\n",
            "Complete prediction MSE : 0.0011715601590401937\n",
            "Saving model\n",
            "Epoch 108 : Train loss 4.103428727015853, validation loss 7.874216556549072\n",
            "Complete prediction MSE : 0.001234629328066461\n",
            "Epoch 109 : Train loss 4.104141832794994, validation loss 7.794674396514893\n",
            "Complete prediction MSE : 0.0011784768890303243\n",
            "Epoch 110 : Train loss 4.086236864794046, validation loss 8.465285301208496\n",
            "Complete prediction MSE : 0.001112572651355369\n",
            "Saving model\n",
            "Epoch 111 : Train loss 4.074783922173083, validation loss 7.863418102264404\n",
            "Complete prediction MSE : 0.0011597539178608734\n",
            "Epoch 112 : Train loss 4.072223263327032, validation loss 7.8588738441467285\n",
            "Complete prediction MSE : 0.0011892828015100053\n",
            "Epoch 113 : Train loss 4.067047175485641, validation loss 7.844731330871582\n",
            "Complete prediction MSE : 0.001118106841635808\n",
            "Epoch 114 : Train loss 4.059900875668973, validation loss 7.840233325958252\n",
            "Complete prediction MSE : 0.001079606666259588\n",
            "Saving model\n",
            "Epoch 115 : Train loss 4.058456408325583, validation loss 7.8779683113098145\n",
            "Complete prediction MSE : 0.001101357725125601\n",
            "Epoch 116 : Train loss 4.043109066318721, validation loss 8.156381607055664\n",
            "Complete prediction MSE : 0.0011583427059596893\n",
            "Epoch 117 : Train loss 4.038373831659555, validation loss 7.899949550628662\n",
            "Complete prediction MSE : 0.0011297334690812102\n",
            "Epoch 118 : Train loss 4.036337272729725, validation loss 8.19310188293457\n",
            "Complete prediction MSE : 0.0010740832959612817\n",
            "Saving model\n",
            "Epoch 119 : Train loss 4.0181190287694335, validation loss 8.08514404296875\n",
            "Complete prediction MSE : 0.001105549974190554\n",
            "Epoch 120 : Train loss 4.022345572244376, validation loss 8.148568153381348\n",
            "Complete prediction MSE : 0.001103457718987823\n",
            "Epoch 121 : Train loss 4.011041488964111, validation loss 8.342484474182129\n",
            "Complete prediction MSE : 0.0010162148050520314\n",
            "Saving model\n",
            "Epoch 122 : Train loss 4.000972941052169, validation loss 8.083093643188477\n",
            "Complete prediction MSE : 0.0011206416153198642\n",
            "Epoch 123 : Train loss 4.00859145168215, validation loss 8.193263053894043\n",
            "Complete prediction MSE : 0.0010978223232618156\n",
            "Epoch 124 : Train loss 4.001044641714543, validation loss 8.213674545288086\n",
            "Complete prediction MSE : 0.0010609890050255451\n",
            "Epoch 125 : Train loss 3.9777278332039714, validation loss 8.40868854522705\n",
            "Complete prediction MSE : 0.0010502884924726607\n",
            "Epoch 126 : Train loss 3.976578018628061, validation loss 8.195710182189941\n",
            "Complete prediction MSE : 0.0011231721298260986\n",
            "Epoch 127 : Train loss 3.975788121111691, validation loss 8.411991119384766\n",
            "Complete prediction MSE : 0.0009885868780932345\n",
            "Saving model\n",
            "Epoch 128 : Train loss 3.9719537789933383, validation loss 8.683847427368164\n",
            "Complete prediction MSE : 0.0010063779296452778\n",
            "Epoch 129 : Train loss 3.9641133276745677, validation loss 8.648653030395508\n",
            "Complete prediction MSE : 0.0010530612445800132\n",
            "Epoch 130 : Train loss 3.9565580636262894, validation loss 8.711949348449707\n",
            "Complete prediction MSE : 0.0010874343284784445\n",
            "Epoch 131 : Train loss 3.950198580045253, validation loss 8.253462791442871\n",
            "Complete prediction MSE : 0.0010267414146746916\n",
            "Epoch 132 : Train loss 3.946654255501926, validation loss 8.677549362182617\n",
            "Complete prediction MSE : 0.000996150699965896\n",
            "Epoch 133 : Train loss 3.9449095320887864, validation loss 8.413016319274902\n",
            "Complete prediction MSE : 0.000988762790682336\n",
            "Epoch 134 : Train loss 3.93723617028445, validation loss 8.600909233093262\n",
            "Complete prediction MSE : 0.001027742405180256\n",
            "Epoch 135 : Train loss 3.935058114118874, validation loss 8.462804794311523\n",
            "Complete prediction MSE : 0.0011063189939153721\n",
            "Epoch 136 : Train loss 3.9336252002976835, validation loss 8.413419723510742\n",
            "Complete prediction MSE : 0.0010832382237053052\n",
            "Epoch 137 : Train loss 3.922830821480602, validation loss 8.464126586914062\n",
            "Complete prediction MSE : 0.0010611131066214242\n",
            "Epoch 138 : Train loss 3.9181182770989835, validation loss 8.586193084716797\n",
            "Complete prediction MSE : 0.0010219840422687435\n",
            "Epoch 139 : Train loss 3.914061809424311, validation loss 8.564752578735352\n",
            "Complete prediction MSE : 0.0010255778602982824\n",
            "Epoch 140 : Train loss 3.913982984609902, validation loss 8.346036911010742\n",
            "Complete prediction MSE : 0.001024374622945168\n",
            "Epoch 141 : Train loss 3.902919010259211, validation loss 8.549853324890137\n",
            "Complete prediction MSE : 0.0010251610599776382\n",
            "Epoch 142 : Train loss 3.8994254949502647, validation loss 8.48717975616455\n",
            "Complete prediction MSE : 0.0010502173547220902\n",
            "Epoch 143 : Train loss 3.895143943838775, validation loss 8.212294578552246\n",
            "Complete prediction MSE : 0.0010558430768759098\n",
            "Epoch 144 : Train loss 3.8867284217849374, validation loss 8.399770736694336\n",
            "Complete prediction MSE : 0.0010700738545536279\n",
            "Epoch 145 : Train loss 3.887691886164248, validation loss 8.454216957092285\n",
            "Complete prediction MSE : 0.00113841179810011\n",
            "Epoch 146 : Train loss 3.887506208382547, validation loss 8.267467498779297\n",
            "Complete prediction MSE : 0.0010726582059663915\n",
            "Epoch 147 : Train loss 3.879930320661515, validation loss 7.924314498901367\n",
            "Complete prediction MSE : 0.0010308691127143995\n",
            "Epoch 148 : Train loss 3.876813347451389, validation loss 8.346779823303223\n",
            "Complete prediction MSE : 0.0010509834375532602\n",
            "Epoch 149 : Train loss 3.8716641743667424, validation loss 8.34078311920166\n",
            "Complete prediction MSE : 0.0011321555286666818\n",
            "Epoch 150 : Train loss 3.872208441607654, validation loss 8.36221981048584\n",
            "Complete prediction MSE : 0.001164398757049288\n",
            "Epoch 151 : Train loss 3.8704148079268634, validation loss 8.324825286865234\n",
            "Complete prediction MSE : 0.001034763971001012\n",
            "Epoch 152 : Train loss 3.856229188386351, validation loss 8.576675415039062\n",
            "Complete prediction MSE : 0.001086838531369455\n",
            "Epoch 153 : Train loss 3.8558347006328404, validation loss 8.069777488708496\n",
            "Complete prediction MSE : 0.0009686646889694636\n",
            "Saving model\n",
            "Epoch 154 : Train loss 3.847613338381052, validation loss 8.035233497619629\n",
            "Complete prediction MSE : 0.0010257918392179996\n",
            "Epoch 155 : Train loss 3.842683451715857, validation loss 8.48996353149414\n",
            "Complete prediction MSE : 0.0010261717478521988\n",
            "Epoch 156 : Train loss 3.8400579430162907, validation loss 8.338540077209473\n",
            "Complete prediction MSE : 0.0010971993276110556\n",
            "Epoch 157 : Train loss 3.8454123297706246, validation loss 8.515453338623047\n",
            "Complete prediction MSE : 0.001041973030807748\n",
            "Epoch 158 : Train loss 3.839386633131653, validation loss 8.132360458374023\n",
            "Complete prediction MSE : 0.0010300680392897525\n",
            "Epoch 159 : Train loss 3.8369227489456534, validation loss 8.176946640014648\n",
            "Complete prediction MSE : 0.0010497672370812033\n",
            "Epoch 160 : Train loss 3.83280061557889, validation loss 8.798554420471191\n",
            "Complete prediction MSE : 0.001072888633195946\n",
            "Epoch 161 : Train loss 3.8252858915366232, validation loss 8.781216621398926\n",
            "Complete prediction MSE : 0.0010996891369295257\n",
            "Epoch 162 : Train loss 3.817407623399049, validation loss 8.640963554382324\n",
            "Complete prediction MSE : 0.001026679172179374\n",
            "Epoch 163 : Train loss 3.8195647597312927, validation loss 8.602104187011719\n",
            "Complete prediction MSE : 0.001087238292704852\n",
            "Epoch 164 : Train loss 3.8197841895744205, validation loss 8.430153846740723\n",
            "Complete prediction MSE : 0.001105454085100062\n",
            "Epoch 165 : Train loss 3.8113078298047185, validation loss 8.6099271774292\n",
            "Complete prediction MSE : 0.0011022347077906188\n",
            "Epoch 166 : Train loss 3.8106624223291874, validation loss 8.526580810546875\n",
            "Complete prediction MSE : 0.0010585505699929978\n",
            "Epoch 167 : Train loss 3.795838814228773, validation loss 8.649293899536133\n",
            "Complete prediction MSE : 0.0010435428798032348\n",
            "Epoch 168 : Train loss 3.8012210773304105, validation loss 8.467070579528809\n",
            "Complete prediction MSE : 0.0010827002300193907\n",
            "Epoch 169 : Train loss 3.7895994097925723, validation loss 8.177242279052734\n",
            "Complete prediction MSE : 0.0010865457683322162\n",
            "Epoch 170 : Train loss 3.793734911363572, validation loss 8.22945785522461\n",
            "Complete prediction MSE : 0.0010977237587244902\n",
            "Epoch 171 : Train loss 3.7913232161663473, validation loss 8.010807991027832\n",
            "Complete prediction MSE : 0.0010927728684136976\n",
            "Epoch 172 : Train loss 3.7894560848362744, validation loss 8.102498054504395\n",
            "Complete prediction MSE : 0.0011781361131656953\n",
            "Epoch 173 : Train loss 3.7880408954806626, validation loss 8.317602157592773\n",
            "Complete prediction MSE : 0.001105168560966549\n",
            "Epoch 174 : Train loss 3.7735018343664706, validation loss 7.969168663024902\n",
            "Complete prediction MSE : 0.0010965293570351327\n",
            "Epoch 175 : Train loss 3.773562707938254, validation loss 8.379005432128906\n",
            "Complete prediction MSE : 0.00106688766132467\n",
            "Epoch 176 : Train loss 3.775442037731409, validation loss 8.223812103271484\n",
            "Complete prediction MSE : 0.0011549888191057837\n",
            "Epoch 177 : Train loss 3.772292699664831, validation loss 8.155378341674805\n",
            "Complete prediction MSE : 0.001152682674340285\n",
            "Epoch 178 : Train loss 3.7673350195400417, validation loss 8.333476066589355\n",
            "Complete prediction MSE : 0.0011179364799214612\n",
            "Epoch 179 : Train loss 3.768787923734635, validation loss 8.188045501708984\n",
            "Complete prediction MSE : 0.0011505893434827334\n",
            "Epoch 180 : Train loss 3.7582356836646795, validation loss 8.411389350891113\n",
            "Complete prediction MSE : 0.0012254598716474995\n",
            "Epoch 181 : Train loss 3.7695976556278765, validation loss 8.31771469116211\n",
            "Complete prediction MSE : 0.0011537962937853505\n",
            "Epoch 182 : Train loss 3.75945614092052, validation loss 7.912912845611572\n",
            "Complete prediction MSE : 0.001273061031641491\n",
            "Epoch 183 : Train loss 3.7579056513495743, validation loss 7.979262828826904\n",
            "Complete prediction MSE : 0.0011063072647813762\n",
            "Epoch 184 : Train loss 3.7522369204089046, validation loss 8.763193130493164\n",
            "Complete prediction MSE : 0.0010406959853835119\n",
            "Epoch 185 : Train loss 3.7512036971747875, validation loss 8.132000923156738\n",
            "Complete prediction MSE : 0.0011292865649902553\n",
            "Epoch 186 : Train loss 3.743319818750024, validation loss 8.289192199707031\n",
            "Complete prediction MSE : 0.001139267322716496\n",
            "Epoch 187 : Train loss 3.749987204093486, validation loss 8.28466510772705\n",
            "Complete prediction MSE : 0.0010954278216536246\n",
            "Epoch 188 : Train loss 3.7381083793006837, validation loss 8.433337211608887\n",
            "Complete prediction MSE : 0.0011520560201292095\n",
            "Epoch 189 : Train loss 3.7399860993027687, validation loss 8.17559814453125\n",
            "Complete prediction MSE : 0.0011124128268234453\n",
            "Epoch 190 : Train loss 3.7511005043052137, validation loss 8.49277400970459\n",
            "Complete prediction MSE : 0.0011758718590485786\n",
            "Epoch 191 : Train loss 3.737490885425359, validation loss 8.217044830322266\n",
            "Complete prediction MSE : 0.0012057797382810864\n",
            "Epoch 192 : Train loss 3.7317379293963313, validation loss 7.925523281097412\n",
            "Complete prediction MSE : 0.0012155750459354542\n",
            "Epoch 193 : Train loss 3.7260386692360044, validation loss 8.095319747924805\n",
            "Complete prediction MSE : 0.0010861698138835403\n",
            "Epoch 194 : Train loss 3.729629130102694, validation loss 8.195330619812012\n",
            "Complete prediction MSE : 0.0011956610483901784\n",
            "Epoch 195 : Train loss 3.730348687618971, validation loss 8.488807678222656\n",
            "Complete prediction MSE : 0.00111091933960805\n",
            "Epoch 196 : Train loss 3.722900042310357, validation loss 8.337143898010254\n",
            "Complete prediction MSE : 0.0012475019128392242\n",
            "Epoch 197 : Train loss 3.7180665279738605, validation loss 8.02734661102295\n",
            "Complete prediction MSE : 0.0010817595445986655\n",
            "Epoch 198 : Train loss 3.715827860403806, validation loss 8.334386825561523\n",
            "Complete prediction MSE : 0.0013478503806712966\n",
            "Epoch 199 : Train loss 3.7133083040826023, validation loss 7.74501895904541\n",
            "Complete prediction MSE : 0.0012153985983286008\n",
            "Epoch 200 : Train loss 3.719361779280007, validation loss 7.7633256912231445\n",
            "Complete prediction MSE : 0.001111799550811125\n",
            "Epoch 201 : Train loss 3.714986586011946, validation loss 8.179744720458984\n",
            "Complete prediction MSE : 0.00131284530533524\n",
            "Epoch 202 : Train loss 3.7087627379223704, validation loss 7.870772361755371\n",
            "Complete prediction MSE : 0.0012168321056155091\n",
            "Epoch 203 : Train loss 3.7053585057146847, validation loss 8.109322547912598\n",
            "Complete prediction MSE : 0.0011695235857438573\n",
            "Early stopping due to no more improvement and/or unstable training\n"
          ]
        }
      ],
      "source": [
        "nb_seeds = 5\n",
        "for seed in range(nb_seeds):\n",
        "  torch.manual_seed(seed)\n",
        "  model = AIKAE.AIKAE(input_dim=20, hidden_dim=256, n_layers_encoder=6, augmentation_dims=[512,512,16],\n",
        "                      positive_nonlin=nn.Softplus(), flow='NICE', device=device).to(device)\n",
        "  print(f'Training model with seed {seed}')\n",
        "  epochs = 500\n",
        "  #opt = model.configure_optimizers(lr=1e-3)\n",
        "  opt = model.configure_optimizers(lr=1e-3, weight_decay=1e-6) #with weight decay\n",
        "  max_patience = 50\n",
        "  patience = 0\n",
        "  time_span = 100\n",
        "  alpha = 0\n",
        "  lamda = 100.\n",
        "  model.best_epoch, model.best_val = 0, 1e15\n",
        "  last_train_index = 53\n",
        "  model.train_losses = []\n",
        "  model.val_losses = []\n",
        "  model.val_losses2 = []\n",
        "  model.val_losses3 = []\n",
        "  starting_point = 0\n",
        "  loss_every = 1\n",
        "\n",
        "  for epoch in range(epochs+1) :\n",
        "    if patience >= max_patience:\n",
        "      print('Early stopping due to no more improvement and/or unstable training')\n",
        "      break\n",
        "    epoch_loss = 0\n",
        "    epoch_val_loss = 0\n",
        "    model.train()\n",
        "    for batch in range(nb_batches) :\n",
        "      opt.zero_grad()\n",
        "      x0 = state_batches[0,batch].to(device)\n",
        "      gt = state_batches[:,batch].to(device)\n",
        "      latent_states = model.encode(gt.flatten(0,1))\n",
        "      #print(gt.shape, latent_states.shape, x0.shape)\n",
        "      xt, phis = model.forward_n_remember(x0, time_span)\n",
        "      phi_0 = phis[0]\n",
        "      loss = 0\n",
        "      # Prediction loss\n",
        "      #print(phis.shape, latent_states.shape, gt.shape)\n",
        "      pred_loss = mse_loss(model.decode(phis.flatten(0,1)).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "      loss += pred_loss\n",
        "      # Reconstruction loss\n",
        "      #ae_loss = mse_loss(model.decode(latent_states).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "      #loss += ae_loss\n",
        "      # Linearity loss\n",
        "      lin_loss = mse_loss(phis, latent_states.reshape((phis.shape[0], phis.shape[1], phis.shape[2])))\n",
        "      loss += lin_loss\n",
        "      # Orthogonality loss\n",
        "      orth_loss = lamda * mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "      loss += orth_loss\n",
        "      #if batch % 100 == 0:\n",
        "        #print(f\"Batch {batch}: loss = {loss}\")\n",
        "        #print(f\"pred loss = {pred_loss}, ae loss = {ae_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\n",
        "        #print(f\"pred loss = {pred_loss}, lin loss = {lin_loss}, orth loss = {orth_loss}\")\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      epoch_loss += loss.detach().item()\n",
        "\n",
        "    #scheduler.step()\n",
        "    epoch_loss /= nb_batches\n",
        "    model.train_losses.append(epoch_loss)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    x0 = states_val[0].to(device)\n",
        "    gt = states_val.to(device)\n",
        "    latent_states = model.encode(states_val.to(device).flatten(0,1))\n",
        "    xt, phis = model.forward_n_remember(x0, time_span)\n",
        "    phi_0 = phis[0]\n",
        "    loss = 0\n",
        "    # Prediction loss\n",
        "    val_loss += mse_loss(model.decode(phis.flatten(0,1)).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "    # Reconstruction loss\n",
        "    #val_loss += mse_loss(model.decode(latent_states).reshape((gt.shape[0], gt.shape[1], gt.shape[2])), gt)\n",
        "    # Linearity loss\n",
        "    val_loss += mse_loss(phis, latent_states.reshape((phis.shape[0], phis.shape[1], phis.shape[2])))\n",
        "    # Orthogonality loss\n",
        "    val_loss += lamda * mse_loss(torch.matmul(model.K, model.K.T), torch.eye(model.latent_dim).to(device)) * batch_size / 512\n",
        "    model.val_losses2.append(val_loss.item())\n",
        "    #epoch_val_loss = val_loss.item()\n",
        "    whole_predictions = np.zeros((data_small.shape[0]-101, data_small.shape[1]//10, data_small.shape[2], data_small.shape[3]))\n",
        "    for column in range(data_small.shape[1] // 10) :\n",
        "      states = torch.Tensor(data_small[1:,10*column]).to(device)\n",
        "      states = torch.cat([states, states - torch.Tensor(data_small[:-1,10*column]).to(device)], dim=2) # Add derivatives\n",
        "      predictions, phis = model.forward_n_remember(states[starting_point],241)\n",
        "      #whole_predictions[starting_point:, column] = predictions[:342-starting_point,:10].cpu().detach()\n",
        "      decoded = model.decode(phis.flatten(0,1)).reshape((phis.shape[0], phis.shape[1], model.input_dim))\n",
        "      whole_predictions[starting_point:, column] = decoded[:whole_predictions.shape[0]-starting_point,:,:10].cpu().detach()\n",
        "\n",
        "    val_loss3 = np.mean((data_small[starting_point+1:starting_point+243,::10] - whole_predictions)[starting_point:] **2)\n",
        "    model.val_losses3.append(val_loss3.item())\n",
        "    epoch_val_loss = val_loss3.item()\n",
        "    if epoch % loss_every == 0 :\n",
        "      print(f\"Epoch {epoch+1} : Train loss {model.train_losses[-1]}, validation loss {model.val_losses2[-1]}\")\n",
        "      print(f\"Complete prediction MSE : {model.val_losses3[-1]}\")\n",
        "    if epoch_val_loss < model.best_val : # Save the model parameters\n",
        "      model.best_val = epoch_val_loss\n",
        "      model.best_epoch = epoch\n",
        "      torch.save(model.state_dict(), models_path+f'/best_model_{seed}.pt')\n",
        "      torch.save(model.K, models_path+f'/best_K_{seed}.pt')\n",
        "      patience = 0\n",
        "      print('Saving model')\n",
        "    else:\n",
        "      patience += 1\n",
        "      if math.isnan(epoch_val_loss) or model.train_losses[-1] > 1000:\n",
        "        patience += 10"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zuV-T9cAJH7T",
        "ztmhyu9VLEVM",
        "a-jfGwjDYzQo",
        "F6B4duNNN-NE",
        "UeOHCR1FE9QZ",
        "1e70Yh5M757P",
        "GMvDZUXg4SPH",
        "sa05gcYgH_8b",
        "uXHr1F9RGFVm",
        "DotWdymHnj20",
        "eP4OBmLrcKhM",
        "ryvU5XgIrhln",
        "nIpyTb0Q90b9",
        "GXoSypqN_hOy",
        "prnpCXBBF6hx",
        "MIkmeZXqXqZ6",
        "wuYvtExFB5_p",
        "KgQO8W5RpI9f",
        "7sK-ShMwKSBO",
        "vCIcVKcYYzLy",
        "NNvvmjWBEcJM",
        "6Y9RAf4q7RUL",
        "OFylNgptu8gZ",
        "akV7Osa-xFpS",
        "lEaH0kovxI3x",
        "j2ox8UefdWDK",
        "hk7hROB1gGxb",
        "11omh3QvFFb3",
        "Gs2EviD_Fr94",
        "8qSdoIMCJn3D",
        "CzblXzc6F0sM",
        "CH3uHSvRmdxH",
        "BAMVV_kpFIjT",
        "aoyh4RdueVc9",
        "TPsn2RXVzX3p",
        "0yi67SJhtIdj",
        "stlfswast0-n"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}